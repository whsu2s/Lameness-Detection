{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DeepLabCut Toolbox\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "\n",
    "Nath\\*, Mathis\\* et al. *Using DeepLabCut for markerless pose estimation during behavior across species*, (under revision).\n",
    "\n",
    "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
    "This shows the most simple code to do so, but many of the functions have additional features, so please check out the overview & the protocol paper!\n",
    "\n",
    "This notebook illustrates how to:\n",
    "- create a project\n",
    "- extract training frames\n",
    "- label the frames\n",
    "- plot the labeled images\n",
    "- create a training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "- create an automatically labeled video \n",
    "- plot the trajectories\n",
    "\n",
    "*Note*: Refine a network based after the network was trained on just a few labeled images is illustrated in \"Demo-labeledexample-MouseReaching.ipynb\". This demo also contains an already labeled data set and is perhaps the best starting point for brand new users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate. This function creates a new project with subdirectories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/videos\"\n",
      "Created \"/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data\"\n",
      "Created \"/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/training-datasets\"\n",
      "Created \"/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models\"\n",
      "Copying the videos\n",
      "data/Tag1/cow1.mp4\n",
      "data/Tag1/cow24.mp4\n",
      "Generated \"/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/config.yaml\"\n",
      "\n",
      "A new project with name Cow_labeling-FKIE-2019-01-02 is created at /home/wei-chan/Documents/Thesis/src/annotation and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/config.yaml'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = 'Cow_labeling' # Enter the name of your experiment Task\n",
    "experimenter = 'FKIE' # Enter the name of the experimenter\n",
    "video = ['data/Tag1/cow1.mp4', 'data/Tag1/cow24.mp4'] # Enter the paths of your videos you want to grab frames from.\n",
    "\n",
    "deeplabcut.create_new_project(task, experimenter, video, working_directory='/home/wei-chan/Documents/Thesis/src/annotation', copy_videos=True) #change the working directory to where you want the folders created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Add new videos \n",
    "Additionally, if the user wants to add new videos to the project at any stage, the function add_new_videos can be used. This will update the list of videos in the project's configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path of the config file that was just created from the above step (check the folder)\n",
    "path_config_file = '/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/config.yaml' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying the videos\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "video_path = ['data/Tag1/cow155.mp4', 'data/Tag1/cow160.mp4', 'data/Tag1/cow161.mp4', 'data/Tag1/cow220.mp4', \\\n",
    "              'data/Tag1/cow233.mp4', 'data/Tag1/cow254.mp4', 'data/Tag1/cow274.mp4', 'data/Tag1/cow1403.mp4']\n",
    "deeplabcut.add_new_videos(path_config_file, video_path, copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract frames from videos \n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) (algo=='uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config file successfully...\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 9.3  seconds.\n",
      "Extracting and downsampling... 186  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186it [00:00, 395.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:00, 367.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 7.55  seconds.\n",
      "Extracting and downsampling... 151  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [00:00, 363.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:00, 374.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 7.85  seconds.\n",
      "Extracting and downsampling... 157  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 365.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:00, 353.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 8.6  seconds.\n",
      "Extracting and downsampling... 172  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172it [00:00, 372.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:00, 331.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 11.5  seconds.\n",
      "Extracting and downsampling... 230  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [00:00, 381.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:00, 339.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 7.85  seconds.\n",
      "Extracting and downsampling... 157  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 366.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:00, 416.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 6.1  seconds.\n",
      "Extracting and downsampling... 122  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:00, 412.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:00, 361.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 6.1  seconds.\n",
      "Extracting and downsampling... 122  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:00, 352.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:00, 369.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 6.7  seconds.\n",
      "Extracting and downsampling... 134  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "134it [00:00, 370.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:00, 395.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 5.8  seconds.\n",
      "Extracting and downsampling... 116  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "116it [00:00, 362.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "\n",
      "Frames are selected.\n",
      "You can now label the frames using the function 'label_frames'.\n"
     ]
    }
   ],
   "source": [
    "# There are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "# You can change the cropping to false, then delete the checkcropping part!\n",
    "deeplabcut.extract_frames(path_config_file, 'automatic', 'kmeans', crop=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot activate multiple GUI eventloops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on folder: cow155\n",
      "Working on folder: cow160\n",
      "Working on folder: cow161\n",
      "Working on folder: cow220\n",
      "Working on folder: cow233\n",
      "Working on folder: cow254\n",
      "Working on folder: cow274\n",
      "Working on folder: cow1403\n",
      "You can now check the labels, using 'check_labels' before proceeding. Then,  you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "**Check the labels**\n",
    "\n",
    "Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. The DeepLabCut toolbox provides a function `check\\_labels'  to do so. It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by FKIE.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow1_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow1_labeled.\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow1403_labeled.\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow155_labeled.\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow160_labeled.\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow161_labeled.\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow220_labeled.\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow233_labeled.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow24_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow24_labeled.\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow254_labeled.\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow274_labeled.\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use the refinement GUI to move them around! Check that out below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "This function generates the training data information for DeepCut (which requires a mat file) based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles. \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/training-datasets/iteration-1/UnaugmentedDataSet_Cow_labelingJan2  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1//train  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1//test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training - If you want to use a CPU, continue. \n",
    "### If yu want to use your GPU, you need to exit here and either work from the Docker container, your own TensorFlow installation in an Anaconda env\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt\n",
      "Restoring parameters from /home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'dataset_type': 'default', 'use_gt_segm': False, 'batch_size': 1, 'video': False, 'video_batch': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]], 'all_joints_names': ['head', 'neck', 'withers', 'back1', 'back2', 'back3', 'hoofFL', 'hoofFR', 'hoofHL', 'hoofHR'], 'dataset': 'training-datasets/iteration-1/UnaugmentedDataSet_Cow_labelingJan2/Cow_labeling_FKIE90shuffle1.mat', 'display_iters': 500, 'init_weights': '/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'max_input_size': 1000, 'metadataset': 'training-datasets/iteration-1/UnaugmentedDataSet_Cow_labelingJan2/Documentation_data-Cow_labeling_90shuffle1.pickle', 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 10, 'pos_dist_thresh': 17, 'project_path': '/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02', 'save_iters': 1000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0dc5cb6e2491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgputouse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, gputouse, max_snapshots_to_keep, autotune, displayiters, saveiters, maxiters)\u001b[0m\n\u001b[1;32m     79\u001b[0m           \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m           \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, gputouse, max_snapshots_to_keep, autotune, displayiters, saveiters, maxiters)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m           \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         [_, loss_val, summary] = sess.run([train_op, total_loss, merged_summaries],\n\u001b[0;32m--> 142\u001b[0;31m                                           feed_dict={learning_rate: current_lr})\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file, gputouse=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/evaluation-results/  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/evaluation-results/iteration-1/Cow_labelingJan2-trainset90shuffle1  already exists!\n",
      "Running  DeepCut_resnet50_Cow_labelingJan2shuffle1_30000  with # of trainingiterations: 30000\n",
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "248it [00:17, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-30000\n",
      "Results for 30000  training iterations: 90 1 train error: 4.0 pixels. Test error: 7.97  pixels.\n",
      "With pcutoff of 0.1  train error: 4.0 pixels. Test error: 7.95 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-30000 for model /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1\n",
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "  0%|          | 0/201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4\n",
      "Duration of video [s]:  10.05 , recorded with  20.0 fps!\n",
      "Overall # of frames:  201 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210it [00:09, 22.73it/s]                         \n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  201\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow274.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow274.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow274.mp4\n",
      "Duration of video [s]:  7.65 , recorded with  20.0 fps!\n",
      "Overall # of frames:  153 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:06, 24.05it/s]                         \n",
      "  0%|          | 0/182 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  153\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow160.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow160.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow160.mp4\n",
      "Duration of video [s]:  9.1 , recorded with  20.0 fps!\n",
      "Overall # of frames:  182 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "190it [00:07, 22.34it/s]                         \n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  182\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow161.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow161.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow161.mp4\n",
      "Duration of video [s]:  10.0 , recorded with  20.0 fps!\n",
      "Overall # of frames:  200 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210it [00:08, 22.22it/s]                         \n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  200\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24.mp4\n",
      "Duration of video [s]:  7.85 , recorded with  20.0 fps!\n",
      "Overall # of frames:  157 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:06, 23.68it/s]                         \n",
      "  0%|          | 0/195 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  157\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow220.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow220.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow220.mp4\n",
      "Duration of video [s]:  9.75 , recorded with  20.0 fps!\n",
      "Overall # of frames:  195 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:08, 23.55it/s]                         \n",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  195\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1403.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1403.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1403.mp4\n",
      "Duration of video [s]:  7.8 , recorded with  20.0 fps!\n",
      "Overall # of frames:  156 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:06, 23.54it/s]                         \n",
      "  0%|          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  156\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow155.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow155.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow155.mp4\n",
      "Duration of video [s]:  8.6 , recorded with  20.0 fps!\n",
      "Overall # of frames:  172 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [00:07, 23.48it/s]                         \n",
      "  0%|          | 0/175 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  172\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow233.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow233.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow233.mp4\n",
      "Duration of video [s]:  8.75 , recorded with  20.0 fps!\n",
      "Overall # of frames:  175 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [00:07, 22.65it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  175\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow254.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow254.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow254.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/136 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]:  6.8 , recorded with  20.0 fps!\n",
      "Overall # of frames:  136 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:06, 22.35it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  136\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter the list of videos to analyze.\n",
    "videofile_path = glob.glob('/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/*.mp4')\n",
    "deeplabcut.analyze_videos(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['head',\n",
      "                      'neck',\n",
      "                      'withers',\n",
      "                      'back1',\n",
      "                      'back2',\n",
      "                      'back3',\n",
      "                      'hoofFL',\n",
      "                      'hoofFR',\n",
      "                      'hoofHL',\n",
      "                      'hoofHR'],\n",
      " 'batch_size': 4,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Cow_labelingJan2/Cow_labeling_FKIE90shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'display_iters': 500,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1000,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Cow_labelingJan2/Documentation_data-Cow_labeling_90shuffle1.pickle',\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 1000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-0/Cow_labelingJan2-trainset90shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'use_gt_segm': False,\n",
      " 'video': False,\n",
      " 'video_batch': False,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['head',\n",
      "                      'neck',\n",
      "                      'withers',\n",
      "                      'back1',\n",
      "                      'back2',\n",
      "                      'back3',\n",
      "                      'hoofFL',\n",
      "                      'hoofFR',\n",
      "                      'hoofHL',\n",
      "                      'hoofHR'],\n",
      " 'batch_size': 4,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Cow_labelingJan2/Cow_labeling_FKIE90shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'display_iters': 500,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1000,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Cow_labelingJan2/Documentation_data-Cow_labeling_90shuffle1.pickle',\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 1000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-0/Cow_labelingJan2-trainset90shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'use_gt_segm': False,\n",
      " 'video': False,\n",
      " 'video_batch': False,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-21000 for model /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-0/Cow_labelingJan2-trainset90shuffle1\n",
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-0/Cow_labelingJan2-trainset90shuffle1/train/snapshot-21000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-0/Cow_labelingJan2-trainset90shuffle1/train/snapshot-21000\n",
      "Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-0/Cow_labelingJan2-trainset90shuffle1/train/snapshot-21000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4\n",
      "Video already analyzed! /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1DeepCut_resnet50_Cow_labelingJan2shuffle1_21000.h5\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24.mp4\n",
      "Video already analyzed! /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24DeepCut_resnet50_Cow_labelingJan2shuffle1_21000.h5\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    }
   ],
   "source": [
    "# Enter the list of videos to analyze.\n",
    "videofile_path = ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4',\\\n",
    "                  '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24.mp4',\\\n",
    "                  '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4',\\\n",
    "                  '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24.mp4',\\\n",
    "                  '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4',\\\n",
    "                  '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24.mp4',\\\n",
    "                  '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4',\\\n",
    "                  '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24.mp4',\\\n",
    "                  '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4',\\\n",
    "                  '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow24.mp4',\\] \n",
    "deeplabcut.analyze_videos(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [optional step]\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. Make sure to provide the correct value of the \"iterations\" as it will be used to create the unique directory where the extracted frames will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network parameters: DeepCut_resnet50_Cow_labelingJan2shuffle1_30000\n",
      "The video has not been analyzed yet!. You can only refine the labels, after the pose has been estimate. Please run 'analyze_video' first.\n",
      "Fitting state-space models with parameters 3 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      "/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  1.61it/s]WARNING:py.warnings:/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      "/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      " 50%|█████     | 2/4 [00:01<00:01,  1.67it/s]WARNING:py.warnings:/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      "/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  1.60it/s]WARNING:py.warnings:/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      "/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  fitting  found  176  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, ARdegree, MAdegree, alpha, comparisonbodyparts) or use a different method.\n",
      "yes/noyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/utils/frameselectiontools.py:47: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if Index==\"all\":\n",
      "\n",
      "/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/utils/frameselectiontools.py:47: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if Index==\"all\":\n",
      "\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video cow1  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  10.05 , recorded @  20.0 fps!\n",
      "Overall # of frames:  201 with (cropped) frame dimensions:  [680, 420]\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 10.05  seconds.\n",
      "Extracting... 175  (this might take a while).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [00:00, 366.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering...(this might take a while).\n",
      "Let's select frames indices: [187, 126, 87, 16, 162, 41, 90, 141, 50, 19, 119, 25, 105, 156, 136, 171, 149, 65, 6, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow1.mp4 Coordinates for cropping: None\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\cow1.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Fitting state-space models with parameters 3 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      "/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  1.61it/s]WARNING:py.warnings:/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      "/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      " 50%|█████     | 2/4 [00:01<00:01,  1.59it/s]WARNING:py.warnings:/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      "/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  fitting  found  152  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, ARdegree, MAdegree, alpha, comparisonbodyparts) or use a different method.\n",
      "yes/noyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video cow274  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  7.65 , recorded @  20.0 fps!\n",
      "Overall # of frames:  153 with (cropped) frame dimensions:  [680, 420]\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 7.65  seconds.\n",
      "Extracting... 151  (this might take a while).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [00:00, 375.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering...(this might take a while).\n",
      "Let's select frames indices: [41, 90, 134, 50, 113, 147, 15, 111, 65, 121, 143, 106, 28, 123, 83, 3, 80, 44, 64, 94]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow274.mp4 Coordinates for cropping: None\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\cow274.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "The video has not been analyzed yet!. You can only refine the labels, after the pose has been estimate. Please run 'analyze_video' first.\n",
      "Fitting state-space models with parameters 3 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  fitting  found  179  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, ARdegree, MAdegree, alpha, comparisonbodyparts) or use a different method.\n",
      "yes/noyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video cow160  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  9.1 , recorded @  20.0 fps!\n",
      "Overall # of frames:  182 with (cropped) frame dimensions:  [680, 420]\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 9.1  seconds.\n",
      "Extracting... 178  (this might take a while).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "178it [00:00, 369.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering...(this might take a while).\n",
      "Let's select frames indices: [32, 141, 175, 105, 50, 21, 92, 36, 160, 64, 7, 117, 84, 123, 110, 164, 15, 178, 71, 134]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow160.mp4 Coordinates for cropping: None\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\cow160.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "The video has not been analyzed yet!. You can only refine the labels, after the pose has been estimate. Please run 'analyze_video' first.\n",
      "The video has not been analyzed yet!. You can only refine the labels, after the pose has been estimate. Please run 'analyze_video' first.\n",
      "Fitting state-space models with parameters 3 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  fitting  found  200  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, ARdegree, MAdegree, alpha, comparisonbodyparts) or use a different method.\n",
      "yes/noyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video cow161  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  10.0 , recorded @  20.0 fps!\n",
      "Overall # of frames:  200 with (cropped) frame dimensions:  [680, 420]\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 10.0  seconds.\n",
      "Extracting... 199  (this might take a while).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [00:00, 396.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering...(this might take a while).\n",
      "Let's select frames indices: [119, 26, 171, 80, 152, 1, 190, 98, 93, 52, 15, 187, 106, 62, 36, 133, 166, 114, 127, 136]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: /home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/cow161.mp4 Coordinates for cropping: None\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\cow161.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Fitting state-space models with parameters 3 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      "/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  1.76it/s]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "LU decomposition error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-53a9c6051b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                                   \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                   \u001b[0mp_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                   extractionalgorithm = 'kmeans')\n\u001b[0m",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/refine_training_dataset/outlier_frames.py\u001b[0m in \u001b[0;36mextract_outlier_frames\u001b[0;34m(config, videos, shuffle, trainingsetindex, outlieralgorithm, comparisonbodyparts, epsilon, p_bound, ARdegree, MAdegree, alpha, extractionalgorithm, automatic)\u001b[0m\n\u001b[1;32m    129\u001b[0m               \u001b[0;31m#deviation_dataname = str(Path(videofolder)/Path(dataname))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m               \u001b[0;31m# Calculate deviatons for video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m               \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputeDeviations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomparisonbodyparts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mARdegree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m               \u001b[0;31m#Some heuristics for extracting frames based on distance:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m               \u001b[0mIndices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# time points with at least average difference of epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/refine_training_dataset/outlier_frames.py\u001b[0m in \u001b[0;36mComputeDeviations\u001b[0;34m(Dataframe, cfg, comparisonbodyparts, scorer, dataname, p_bound, alpha, ARdegree, MAdegree, storeoutput)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bodyparts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#filter [who knows what users put in...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'likelihood'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mmeanx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCIx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFitSARIMAXModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mARdegree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;31m#meanx,CIx=meanx.values,CIx.values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mmeany\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCIy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFitSARIMAXModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mARdegree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMAdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/refine_training_dataset/outlier_frames.py\u001b[0m in \u001b[0;36mFitSARIMAXModel\u001b[0;34m(x, p, pcutoff, alpha, ARdegree, MAdegree, nforecast)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m#mod = sm.tsa.ARIMA(Y, order=(ARdegree,0,MAdegree)) #order=(ARdegree,0,MAdegree)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#https://groups.google.com/forum/#!topic/pystatsmodels/S_Fo53F25Rk (let's update to statsmodels 0.10.0 soon...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mstartvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconvertparms2start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, transformed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m                                            \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                                            \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                                            skip_hessian=True, **kwargs)\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# Just return the fitted parameters if requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m                                                        \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                                                        \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                                                        full_output=full_output)\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;31m# NOTE: this is for fit_regularized and should be generalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    189\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                             hess=hessian)\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         optim_settings = {'optimizer': method, 'start_params': start_params,\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    408\u001b[0m                                      \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                                      \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                                      **extra_kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mloglike\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inversion_method'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINVERT_UNIVARIATE\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mSOLVE_LU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\u001b[0m in \u001b[0;36mloglike\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m                                ' MEMORY_NO_LIKELIHOOD option is selected.')\n\u001b[1;32m    824\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conserve_memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMEMORY_CONSERVE\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0mMEMORY_NO_LIKELIHOOD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mkfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m         loglikelihood_burn = kwargs.get('loglikelihood_burn',\n\u001b[1;32m    827\u001b[0m                                         self.loglikelihood_burn)\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\u001b[0m in \u001b[0;36m_filter\u001b[0;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;31m# Initialize the state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# Run the filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/representation.py\u001b[0m in \u001b[0;36m_initialize_state\u001b[0;34m(self, prefix, complex_step)\u001b[0m\n\u001b[1;32m    721\u001b[0m             )\n\u001b[1;32m    722\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialization\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'stationary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_statespaces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_stationary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Statespace model not initialized.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_representation.pyx\u001b[0m in \u001b[0;36mstatsmodels.tsa.statespace._representation.dStatespace.initialize_stationary\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_tools.pyx\u001b[0m in \u001b[0;36mstatsmodels.tsa.statespace._tools._dsolve_discrete_lyapunov\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: LU decomposition error."
     ]
    }
   ],
   "source": [
    "''' \n",
    "deeplabcut.extract_outlier_frames(path_config_file, \n",
    "                                  video_path,\n",
    "                                  comparisonbodyparts = ['hoofFL','hoofFR','hoofHL', 'hoofHR'], \n",
    "                                  epsilon = 5, \n",
    "                                  p_bound = 0.2\n",
    "                                  extractionalgorithm = 'kmeans')\n",
    "'''\n",
    "videofile_path = glob.glob('/home/wei-chan/Documents/Thesis/src/annotation/data/Tag4/*.mp4')\n",
    "deeplabcut.extract_outlier_frames(path_config_file, \n",
    "                                  videofile_path,\n",
    "                                  comparisonbodyparts = ['hoofFL','hoofFR','hoofHL', 'hoofHR'], \n",
    "                                  epsilon = 5, \n",
    "                                  p_bound = 0.2,\n",
    "                                  extractionalgorithm = 'kmeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow1\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow24\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow160\n",
      "Checking labels if they are outside the image\n",
      "Found head outside the image labeled-data/cow160/img179.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow160/img180.png.Setting it to NaN\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow274\n",
      "Checking labels if they are outside the image\n",
      "Found head outside the image labeled-data/cow274/img151.png.Setting it to NaN\n",
      "Found hoofFR outside the image labeled-data/cow274/img151.png.Setting it to NaN\n",
      "Found hoofHL outside the image labeled-data/cow274/img151.png.Setting it to NaN\n",
      "Found hoofHR outside the image labeled-data/cow274/img151.png.Setting it to NaN\n",
      "Found back1 outside the image labeled-data/cow274/img062.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img062.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img027.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img024.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img137.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img016.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img129.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img044.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img044.png.Setting it to NaN\n",
      "Found back1 outside the image labeled-data/cow274/img044.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img075.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img056.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img031.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img006.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img135.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img022.png.Setting it to NaN\n",
      "Found back1 outside the image labeled-data/cow274/img041.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img017.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img017.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img110.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img059.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img059.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img114.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img085.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img065.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img065.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img055.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img025.png.Setting it to NaN\n",
      "Found hoofFR outside the image labeled-data/cow274/img149.png.Setting it to NaN\n",
      "Found hoofHL outside the image labeled-data/cow274/img149.png.Setting it to NaN\n",
      "Found hoofHR outside the image labeled-data/cow274/img149.png.Setting it to NaN\n",
      "Found withers outside the image labeled-data/cow274/img034.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img018.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img066.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img066.png.Setting it to NaN\n",
      "Found back1 outside the image labeled-data/cow274/img073.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img073.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img047.png.Setting it to NaN\n",
      "Found withers outside the image labeled-data/cow274/img047.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img019.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img134.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img050.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img147.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img015.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img015.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img143.png.Setting it to NaN\n",
      "Found hoofFR outside the image labeled-data/cow274/img143.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img028.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img083.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img083.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img003.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img003.png.Setting it to NaN\n",
      "Found back1 outside the image labeled-data/cow274/img064.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img064.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img064.png.Setting it to NaN\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow274\n",
      "Checking labels if they are outside the image\n",
      "Found head outside the image labeled-data/cow274/img151.png.Setting it to NaN\n",
      "Found hoofFR outside the image labeled-data/cow274/img151.png.Setting it to NaN\n",
      "Found hoofHL outside the image labeled-data/cow274/img151.png.Setting it to NaN\n",
      "Found hoofHR outside the image labeled-data/cow274/img151.png.Setting it to NaN\n",
      "Found back1 outside the image labeled-data/cow274/img062.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img062.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img027.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img024.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img137.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img016.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img129.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img044.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img044.png.Setting it to NaN\n",
      "Found back1 outside the image labeled-data/cow274/img044.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img075.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img056.png.Setting it to NaN\n",
      "Found hoofFR outside the image labeled-data/cow274/img145.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img022.png.Setting it to NaN\n",
      "Found back1 outside the image labeled-data/cow274/img041.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img017.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img017.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img110.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img059.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img059.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img114.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img085.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img065.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img065.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img055.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img025.png.Setting it to NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found hoofFL outside the image labeled-data/cow274/img149.png.Setting it to NaN\n",
      "Found hoofFR outside the image labeled-data/cow274/img149.png.Setting it to NaN\n",
      "Found hoofHL outside the image labeled-data/cow274/img149.png.Setting it to NaN\n",
      "Found hoofHR outside the image labeled-data/cow274/img149.png.Setting it to NaN\n",
      "Found withers outside the image labeled-data/cow274/img034.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img018.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img066.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img066.png.Setting it to NaN\n",
      "Found back1 outside the image labeled-data/cow274/img073.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img073.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img047.png.Setting it to NaN\n",
      "Found withers outside the image labeled-data/cow274/img047.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img019.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img050.png.Setting it to NaN\n",
      "Found head outside the image labeled-data/cow274/img015.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img015.png.Setting it to NaN\n",
      "Found hoofFR outside the image labeled-data/cow274/img143.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img028.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img083.png.Setting it to NaN\n",
      "Found neck outside the image labeled-data/cow274/img003.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img003.png.Setting it to NaN\n",
      "Found back1 outside the image labeled-data/cow274/img064.png.Setting it to NaN\n",
      "Found back2 outside the image labeled-data/cow274/img064.png.Setting it to NaN\n",
      "Found back3 outside the image labeled-data/cow274/img064.png.Setting it to NaN\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 2.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "#Once all folders are relabeled, check them and advance. See how to check labels, above!\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refine labels, append these frames to the original dataset to create a new iteration of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by FKIE.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow1_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow1_labeled.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow1403_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow1403_labeled.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow155_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow155_labeled.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow160_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow160_labeled.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow161_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow161_labeled.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow220_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow220_labeled.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow233_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow233_labeled.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow24_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow24_labeled.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow254_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow254_labeled.\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow274_labeled  already exists!\n",
      "They are stored in the following folder: /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/labeled-data/cow274_labeled.\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "#Perhaps plot the labels to see how how all the frames are annoted (including the refined ones)\n",
    "deeplabcut.check_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/training-datasets/iteration-2/UnaugmentedDataSet_Cow_labelingJan2  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1//train  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1//test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now one can train the network again... (with the expanded data set)\n",
    "\n",
    "Default 'max_snapshots_to_keep = 5' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'dataset_type': 'default', 'use_gt_segm': False, 'batch_size': 1, 'video': False, 'video_batch': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]], 'all_joints_names': ['head', 'neck', 'withers', 'back1', 'back2', 'back3', 'hoofFL', 'hoofFR', 'hoofHL', 'hoofHR'], 'dataset': 'training-datasets/iteration-2/UnaugmentedDataSet_Cow_labelingJan2/Cow_labeling_FKIE90shuffle1.mat', 'display_iters': 1000, 'init_weights': '/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-1/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000', 'max_input_size': 1000, 'metadataset': 'training-datasets/iteration-2/UnaugmentedDataSet_Cow_labelingJan2/Documentation_data-Cow_labeling_90shuffle1.pickle', 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 10, 'pos_dist_thresh': 17, 'project_path': '/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02', 'save_iters': 1000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0dc5cb6e2491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgputouse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, gputouse, max_snapshots_to_keep, autotune, displayiters, saveiters, maxiters)\u001b[0m\n\u001b[1;32m     79\u001b[0m           \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m           \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, gputouse, max_snapshots_to_keep, autotune, displayiters, saveiters, maxiters)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m           \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         [_, loss_val, summary] = sess.run([train_op, total_loss, merged_summaries],\n\u001b[0;32m--> 142\u001b[0;31m                                           feed_dict={learning_rate: current_lr})\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wei-chan/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file, gputouse=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/evaluation-results/  already exists!\n",
      "Running  DeepCut_resnet50_Cow_labelingJan2shuffle1_30000  with # of trainingiterations: 30000\n",
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "439it [00:30, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-30000\n",
      "Results for 30000  training iterations: 90 1 train error: 3.9 pixels. Test error: 5.28  pixels.\n",
      "With pcutoff of 0.1  train error: 3.89 pixels. Test error: 5.04 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-30000 for model /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1\n",
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "Restoring parameters from /home/wei-chan/Documents/Thesis/src/annotation/Cow_labeling-FKIE-2019-01-02/dlc-models/iteration-2/Cow_labelingJan2-trainset90shuffle1/train/snapshot-30000\n",
      "  0%|          | 0/138 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4\n",
      "Duration of video [s]:  6.9 , recorded with  20.0 fps!\n",
      "Overall # of frames:  138 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:05, 24.07it/s]                         \n",
      "  0%|          | 0/126 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  138\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4\n",
      "Duration of video [s]:  6.3 , recorded with  20.0 fps!\n",
      "Overall # of frames:  126 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130it [00:05, 22.66it/s]                         \n",
      "  0%|          | 0/173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  126\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4\n",
      "Duration of video [s]:  8.65 , recorded with  20.0 fps!\n",
      "Overall # of frames:  173 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [00:07, 23.96it/s]                         \n",
      "  0%|          | 0/218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  173\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4\n",
      "Duration of video [s]:  10.9 , recorded with  20.0 fps!\n",
      "Overall # of frames:  218 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [00:09, 23.69it/s]                         \n",
      "  0%|          | 0/166 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  218\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4\n",
      "Duration of video [s]:  8.3 , recorded with  20.0 fps!\n",
      "Overall # of frames:  166 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [00:07, 22.24it/s]                         \n",
      "  0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  166\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4\n",
      "Duration of video [s]:  10.75 , recorded with  20.0 fps!\n",
      "Overall # of frames:  215 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [00:09, 23.56it/s]                         \n",
      "  0%|          | 0/135 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  215\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4\n",
      "Duration of video [s]:  6.75 , recorded with  20.0 fps!\n",
      "Overall # of frames:  135 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:05, 23.74it/s]                         \n",
      "  0%|          | 0/186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  135\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4\n",
      "Duration of video [s]:  9.3 , recorded with  20.0 fps!\n",
      "Overall # of frames:  186 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "190it [00:08, 21.63it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  186\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]:  7.8 , recorded with  20.0 fps!\n",
      "Overall # of frames:  156 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:06, 22.09it/s]                         \n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  156\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5...\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4\n",
      "Duration of video [s]:  6.7 , recorded with  20.0 fps!\n",
      "Overall # of frames:  134 without cropped frame dimensions:  680 420\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:06, 21.67it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  134\n",
      "Saving results in /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter the list of videos to analyze.\n",
    "videofile_path = glob.glob('/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/*.mp4')\n",
    "deeplabcut.analyze_videos(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/138 [00:00<00:05, 23.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4 and data.\n",
      "False 0 680 0 420\n",
      "138\n",
      "Duration of video [s]:  6.9 , recorded with  20.0 fps!\n",
      "Overall # of frames:  138 with cropped frame dimensions:  680 420\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [00:05<00:00, 27.03it/s]\n",
      "  2%|▏         | 3/126 [00:00<00:04, 25.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4 and data.\n",
      "False 0 680 0 420\n",
      "126\n",
      "Duration of video [s]:  6.3 , recorded with  20.0 fps!\n",
      "Overall # of frames:  126 with cropped frame dimensions:  680 420\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:04<00:00, 29.13it/s]\n",
      "  2%|▏         | 3/173 [00:00<00:06, 25.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4 and data.\n",
      "False 0 680 0 420\n",
      "173\n",
      "Duration of video [s]:  8.65 , recorded with  20.0 fps!\n",
      "Overall # of frames:  173 with cropped frame dimensions:  680 420\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:05<00:00, 28.92it/s]\n",
      "  1%|▏         | 3/218 [00:00<00:08, 25.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4 and data.\n",
      "False 0 680 0 420\n",
      "218\n",
      "Duration of video [s]:  10.9 , recorded with  20.0 fps!\n",
      "Overall # of frames:  218 with cropped frame dimensions:  680 420\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:07<00:00, 28.76it/s]\n",
      "  2%|▏         | 3/166 [00:00<00:05, 27.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4 and data.\n",
      "False 0 680 0 420\n",
      "166\n",
      "Duration of video [s]:  8.3 , recorded with  20.0 fps!\n",
      "Overall # of frames:  166 with cropped frame dimensions:  680 420\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:05<00:00, 29.96it/s]\n",
      "  1%|▏         | 3/215 [00:00<00:08, 26.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4 and data.\n",
      "False 0 680 0 420\n",
      "215\n",
      "Duration of video [s]:  10.75 , recorded with  20.0 fps!\n",
      "Overall # of frames:  215 with cropped frame dimensions:  680 420\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:07<00:00, 29.26it/s]\n",
      "  2%|▏         | 3/135 [00:00<00:05, 25.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4 and data.\n",
      "False 0 680 0 420\n",
      "135\n",
      "Duration of video [s]:  6.75 , recorded with  20.0 fps!\n",
      "Overall # of frames:  135 with cropped frame dimensions:  680 420\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:04<00:00, 29.07it/s]\n",
      "  2%|▏         | 3/186 [00:00<00:07, 25.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4 and data.\n",
      "False 0 680 0 420\n",
      "186\n",
      "Duration of video [s]:  9.3 , recorded with  20.0 fps!\n",
      "Overall # of frames:  186 with cropped frame dimensions:  680 420\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [00:06<00:00, 29.45it/s]\n",
      "  2%|▏         | 3/156 [00:00<00:06, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4 and data.\n",
      "False 0 680 0 420\n",
      "156\n",
      "Duration of video [s]:  7.8 , recorded with  20.0 fps!\n",
      "Overall # of frames:  156 with cropped frame dimensions:  680 420\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:05<00:00, 28.26it/s]\n",
      "  2%|▏         | 3/134 [00:00<00:04, 27.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4 and data.\n",
      "False 0 680 0 420\n",
      "134\n",
      "Duration of video [s]:  6.7 , recorded with  20.0 fps!\n",
      "Overall # of frames:  134 with cropped frame dimensions:  680 420\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:04<00:00, 30.13it/s]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file, videofile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5  already exists!\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/plot-poses  already exists!\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/plot-poses  already exists!\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/plot-poses  already exists!\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/plot-poses  already exists!\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/plot-poses  already exists!\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/plot-poses  already exists!\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/plot-poses  already exists!\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4 and data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/plot-poses  already exists!\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4\n",
      "Starting %  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5 ['/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow274.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow160.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow161.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow24.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow220.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow1403.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow155.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow233.mp4', '/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4']\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5  already exists!\n",
      "/home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/plot-poses  already exists!\n",
      "Loading  /home/wei-chan/Documents/Thesis/src/annotation/data/Tag5/cow254.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib notebook #for making interactive plots.\n",
    "%matplotlib inline\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
