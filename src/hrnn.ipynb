{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchsummary\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from torchsummary import summary\n",
    "\n",
    "import time\n",
    "import os, glob\n",
    "import cv2\n",
    "import copy\n",
    "from os.path import join, isdir\n",
    "import random\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.append('/home/wei-chan.hsu/Dokumente/Lameness-Detection/utils')  \n",
    "from auxiliaryfunctions import classify, tag_loc, copy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before shuffle:  ['cow239-3.json', 'cow1-14.json', 'cow1407-6.json', 'cow1407-1.json', 'cow161-0.json']\n",
      "After shuffle:  ['cow155-3.json', 'cow284-1.json', 'cow202-14.json', 'cow181-4.json', 'cow181-7.json']\n"
     ]
    }
   ],
   "source": [
    "# Shuffle dataset\n",
    "datadir = '/home/wei-chan.hsu/Dokumente/Thesis/src/annotation/data/all2/data_json/'\n",
    "all_files = os.listdir(os.path.abspath(datadir))\n",
    "data_files = list(filter(lambda file: file.endswith('.json'), all_files))\n",
    "\n",
    "print(\"Before shuffle: \", data_files[:5])\n",
    "random.shuffle(data_files)\n",
    "print(\"After shuffle: \", data_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (320 samples):  ['cow155-3.json', 'cow284-1.json', 'cow202-14.json', 'cow181-4.json', 'cow181-7.json']\n",
      "Validation set (80 samples):  ['cow160-7.json', 'cow287-5.json', 'cow204-1.json', 'cow234-3.json', 'cow285-6.json']\n",
      "Test set (101 samples):  ['cow253-3.json', 'cow257-6.json', 'cow191-3.json', 'cow285-1.json', 'cow234-7.json']\n"
     ]
    }
   ],
   "source": [
    "# Split data into two sets\n",
    "split_ratio = 0.8\n",
    "split_tt = int(split_ratio * len(data_files))\n",
    "training_set = data_files[:split_tt]\n",
    "test_set = data_files[split_tt:]\n",
    "split_tv = int(split_ratio * len(training_set))\n",
    "val_set = training_set[split_tv:]\n",
    "training_set = training_set = data_files[:split_tt][:split_tv]\n",
    "\n",
    "\n",
    "print(\"Training set ({} samples): \".format(len(training_set)), training_set[:5])\n",
    "print(\"Validation set ({} samples): \".format(len(val_set)), val_set[:5])\n",
    "print(\"Test set ({} samples): \".format(len(test_set)), test_set[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy png files into directories \n",
    "src_train = [(datadir + file) for file in training_set]\n",
    "src_val = [(datadir + file) for file in val_set]\n",
    "src_test = [(datadir + file) for file in test_set]\n",
    "dst_train = '/home/wei-chan.hsu/Dokumente/Thesis/src/lstm/data/train/'\n",
    "dst_val = '/home/wei-chan.hsu/Dokumente/Thesis/src/lstm/data/val/'\n",
    "dst_test = '/home/wei-chan.hsu/Dokumente/Thesis/src/lstm/data/test/'\n",
    "\n",
    "copy_files(src_train, dst_train)\n",
    "copy_files(src_val, dst_val)\n",
    "copy_files(src_test, dst_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkeletonDataset(Dataset):\n",
    "    # subset can be: 'train', 'val', 'test'\n",
    "    def __init__(self, data_dir, csv_file):\n",
    "        super(SkeletonDataset, self).__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.files = glob.glob(os.path.join(data_dir, '*.json'))\n",
    "        self.label_table = pd.read_csv(csv_file)\n",
    "        self.classes = [0,1,2,3]       \n",
    "        self.num_sequences = 20\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        poses = []\n",
    "        cow = os.path.basename(self.files[index]).split('.')[0]\n",
    "        cow_id = cow.split('-')[0]\n",
    "        tag = cow.split('-')[1]\n",
    "        label = classify(self.label_table[(self.label_table['cow_id'] == cow_id)].iloc[0, tag_loc(int(tag))]) - 1\n",
    "        \n",
    "        #'''\n",
    "        with open(self.files[index]) as json_file:  \n",
    "            data = json.load(json_file)\n",
    "            for frame in data['data']:\n",
    "                num_frame = frame['frame_index'] - 1\n",
    "                skeleton = frame['skeleton'][0]\n",
    "                pose = np.array(skeleton['pose'])\n",
    "                x_channel = pose[0::2]\n",
    "                y_channel = pose[1::2]\n",
    "                if num_frame < self.num_sequences:\n",
    "                    poses.append(pose)\n",
    "                \n",
    "        #'''\n",
    "        poses = np.array(poses)\n",
    "        sample = {'seq': poses, 'label': label}\n",
    "             \n",
    "        return cow, sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "cow239-3 with LS: 0\n",
      "cow1-14 with LS: 3\n",
      "cow1407-6 with LS: 1\n",
      "cow1407-1 with LS: 1\n",
      "cow161-0 with LS: 3\n",
      "cow240-14 with LS: 1\n",
      "cow234-5 with LS: 1\n",
      "cow248-7 with LS: 1\n",
      "cow285-3 with LS: 0\n",
      "cow205-6 with LS: 2\n",
      "cow272-2 with LS: 0\n",
      "cow1407-3 with LS: 1\n",
      "cow161-7 with LS: 2\n",
      "cow69-0 with LS: 3\n",
      "cow202-2 with LS: 3\n",
      "cow277-1 with LS: 0\n",
      "cow215-1 with LS: 2\n",
      "cow1403-4 with LS: 3\n",
      "cow257-1 with LS: 0\n",
      "cow1406-0 with LS: 1\n",
      "cow287-14 with LS: 1\n",
      "cow257-4 with LS: 0\n",
      "cow215-14 with LS: 2\n",
      "cow262-7 with LS: 1\n",
      "cow1-0 with LS: 3\n",
      "cow285-0 with LS: 1\n",
      "cow254-7 with LS: 0\n",
      "cow160-5 with LS: 1\n",
      "cow160-1 with LS: 1\n",
      "cow248-1 with LS: 0\n",
      "cow224-1 with LS: 1\n",
      "cow254-14 with LS: 0\n",
      "cow199-3 with LS: 1\n",
      "cow217-0 with LS: 0\n",
      "cow239-1 with LS: 0\n",
      "cow234-14 with LS: 1\n",
      "cow1412-7 with LS: 0\n",
      "cow277-6 with LS: 0\n",
      "cow1406-5 with LS: 0\n",
      "cow1403-14 with LS: 3\n",
      "cow56-5 with LS: 1\n",
      "cow276-14 with LS: 1\n",
      "cow220-6 with LS: 3\n",
      "cow284-14 with LS: 0\n",
      "cow239-7 with LS: 0\n",
      "cow1-1 with LS: 3\n",
      "cow253-0 with LS: 0\n",
      "cow205-14 with LS: 2\n",
      "cow183-4 with LS: 1\n",
      "cow1407-14 with LS: 1\n",
      "cow287-1 with LS: 0\n",
      "cow285-1 with LS: 0\n",
      "cow276-0 with LS: 0\n",
      "cow216-5 with LS: 3\n",
      "cow287-3 with LS: 0\n",
      "cow274-1 with LS: 1\n",
      "cow264-0 with LS: 1\n",
      "cow80-7 with LS: 3\n",
      "cow276-3 with LS: 0\n",
      "cow199-1 with LS: 1\n",
      "cow1-5 with LS: 3\n",
      "cow268-0 with LS: 0\n",
      "cow181-6 with LS: 3\n",
      "cow257-5 with LS: 0\n",
      "cow208-0 with LS: 2\n",
      "cow253-4 with LS: 1\n",
      "cow201-14 with LS: 2\n",
      "cow224-2 with LS: 1\n",
      "cow262-6 with LS: 1\n",
      "cow277-5 with LS: 0\n",
      "cow204-14 with LS: 1\n",
      "cow254-5 with LS: 0\n",
      "cow1414-14 with LS: 0\n",
      "cow205-2 with LS: 2\n",
      "cow1406-1 with LS: 0\n",
      "cow224-3 with LS: 1\n",
      "cow24-2 with LS: 1\n",
      "cow234-1 with LS: 1\n",
      "cow80-0 with LS: 2\n",
      "cow267-14 with LS: 0\n",
      "cow276-7 with LS: 1\n",
      "cow80-14 with LS: 3\n",
      "cow160-14 with LS: 2\n",
      "cow201-0 with LS: 1\n",
      "cow1407-4 with LS: 1\n",
      "cow69-2 with LS: 3\n",
      "cow262-14 with LS: 1\n",
      "cow1-4 with LS: 3\n",
      "cow243-3 with LS: 2\n",
      "cow272-1 with LS: 0\n",
      "cow264-3 with LS: 1\n",
      "cow276-1 with LS: 0\n",
      "cow54-5 with LS: 3\n",
      "cow284-7 with LS: 0\n",
      "cow1413-14 with LS: 0\n",
      "cow217-6 with LS: 0\n",
      "cow243-14 with LS: 3\n",
      "cow155-6 with LS: 1\n",
      "cow274-2 with LS: 1\n",
      "cow208-4 with LS: 2\n",
      "cow278-5 with LS: 0\n",
      "cow171-7 with LS: 0\n",
      "cow233-2 with LS: 1\n",
      "cow277-4 with LS: 0\n",
      "cow1407-2 with LS: 1\n",
      "cow1412-14 with LS: 0\n",
      "cow1403-6 with LS: 3\n",
      "cow277-14 with LS: 0\n",
      "cow272-14 with LS: 0\n",
      "cow278-4 with LS: 0\n",
      "cow204-0 with LS: 1\n",
      "cow1413-1 with LS: 0\n",
      "cow264-1 with LS: 1\n",
      "cow1404-0 with LS: 0\n",
      "cow1408-0 with LS: 0\n",
      "cow278-7 with LS: 1\n",
      "cow216-14 with LS: 3\n",
      "cow155-7 with LS: 2\n",
      "cow254-0 with LS: 0\n",
      "cow273-5 with LS: 0\n",
      "cow280-0 with LS: 0\n",
      "cow210-3 with LS: 0\n",
      "cow190-1 with LS: 1\n",
      "cow240-3 with LS: 0\n",
      "cow278-2 with LS: 0\n",
      "cow233-1 with LS: 1\n",
      "cow277-0 with LS: 1\n",
      "cow24-5 with LS: 1\n",
      "cow1403-1 with LS: 3\n",
      "cow1408-14 with LS: 0\n",
      "cow190-0 with LS: 2\n",
      "cow254-1 with LS: 0\n",
      "cow80-5 with LS: 2\n",
      "cow267-4 with LS: 0\n",
      "cow56-3 with LS: 1\n",
      "cow267-3 with LS: 0\n",
      "cow239-6 with LS: 0\n",
      "cow181-7 with LS: 3\n",
      "cow210-0 with LS: 0\n",
      "cow205-0 with LS: 2\n",
      "cow233-4 with LS: 1\n",
      "cow280-6 with LS: 0\n",
      "cow253-1 with LS: 0\n",
      "cow56-1 with LS: 1\n",
      "cow234-0 with LS: 2\n",
      "cow204-4 with LS: 1\n",
      "cow80-2 with LS: 2\n",
      "cow1413-6 with LS: 0\n",
      "cow212-1 with LS: 1\n",
      "cow262-0 with LS: 1\n",
      "cow212-6 with LS: 1\n",
      "cow264-2 with LS: 1\n",
      "cow276-4 with LS: 0\n",
      "cow202-0 with LS: 3\n",
      "cow237-5 with LS: 2\n",
      "cow287-5 with LS: 0\n",
      "cow257-6 with LS: 0\n",
      "cow204-2 with LS: 1\n",
      "cow253-2 with LS: 0\n",
      "cow248-5 with LS: 0\n",
      "cow267-2 with LS: 0\n",
      "cow217-2 with LS: 0\n",
      "cow155-2 with LS: 1\n",
      "cow54-14 with LS: 3\n",
      "cow161-4 with LS: 2\n",
      "cow284-4 with LS: 0\n",
      "cow254-2 with LS: 0\n",
      "cow257-2 with LS: 0\n",
      "cow80-6 with LS: 2\n",
      "cow276-2 with LS: 0\n",
      "cow257-7 with LS: 0\n",
      "cow243-0 with LS: 2\n",
      "cow280-3 with LS: 0\n",
      "cow284-3 with LS: 0\n",
      "cow190-6 with LS: 1\n",
      "cow272-6 with LS: 0\n",
      "cow1408-4 with LS: 0\n",
      "cow190-5 with LS: 1\n",
      "cow215-3 with LS: 2\n",
      "cow210-6 with LS: 0\n",
      "cow224-14 with LS: 2\n",
      "cow191-5 with LS: 2\n",
      "cow205-4 with LS: 2\n",
      "cow181-1 with LS: 3\n",
      "cow220-5 with LS: 3\n",
      "cow1413-2 with LS: 0\n",
      "cow254-6 with LS: 0\n",
      "cow224-0 with LS: 1\n",
      "cow181-5 with LS: 3\n",
      "cow161-2 with LS: 2\n",
      "cow1403-2 with LS: 3\n",
      "cow202-1 with LS: 3\n",
      "cow248-6 with LS: 0\n",
      "cow217-3 with LS: 0\n",
      "cow272-7 with LS: 0\n",
      "cow239-0 with LS: 0\n",
      "cow1404-7 with LS: 0\n",
      "cow1403-5 with LS: 3\n",
      "cow215-2 with LS: 2\n",
      "cow201-4 with LS: 1\n",
      "cow208-1 with LS: 2\n",
      "cow267-1 with LS: 0\n",
      "cow262-4 with LS: 1\n",
      "cow160-6 with LS: 1\n",
      "cow253-5 with LS: 1\n",
      "cow272-5 with LS: 0\n",
      "cow183-3 with LS: 0\n",
      "cow285-14 with LS: 0\n",
      "cow183-6 with LS: 1\n",
      "cow285-4 with LS: 0\n",
      "cow54-2 with LS: 3\n",
      "cow220-4 with LS: 3\n",
      "cow215-0 with LS: 2\n",
      "cow234-3 with LS: 1\n",
      "cow1406-6 with LS: 0\n",
      "cow1-7 with LS: 3\n",
      "cow215-7 with LS: 2\n",
      "cow223-1 with LS: 0\n",
      "cow1412-2 with LS: 0\n",
      "cow274-4 with LS: 1\n",
      "cow190-14 with LS: 1\n",
      "cow243-5 with LS: 2\n",
      "cow1407-7 with LS: 1\n",
      "cow183-14 with LS: 2\n",
      "cow1-3 with LS: 3\n",
      "cow199-7 with LS: 1\n",
      "cow161-1 with LS: 2\n",
      "cow54-4 with LS: 3\n",
      "cow54-6 with LS: 3\n",
      "cow210-14 with LS: 1\n",
      "cow254-4 with LS: 0\n",
      "cow248-4 with LS: 0\n",
      "cow216-7 with LS: 3\n",
      "cow1412-0 with LS: 0\n",
      "cow1404-3 with LS: 0\n",
      "cow217-1 with LS: 0\n",
      "cow1413-7 with LS: 0\n",
      "cow1412-3 with LS: 0\n",
      "cow240-6 with LS: 0\n",
      "cow233-6 with LS: 1\n",
      "cow280-4 with LS: 0\n",
      "cow155-0 with LS: 1\n",
      "cow237-3 with LS: 2\n",
      "cow285-6 with LS: 0\n",
      "cow199-6 with LS: 1\n",
      "cow248-2 with LS: 0\n",
      "cow284-2 with LS: 0\n",
      "cow267-5 with LS: 0\n",
      "cow54-3 with LS: 3\n",
      "cow237-1 with LS: 2\n",
      "cow243-6 with LS: 2\n",
      "cow234-2 with LS: 1\n",
      "cow208-6 with LS: 2\n",
      "cow201-7 with LS: 2\n",
      "cow210-4 with LS: 0\n",
      "cow274-7 with LS: 1\n",
      "cow190-4 with LS: 1\n",
      "cow216-6 with LS: 3\n",
      "cow202-3 with LS: 3\n",
      "cow24-1 with LS: 1\n",
      "cow202-7 with LS: 3\n",
      "cow1409-5 with LS: 0\n",
      "cow278-3 with LS: 0\n",
      "cow202-14 with LS: 3\n",
      "cow171-5 with LS: 0\n",
      "cow202-6 with LS: 3\n",
      "cow239-14 with LS: 0\n",
      "cow212-7 with LS: 1\n",
      "cow267-0 with LS: 0\n",
      "cow1408-3 with LS: 0\n",
      "cow1408-2 with LS: 0\n",
      "cow280-7 with LS: 1\n",
      "cow171-6 with LS: 0\n",
      "cow181-2 with LS: 3\n",
      "cow202-5 with LS: 3\n",
      "cow24-14 with LS: 2\n",
      "cow224-7 with LS: 2\n",
      "cow54-1 with LS: 3\n",
      "cow280-5 with LS: 0\n",
      "cow212-14 with LS: 1\n",
      "cow1404-4 with LS: 0\n",
      "cow287-6 with LS: 0\n",
      "cow56-14 with LS: 2\n",
      "cow171-2 with LS: 0\n",
      "cow274-3 with LS: 1\n",
      "cow240-0 with LS: 0\n",
      "cow205-5 with LS: 2\n",
      "cow262-2 with LS: 1\n",
      "cow161-6 with LS: 2\n",
      "cow1406-14 with LS: 0\n",
      "cow199-14 with LS: 1\n",
      "cow155-4 with LS: 1\n",
      "cow210-7 with LS: 1\n",
      "cow80-3 with LS: 2\n",
      "cow285-7 with LS: 0\n",
      "cow161-3 with LS: 2\n",
      "cow1414-3 with LS: 0\n",
      "cow1408-6 with LS: 0\n",
      "cow1-6 with LS: 3\n",
      "cow1402-14 with LS: 0\n",
      "cow69-1 with LS: 3\n",
      "cow161-5 with LS: 2\n",
      "cow265-0 with LS: 0\n",
      "cow191-6 with LS: 2\n",
      "cow237-2 with LS: 2\n",
      "cow181-4 with LS: 3\n",
      "cow1409-6 with LS: 0\n",
      "cow267-7 with LS: 0\n",
      "cow285-5 with LS: 0\n",
      "cow273-6 with LS: 0\n",
      "cow280-14 with LS: 1\n",
      "cow224-4 with LS: 1\n",
      "cow274-0 with LS: 1\n",
      "cow285-2 with LS: 0\n",
      "cow212-3 with LS: 1\n",
      "cow253-7 with LS: 2\n",
      "cow272-3 with LS: 0\n",
      "cow280-2 with LS: 0\n",
      "cow1404-1 with LS: 0\n",
      "cow272-4 with LS: 0\n",
      "cow191-1 with LS: 1\n",
      "cow233-3 with LS: 1\n",
      "cow208-3 with LS: 2\n",
      "cow273-4 with LS: 0\n",
      "cow248-14 with LS: 1\n",
      "cow276-5 with LS: 0\n",
      "cow274-6 with LS: 1\n",
      "cow80-4 with LS: 2\n",
      "cow171-1 with LS: 0\n",
      "cow155-3 with LS: 1\n",
      "cow1413-4 with LS: 0\n",
      "cow56-7 with LS: 2\n",
      "cow1403-3 with LS: 3\n",
      "cow202-4 with LS: 3\n",
      "cow220-1 with LS: 3\n",
      "cow215-4 with LS: 2\n",
      "cow287-7 with LS: 1\n",
      "cow171-0 with LS: 1\n",
      "cow155-5 with LS: 1\n",
      "cow273-3 with LS: 0\n",
      "cow273-1 with LS: 0\n",
      "cow243-4 with LS: 2\n",
      "cow284-1 with LS: 0\n",
      "cow262-5 with LS: 1\n",
      "cow1409-0 with LS: 1\n",
      "cow205-3 with LS: 2\n",
      "cow199-2 with LS: 1\n",
      "cow1406-3 with LS: 0\n",
      "cow274-5 with LS: 1\n",
      "cow1406-4 with LS: 0\n",
      "cow1406-2 with LS: 0\n",
      "cow199-5 with LS: 1\n",
      "cow24-4 with LS: 1\n",
      "cow1414-6 with LS: 0\n",
      "cow233-7 with LS: 2\n",
      "cow264-7 with LS: 1\n",
      "cow191-3 with LS: 1\n",
      "cow1414-5 with LS: 0\n",
      "cow239-4 with LS: 0\n",
      "cow1408-5 with LS: 0\n",
      "cow264-6 with LS: 1\n",
      "cow273-0 with LS: 0\n",
      "cow171-3 with LS: 0\n",
      "cow248-0 with LS: 0\n",
      "cow1412-4 with LS: 0\n",
      "cow240-4 with LS: 0\n",
      "cow56-4 with LS: 1\n",
      "cow217-5 with LS: 0\n",
      "cow155-14 with LS: 2\n",
      "cow273-7 with LS: 1\n",
      "cow240-1 with LS: 0\n",
      "cow287-0 with LS: 0\n",
      "cow287-2 with LS: 0\n",
      "cow210-1 with LS: 0\n",
      "cow212-2 with LS: 1\n",
      "cow240-5 with LS: 0\n",
      "cow1414-4 with LS: 0\n",
      "cow201-6 with LS: 1\n",
      "cow253-6 with LS: 1\n",
      "cow1409-2 with LS: 0\n",
      "cow243-2 with LS: 2\n",
      "cow234-7 with LS: 1\n",
      "cow1403-7 with LS: 3\n",
      "cow199-4 with LS: 1\n",
      "cow215-6 with LS: 2\n",
      "cow1409-4 with LS: 0\n",
      "cow190-2 with LS: 1\n",
      "cow183-1 with LS: 0\n",
      "cow205-7 with LS: 2\n",
      "cow1413-3 with LS: 0\n",
      "cow237-4 with LS: 2\n",
      "cow262-1 with LS: 1\n",
      "cow1409-7 with LS: 0\n",
      "cow160-4 with LS: 1\n",
      "cow1408-7 with LS: 0\n",
      "cow210-5 with LS: 0\n",
      "cow253-3 with LS: 0\n",
      "cow248-3 with LS: 0\n",
      "cow217-7 with LS: 1\n",
      "cow1407-5 with LS: 1\n",
      "cow160-7 with LS: 2\n",
      "cow253-14 with LS: 2\n",
      "cow284-0 with LS: 0\n",
      "cow199-0 with LS: 1\n",
      "cow171-4 with LS: 0\n",
      "cow267-6 with LS: 0\n",
      "cow237-14 with LS: 2\n",
      "cow204-3 with LS: 1\n",
      "cow208-14 with LS: 3\n",
      "cow208-5 with LS: 2\n",
      "cow240-7 with LS: 1\n",
      "cow1409-3 with LS: 0\n",
      "cow277-3 with LS: 0\n",
      "cow274-14 with LS: 1\n",
      "cow278-6 with LS: 0\n",
      "cow1-2 with LS: 3\n",
      "cow204-6 with LS: 1\n",
      "cow54-7 with LS: 3\n",
      "cow204-5 with LS: 1\n",
      "cow210-2 with LS: 0\n",
      "cow264-5 with LS: 1\n",
      "cow191-4 with LS: 2\n",
      "cow243-1 with LS: 2\n",
      "cow224-6 with LS: 1\n",
      "cow1404-5 with LS: 0\n",
      "cow56-6 with LS: 1\n",
      "cow1413-5 with LS: 0\n",
      "cow257-14 with LS: 0\n",
      "cow190-7 with LS: 1\n",
      "cow24-3 with LS: 1\n",
      "cow239-2 with LS: 0\n",
      "cow1403-0 with LS: 3\n",
      "cow161-14 with LS: 2\n",
      "cow1406-7 with LS: 0\n",
      "cow212-5 with LS: 1\n",
      "cow201-3 with LS: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cow1404-6 with LS: 0\n",
      "cow280-1 with LS: 0\n",
      "cow273-14 with LS: 1\n",
      "cow217-4 with LS: 0\n",
      "cow191-2 with LS: 1\n",
      "cow1409-14 with LS: 0\n",
      "cow24-7 with LS: 2\n",
      "cow234-4 with LS: 1\n",
      "cow24-6 with LS: 1\n",
      "cow160-2 with LS: 1\n",
      "cow212-0 with LS: 1\n",
      "cow220-2 with LS: 3\n",
      "cow278-14 with LS: 1\n",
      "cow183-7 with LS: 2\n",
      "cow277-7 with LS: 0\n",
      "cow208-7 with LS: 3\n",
      "cow1412-6 with LS: 0\n",
      "cow201-2 with LS: 1\n",
      "cow220-3 with LS: 3\n",
      "cow191-14 with LS: 3\n",
      "cow201-5 with LS: 1\n",
      "cow208-2 with LS: 2\n",
      "cow204-1 with LS: 1\n",
      "cow155-1 with LS: 1\n",
      "cow220-7 with LS: 3\n",
      "cow284-5 with LS: 0\n",
      "cow276-6 with LS: 0\n",
      "cow240-2 with LS: 0\n",
      "cow254-3 with LS: 0\n",
      "cow277-2 with LS: 0\n",
      "cow181-0 with LS: 3\n",
      "cow1416-14 with LS: 0\n",
      "cow224-5 with LS: 1\n",
      "cow212-4 with LS: 1\n",
      "cow217-14 with LS: 1\n",
      "cow190-3 with LS: 1\n",
      "cow181-3 with LS: 3\n",
      "cow1404-2 with LS: 0\n",
      "cow220-14 with LS: 3\n",
      "cow215-5 with LS: 2\n",
      "cow160-3 with LS: 1\n",
      "cow201-1 with LS: 1\n",
      "cow243-7 with LS: 3\n",
      "cow1412-5 with LS: 0\n",
      "cow278-1 with LS: 0\n",
      "cow237-0 with LS: 0\n",
      "cow237-7 with LS: 2\n",
      "cow171-14 with LS: 0\n",
      "cow264-14 with LS: 1\n",
      "cow205-1 with LS: 2\n",
      "cow237-6 with LS: 2\n",
      "cow1408-1 with LS: 0\n",
      "cow183-5 with LS: 1\n",
      "cow191-7 with LS: 3\n",
      "cow257-3 with LS: 0\n",
      "cow287-4 with LS: 0\n",
      "cow204-7 with LS: 1\n",
      "cow233-5 with LS: 1\n",
      "cow56-2 with LS: 1\n",
      "cow239-5 with LS: 0\n",
      "cow264-4 with LS: 1\n",
      "cow1412-1 with LS: 0\n",
      "cow1414-7 with LS: 0\n",
      "cow1409-1 with LS: 0\n",
      "cow284-6 with LS: 0\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/wei-chan.hsu/Dokumente/Thesis/src/annotation/data/all2/data_json/'\n",
    "csv_file = '/home/wei-chan.hsu/Dokumente/Thesis/src/annotation/data_labels.csv'\n",
    "exset = SkeletonDataset(data_dir, csv_file)\n",
    "\n",
    "print(len(exset))\n",
    "for cow, sample in exset:\n",
    "    print('{} with LS: {}'.format(cow, sample['label']))\n",
    "    #print(len(sample['seq']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/wei-chan.hsu/Dokumente/Thesis/src/lstm/data/'\n",
    "batch_size = 16\n",
    "datasets = {x: SkeletonDataset(os.path.join(data_dir, x), csv_file) for x in ['train', 'val', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = datasets['train'].classes\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 320, 'val': 80, 'test': 101}\n",
      "\n",
      "<__main__.SkeletonDataset object at 0x7f00d2cb1d68>\n",
      "0\n",
      "('cow204-4', 'cow272-3', 'cow234-0', 'cow277-5', 'cow215-4', 'cow243-1', 'cow80-0', 'cow287-5', 'cow210-4', 'cow273-1', 'cow1409-0', 'cow1408-2', 'cow155-1', 'cow204-1', 'cow1413-2', 'cow1413-5')\n",
      "tensor([1, 0, 2, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0])\n",
      "torch.Size([16, 20, 50])\n",
      "1\n",
      "('cow1403-4', 'cow160-1', 'cow262-4', 'cow80-14', 'cow234-3', 'cow160-6', 'cow212-6', 'cow201-14', 'cow202-0', 'cow248-2', 'cow278-2', 'cow1408-0', 'cow267-3', 'cow287-7', 'cow161-14', 'cow267-4')\n",
      "tensor([3, 1, 1, 3, 1, 1, 1, 2, 3, 0, 0, 0, 0, 1, 2, 0])\n",
      "torch.Size([16, 20, 50])\n",
      "2\n",
      "('cow272-7', 'cow262-5', 'cow217-2', 'cow285-4', 'cow224-1', 'cow234-2', 'cow1-3', 'cow1404-0', 'cow274-3', 'cow240-1', 'cow243-4', 'cow56-14', 'cow277-14', 'cow257-4', 'cow215-7', 'cow171-3')\n",
      "tensor([0, 1, 0, 0, 1, 1, 3, 0, 1, 0, 2, 2, 0, 0, 2, 0])\n",
      "torch.Size([16, 20, 50])\n",
      "3\n",
      "('cow272-4', 'cow215-1', 'cow254-7', 'cow253-0', 'cow69-1', 'cow199-1', 'cow1403-3', 'cow234-1', 'cow253-6', 'cow233-5', 'cow208-1', 'cow56-7', 'cow56-3', 'cow212-14', 'cow210-2', 'cow248-14')\n",
      "tensor([0, 2, 0, 0, 3, 1, 3, 1, 1, 1, 2, 2, 1, 1, 0, 1])\n",
      "torch.Size([16, 20, 50])\n",
      "4\n",
      "('cow274-7', 'cow160-7', 'cow233-2', 'cow240-3', 'cow1-5', 'cow240-4', 'cow276-3', 'cow276-1', 'cow202-5', 'cow224-0', 'cow287-2', 'cow216-5', 'cow285-6', 'cow285-7', 'cow273-14', 'cow56-1')\n",
      "tensor([1, 2, 1, 0, 3, 0, 0, 0, 3, 1, 0, 3, 0, 0, 1, 1])\n",
      "torch.Size([16, 20, 50])\n",
      "torch.Size([50, 16, 20])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_sizes)\n",
    "print()\n",
    "print(dataloaders['train'].dataset)\n",
    "\n",
    "for i,  (cow, sample) in enumerate(dataloaders['val']):\n",
    "    print(i)\n",
    "    print(cow)\n",
    "    print(sample['label'])\n",
    "    print(sample['seq'].shape)\n",
    "    \n",
    "sample['seq'] = sample['seq'].reshape(50,batch_size,-1)\n",
    "print(sample['seq'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "class HRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_dim=4):\n",
    "        super(HRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        ''' Hierarchy '''\n",
    "        # BRNN 1 ========================================================================\n",
    "        # Head to neck: 0-2\n",
    "        self.rnn1 = nn.RNN(input_size=3*2, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        # Back: 3-8\n",
    "        self.rnn2 = nn.RNN(input_size=6*2, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        # FL leg: 9-12\n",
    "        self.rnn3 = nn.RNN(input_size=4*2, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        # FR leg: 13-16\n",
    "        self.rnn4 = nn.RNN(input_size=4*2, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        # RL leg: 17-20\n",
    "        self.rnn5 = nn.RNN(input_size=4*2, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        # RR leg: 21-24\n",
    "        self.rnn6 = nn.RNN(input_size=4*2, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        # BRNN 2 ========================================================================\n",
    "        self.rnn_l2 = nn.RNN(input_size=200, hidden_size=100, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        # BRNN 3 ========================================================================\n",
    "        self.rnn_l41 = nn.RNN(input_size=200, hidden_size=200, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        self.rnn_l42 = nn.RNN(input_size=800, hidden_size=200, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        # BRNN 4 ========================================================================\n",
    "        self.rnn_l6 = nn.LSTM(input_size=800, hidden_size=200, num_layers=num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.classify_layer = nn.Linear(2*200, output_dim)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print('Input: ',x)\n",
    "        #print(len(x), x.shape, x.dtype)\n",
    "        #output, hn = self.rnn(x.view(len(x), batch_size, -1))\n",
    "        #h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        #c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        #print('Input shape: ', x.shape, len(x))\n",
    "\n",
    "        out1, h1 = self.rnn1(x[:,:,:3*2])\n",
    "        out2, h2 = self.rnn2(x[:,:,3*2:9*2])\n",
    "        out3, h3 = self.rnn3(x[:,:,9*2:13*2])\n",
    "        out4, h4 = self.rnn4(x[:,:,13*2:17*2])\n",
    "        out5, h5 = self.rnn5(x[:,:,17*2:21*2])\n",
    "        out6, h6 = self.rnn6(x[:,:,21*2:])\n",
    "        # Layer 1 =======================================================================\n",
    "        out_layer11 = torch.cat((out1, out2), dim=2)\n",
    "        out_layer12 = torch.cat((out2, out3), dim=2)\n",
    "        out_layer13 = torch.cat((out2, out4), dim=2)\n",
    "        out_layer14 = torch.cat((out2, out5), dim=2)\n",
    "        out_layer15 = torch.cat((out2, out6), dim=2)\n",
    "        #print('L1: ', out_layer11.shape)\n",
    "        # Layer 2 =======================================================================\n",
    "        out_layer21, _ = self.rnn_l2(out_layer11)\n",
    "        out_layer22, _ = self.rnn_l2(out_layer12)\n",
    "        out_layer23, _ = self.rnn_l2(out_layer13)\n",
    "        out_layer24, _ = self.rnn_l2(out_layer14)\n",
    "        out_layer25, _ = self.rnn_l2(out_layer15)\n",
    "        #print('L2: ', out_layer21.shape) #torch.Size([16, 20, 200])\n",
    "        # Layer 3 =======================================================================\n",
    "        out_layer31 = out_layer21\n",
    "        out_layer32 = torch.cat((torch.cat((torch.cat((out_layer22, out_layer23), dim=2), \n",
    "                                            out_layer24), dim=2), out_layer25), dim=2)\n",
    "        #print('L3: ', out_layer31.shape) #torch.Size([16, 20, 200])\n",
    "        # Layer 4 =======================================================================\n",
    "        out_layer41, _ = self.rnn_l41(out_layer31) #torch.Size([16, 20, 400])\n",
    "        out_layer42, _ = self.rnn_l42(out_layer32) #torch.Size([16, 20, 400])\n",
    "        #print('L4: ', out_layer42.shape)\n",
    "        # Layer 5 =======================================================================\n",
    "        out_layer5 = torch.cat((out_layer41, out_layer42), dim=2)\n",
    "        #print('L5: ', out_layer5.shape) #torch.Size([16, 20, 800])\n",
    "        # Layer 6 =======================================================================\n",
    "        out_layer6, _ = self.rnn_l6(out_layer5)\n",
    "        #print('L6: ', out_layer6.shape) #torch.Size([16, 20, 100])\n",
    "        # Layer 7 =======================================================================       \n",
    "        #print('Output: ', out1.shape, out_layer6.shape) # torch.Size([16, 20, 100])\n",
    "        output = self.classify_layer(out_layer6[:, -1, :])\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRNN(\n",
      "  (rnn1): RNN(6, 50, batch_first=True, bidirectional=True)\n",
      "  (rnn2): RNN(12, 50, batch_first=True, bidirectional=True)\n",
      "  (rnn3): RNN(8, 50, batch_first=True, bidirectional=True)\n",
      "  (rnn4): RNN(8, 50, batch_first=True, bidirectional=True)\n",
      "  (rnn5): RNN(8, 50, batch_first=True, bidirectional=True)\n",
      "  (rnn6): RNN(8, 50, batch_first=True, bidirectional=True)\n",
      "  (rnn_l2): RNN(200, 100, batch_first=True, bidirectional=True)\n",
      "  (rnn_l41): RNN(200, 200, batch_first=True, bidirectional=True)\n",
      "  (rnn_l42): RNN(800, 200, batch_first=True, bidirectional=True)\n",
      "  (rnn_l6): LSTM(800, 200, batch_first=True, bidirectional=True)\n",
      "  (classify_layer): Linear(in_features=400, out_features=4, bias=True)\n",
      "  (softmax): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_ft = HRNN(input_size=50, hidden_size=50, num_layers=1)\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([16, 20, 50])\n",
      "torch.Size([16, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei-chan.hsu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#inputn = torch.randn(20, 1, 50)\n",
    "for i, (cow, sample) in enumerate(dataloaders['val']):\n",
    "    pass\n",
    "    #print(sample['seq'].shape)\n",
    "    #sample['seq'] = sample['seq'].reshape(-1, batch_size, 50)\n",
    "    \n",
    "inputn = sample['seq'].float()\n",
    "print('Shape: ', inputn.shape)\n",
    "inputn = inputn.to(device)\n",
    "\n",
    "output = model_ft(inputn)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(inputn0.float().dtype)\n",
    "print(inputn.dtype)\n",
    "#print(inputn - inputn0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    train_acc_history = []\n",
    "    val_acc_history = []  \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for cow, sample in dataloaders[phase]:\n",
    "                inputs = sample['seq'].view(batch_size, 20, 50)\n",
    "                inputs = inputs.float().to(device)  # requires float32\n",
    "                labels = sample['label'].to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss) \n",
    "                train_acc_history.append(epoch_acc)\n",
    "            else:\n",
    "                val_loss.append(epoch_loss)\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print(epoch_loss)\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_acc_history, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei-chan.hsu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3343 Acc: 0.4094\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 1.3218 Acc: 0.4219\n",
      "val Loss: 1.3437 Acc: 0.4000\n",
      "\n",
      "Training complete in 0m 18s\n",
      "Best val Acc: 0.400000\n",
      "1.3436682224273682\n"
     ]
    }
   ],
   "source": [
    "model_ft, train_acc, val_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn1.weight_ih_l0 tensor([[-0.1289, -0.0930,  0.0632, -0.1485,  0.0731, -0.1022],\n",
      "        [-0.1135,  0.0079, -0.1098,  0.0819, -0.1113,  0.0295],\n",
      "        [ 0.0584, -0.0042, -0.0363,  0.0058, -0.1318, -0.0327],\n",
      "        [-0.0816,  0.0883, -0.0249,  0.1247, -0.0482, -0.0458],\n",
      "        [ 0.0836, -0.0254, -0.0176,  0.0050,  0.0748,  0.0753],\n",
      "        [-0.0055, -0.0762,  0.0352, -0.0511, -0.0282,  0.0755],\n",
      "        [-0.0164, -0.0780, -0.1437, -0.1108,  0.0422, -0.1502],\n",
      "        [ 0.0485, -0.0008,  0.0414, -0.1333, -0.1682, -0.1333],\n",
      "        [-0.1282, -0.1402,  0.0009, -0.1673, -0.0983, -0.1100],\n",
      "        [-0.1768, -0.1663, -0.0667, -0.1420, -0.1669,  0.0248],\n",
      "        [ 0.0566,  0.0203,  0.1164,  0.0439,  0.1007, -0.0951],\n",
      "        [ 0.1917,  0.0058, -0.0465,  0.1806, -0.0112, -0.0428],\n",
      "        [ 0.0189, -0.1292,  0.0341, -0.0005, -0.1905, -0.2064],\n",
      "        [ 0.0264, -0.0204, -0.0114, -0.1039, -0.0652,  0.0014],\n",
      "        [-0.0744,  0.1475, -0.0143, -0.0788,  0.0999,  0.1156],\n",
      "        [ 0.0436,  0.0174, -0.1812, -0.1069,  0.0548, -0.0248],\n",
      "        [ 0.0249, -0.0768,  0.1238, -0.0825,  0.1116,  0.0702],\n",
      "        [-0.0442, -0.1270, -0.1924, -0.1835, -0.1475, -0.1364],\n",
      "        [ 0.0750,  0.0544,  0.1066,  0.0524,  0.1797, -0.0213],\n",
      "        [-0.0352, -0.0839, -0.0198,  0.0446,  0.1130,  0.0976],\n",
      "        [ 0.0735, -0.0590, -0.1084, -0.0348,  0.0511, -0.0986],\n",
      "        [ 0.0418, -0.0857,  0.1089, -0.0655,  0.1888,  0.0122],\n",
      "        [ 0.1555, -0.0240, -0.0838,  0.0647,  0.1758, -0.0482],\n",
      "        [-0.1772, -0.1324, -0.1330, -0.0254,  0.0069,  0.0230],\n",
      "        [-0.0168, -0.1529, -0.0136,  0.0087,  0.0799, -0.0637],\n",
      "        [ 0.0738,  0.1509,  0.1348,  0.1588,  0.1805,  0.0689],\n",
      "        [ 0.1180,  0.0467,  0.0725,  0.0294,  0.0865,  0.0893],\n",
      "        [-0.1078, -0.1502,  0.0643, -0.0628, -0.0077,  0.0632],\n",
      "        [ 0.0841,  0.0463, -0.0466,  0.1395,  0.0398,  0.0871],\n",
      "        [ 0.1671, -0.0252,  0.0623, -0.0639,  0.1768, -0.0568],\n",
      "        [-0.1542,  0.0186, -0.1129, -0.0374, -0.0943, -0.0580],\n",
      "        [ 0.1643, -0.0254,  0.0432,  0.1439, -0.0227, -0.0064],\n",
      "        [ 0.0061, -0.0321, -0.1719,  0.0818, -0.1135, -0.1587],\n",
      "        [-0.0598, -0.0799, -0.0243, -0.1116, -0.1212, -0.0043],\n",
      "        [-0.0540,  0.0937, -0.0795, -0.1510,  0.0391, -0.0961],\n",
      "        [ 0.0573, -0.0697,  0.0359, -0.0258, -0.1095, -0.0407],\n",
      "        [-0.0498, -0.1809, -0.1715, -0.0669, -0.0011,  0.0431],\n",
      "        [-0.0498,  0.1714, -0.0698,  0.1214,  0.0914,  0.1956],\n",
      "        [ 0.0486, -0.0823, -0.0292,  0.0203, -0.0588,  0.0773],\n",
      "        [ 0.0323,  0.0021,  0.0894, -0.0007,  0.0634, -0.1051],\n",
      "        [ 0.0350, -0.1886,  0.0341, -0.1556,  0.0778,  0.0705],\n",
      "        [-0.1394,  0.0931, -0.1161,  0.0540,  0.0235, -0.0372],\n",
      "        [ 0.0408,  0.0408,  0.0776,  0.0648, -0.1539,  0.0683],\n",
      "        [-0.0407, -0.1433, -0.0299, -0.1388, -0.1686, -0.0141],\n",
      "        [-0.0283, -0.1626, -0.0803, -0.0077, -0.0270,  0.0695],\n",
      "        [-0.0352, -0.1437, -0.0090, -0.0728, -0.0936, -0.0220],\n",
      "        [-0.1396,  0.0428, -0.0591, -0.1054, -0.1813, -0.1437],\n",
      "        [ 0.0563, -0.0874, -0.0235,  0.1425,  0.0969,  0.1794],\n",
      "        [-0.1084, -0.1387, -0.0860, -0.0921, -0.0116, -0.0864],\n",
      "        [ 0.0398, -0.0687, -0.1719, -0.0982, -0.1083, -0.1629]],\n",
      "       device='cuda:0')\n",
      "rnn1.weight_hh_l0 tensor([[-1.8587e-01,  1.8329e-02,  8.2399e-02,  ...,  5.7293e-02,\n",
      "         -5.6591e-02, -1.3536e-01],\n",
      "        [-6.4812e-02, -7.9922e-02, -4.9741e-02,  ...,  8.6180e-02,\n",
      "          1.0950e-04,  3.4334e-02],\n",
      "        [ 2.6593e-02, -3.4362e-02, -7.8637e-02,  ...,  1.1248e-01,\n",
      "         -1.4978e-01,  5.7753e-03],\n",
      "        ...,\n",
      "        [ 6.4804e-02,  9.3514e-02, -7.6826e-02,  ...,  9.6612e-02,\n",
      "          8.6793e-02,  1.5459e-01],\n",
      "        [-1.2532e-01, -1.8317e-01, -8.6468e-02,  ...,  9.6733e-02,\n",
      "         -1.0176e-01, -5.0048e-02],\n",
      "        [ 5.6283e-02,  9.8318e-02,  8.5828e-02,  ...,  1.9118e-01,\n",
      "         -6.4611e-02, -4.7171e-02]], device='cuda:0')\n",
      "rnn1.bias_ih_l0 tensor([ 0.0863,  0.0238, -0.0928, -0.0440,  0.1911,  0.0547,  0.0728,  0.0228,\n",
      "         0.0389, -0.1496,  0.1824,  0.1172, -0.0367, -0.1885,  0.0402,  0.0413,\n",
      "         0.0498, -0.0681, -0.0437,  0.1348, -0.1218,  0.0803, -0.0072, -0.1872,\n",
      "        -0.1094,  0.0169,  0.0586,  0.0401, -0.0522, -0.0534,  0.0023,  0.2033,\n",
      "        -0.0379, -0.0215,  0.0630, -0.0990, -0.0423,  0.1066,  0.0450,  0.0532,\n",
      "         0.0517,  0.1086, -0.0178,  0.0047, -0.0502, -0.0817, -0.1855, -0.0743,\n",
      "         0.0555,  0.0788], device='cuda:0')\n",
      "rnn1.bias_hh_l0 tensor([-0.1583, -0.1927,  0.0514,  0.1047, -0.0049, -0.1280, -0.1009, -0.1194,\n",
      "         0.0557, -0.1654, -0.0496,  0.1464, -0.0854,  0.0860, -0.0688,  0.0497,\n",
      "         0.1142,  0.0295,  0.0325,  0.0319, -0.1360, -0.0438,  0.1439,  0.0204,\n",
      "        -0.1633,  0.1327,  0.0962,  0.0500, -0.0160,  0.0757,  0.0435, -0.0197,\n",
      "         0.1121,  0.0770, -0.0204,  0.0760, -0.0744, -0.0262,  0.0657,  0.1302,\n",
      "        -0.0660,  0.0519,  0.0386, -0.0046, -0.1289, -0.0787, -0.0296, -0.0391,\n",
      "         0.0160, -0.0262], device='cuda:0')\n",
      "rnn1.weight_ih_l0_reverse tensor([[ 0.0901, -0.0878, -0.0215,  0.0522, -0.0862,  0.0635],\n",
      "        [ 0.0175, -0.0283, -0.1771, -0.1244, -0.0098, -0.1548],\n",
      "        [-0.0144, -0.1046, -0.0621, -0.0975,  0.0008,  0.1057],\n",
      "        [-0.0206,  0.0243,  0.1082, -0.0818, -0.0299,  0.1184],\n",
      "        [-0.0013, -0.0304, -0.0385, -0.1091, -0.1679, -0.0052],\n",
      "        [-0.0651, -0.0436,  0.0486,  0.0695,  0.0564, -0.0943],\n",
      "        [ 0.1212,  0.1167,  0.1131,  0.1449,  0.0915,  0.0921],\n",
      "        [ 0.0384, -0.0250,  0.0772, -0.0956, -0.0026,  0.0304],\n",
      "        [ 0.0439,  0.0275,  0.0772, -0.0721,  0.0133, -0.0026],\n",
      "        [-0.1317, -0.1869, -0.1655, -0.1535,  0.0784, -0.1053],\n",
      "        [-0.0936, -0.1713,  0.0239, -0.1164, -0.1612, -0.1208],\n",
      "        [-0.0550, -0.1731, -0.0350,  0.0792, -0.0368,  0.0368],\n",
      "        [-0.1836, -0.1550, -0.0719, -0.0191,  0.0122, -0.0107],\n",
      "        [ 0.0561,  0.0022, -0.1229,  0.0693, -0.0421,  0.1017],\n",
      "        [-0.0107, -0.0542, -0.0060,  0.0617, -0.0744, -0.0143],\n",
      "        [-0.1124,  0.0221,  0.0563, -0.0854, -0.1348, -0.0947],\n",
      "        [-0.0358,  0.1382, -0.0634, -0.0482,  0.0142,  0.1301],\n",
      "        [-0.1181, -0.1376, -0.0566, -0.0901, -0.1431, -0.0319],\n",
      "        [ 0.1016, -0.0675,  0.1657,  0.0192,  0.1814,  0.0420],\n",
      "        [ 0.0548,  0.1084, -0.0698,  0.1068,  0.0384,  0.0946],\n",
      "        [ 0.0140, -0.0797, -0.0501,  0.0639, -0.0326, -0.1096],\n",
      "        [ 0.0242, -0.0710,  0.1204,  0.0627, -0.0725,  0.0913],\n",
      "        [-0.0378,  0.0921, -0.0583, -0.1639, -0.0541,  0.0411],\n",
      "        [-0.0395, -0.0422,  0.1617,  0.1353, -0.0407,  0.0014],\n",
      "        [-0.0461, -0.0089, -0.0911, -0.1377, -0.1212, -0.0557],\n",
      "        [ 0.1076,  0.0527,  0.0862,  0.1456,  0.0534,  0.0453],\n",
      "        [-0.0288,  0.0657,  0.0377, -0.1880,  0.0303, -0.0201],\n",
      "        [-0.0388, -0.1638,  0.0139,  0.1433,  0.1855,  0.0367],\n",
      "        [ 0.0617, -0.0064, -0.1194, -0.1274,  0.0027,  0.1196],\n",
      "        [-0.0912, -0.0843,  0.0856, -0.1066, -0.1072, -0.1545],\n",
      "        [-0.0402, -0.0669, -0.0495,  0.0820,  0.0648, -0.0289],\n",
      "        [ 0.0193, -0.0718, -0.1384, -0.1281, -0.1704, -0.0588],\n",
      "        [-0.0606,  0.0419,  0.0779, -0.1872, -0.0886, -0.1940],\n",
      "        [-0.0496, -0.0395,  0.0272,  0.1797,  0.1651,  0.0663],\n",
      "        [ 0.0144, -0.0773,  0.1396, -0.0760,  0.0389,  0.1681],\n",
      "        [ 0.1857, -0.0612,  0.1881, -0.0615,  0.1482, -0.0721],\n",
      "        [-0.1914, -0.1093,  0.0274, -0.0731,  0.0668, -0.1076],\n",
      "        [-0.1780, -0.1786,  0.0353, -0.0802,  0.0353, -0.0139],\n",
      "        [ 0.0304,  0.0573,  0.0210,  0.0853,  0.1227, -0.1120],\n",
      "        [ 0.1521, -0.0753,  0.0703,  0.1486, -0.0889,  0.0089],\n",
      "        [ 0.0404, -0.0440,  0.0541,  0.1043,  0.0488, -0.1795],\n",
      "        [-0.0614,  0.0467,  0.0445,  0.0246, -0.0067,  0.1242],\n",
      "        [-0.1340, -0.1235, -0.0139, -0.0256, -0.0242, -0.0408],\n",
      "        [ 0.0110, -0.0798, -0.0829,  0.0434,  0.1492,  0.0959],\n",
      "        [-0.0939, -0.0050, -0.0154, -0.0628, -0.0882,  0.0432],\n",
      "        [-0.0187, -0.0951,  0.0096, -0.0851, -0.0695, -0.0473],\n",
      "        [-0.0011, -0.0442, -0.0890, -0.0260, -0.0146, -0.1649],\n",
      "        [ 0.1349, -0.0461, -0.1236,  0.1726, -0.0016,  0.1554],\n",
      "        [-0.0765,  0.1976,  0.1996,  0.1549,  0.0154,  0.0325],\n",
      "        [-0.0740,  0.0105,  0.0590,  0.0442,  0.0875,  0.1493]],\n",
      "       device='cuda:0')\n",
      "rnn1.weight_hh_l0_reverse tensor([[-0.1162, -0.0660, -0.1619,  ...,  0.0253, -0.0881, -0.1572],\n",
      "        [-0.0855,  0.0285, -0.0998,  ..., -0.1615,  0.0640, -0.0320],\n",
      "        [-0.0143, -0.0520, -0.0363,  ..., -0.0862,  0.1464,  0.0204],\n",
      "        ...,\n",
      "        [-0.1437,  0.1649, -0.0336,  ...,  0.1231,  0.1195, -0.1065],\n",
      "        [-0.1174, -0.1779,  0.0044,  ..., -0.1809,  0.0388, -0.1167],\n",
      "        [-0.1398, -0.1949,  0.0488,  ..., -0.0662,  0.0881, -0.0746]],\n",
      "       device='cuda:0')\n",
      "rnn1.bias_ih_l0_reverse tensor([ 0.1281, -0.1096,  0.0921,  0.0351, -0.0108,  0.1312,  0.0495,  0.0421,\n",
      "         0.0985, -0.1775, -0.0047,  0.0152, -0.1392,  0.0978, -0.1234, -0.0516,\n",
      "         0.0227,  0.0477,  0.0418,  0.1645,  0.0268,  0.1780,  0.0744,  0.0367,\n",
      "        -0.0732,  0.0452, -0.2000, -0.0782, -0.0624,  0.0092, -0.0243, -0.1567,\n",
      "        -0.0326,  0.1787,  0.0477, -0.0099, -0.0572, -0.1326, -0.0533,  0.1141,\n",
      "         0.0687, -0.0532,  0.0050,  0.0295,  0.1316, -0.0929, -0.0601, -0.0554,\n",
      "        -0.0601,  0.1258], device='cuda:0')\n",
      "rnn1.bias_hh_l0_reverse tensor([-0.0080, -0.0588, -0.0670,  0.0303, -0.0908, -0.0772,  0.0298,  0.1487,\n",
      "         0.1863, -0.1097,  0.0040, -0.1358, -0.0536, -0.1244,  0.0820, -0.1759,\n",
      "         0.2135, -0.0603,  0.1115,  0.0965,  0.0759,  0.0246, -0.1555,  0.0220,\n",
      "        -0.1355,  0.0546, -0.1247,  0.1284, -0.0820, -0.0720,  0.0617,  0.0276,\n",
      "         0.0501,  0.1018,  0.1076, -0.0067,  0.0669, -0.0737,  0.0790, -0.0766,\n",
      "         0.0737,  0.0077, -0.1596,  0.1373,  0.0632,  0.1098,  0.0373, -0.0321,\n",
      "         0.1968, -0.0285], device='cuda:0')\n",
      "rnn2.weight_ih_l0 tensor([[-0.1149,  0.0073, -0.1275, -0.1218,  0.1289, -0.0552, -0.1393, -0.0870,\n",
      "          0.1837, -0.1937,  0.0826, -0.0585],\n",
      "        [-0.1257,  0.0341,  0.0234,  0.0709, -0.0006, -0.0943,  0.0104,  0.0573,\n",
      "         -0.0765, -0.1453,  0.1076, -0.1443],\n",
      "        [-0.1618,  0.1097, -0.0625,  0.0964,  0.1198,  0.0797,  0.0274, -0.1108,\n",
      "         -0.0857,  0.0868,  0.0998, -0.0997],\n",
      "        [-0.0202, -0.1068,  0.0049, -0.0550,  0.1278, -0.0906, -0.1521,  0.0536,\n",
      "          0.0886,  0.0417,  0.1413, -0.1326],\n",
      "        [ 0.1814,  0.0970, -0.0405,  0.0576,  0.0490, -0.0454,  0.0187, -0.0199,\n",
      "         -0.0273,  0.1754, -0.0638, -0.0321],\n",
      "        [ 0.0396,  0.0862, -0.1445,  0.0909,  0.0515, -0.0883, -0.1331,  0.0486,\n",
      "         -0.0907,  0.0195,  0.0160, -0.1658],\n",
      "        [ 0.0662,  0.1145, -0.0487, -0.1103, -0.0155, -0.0913,  0.0698,  0.0145,\n",
      "         -0.0158, -0.0079,  0.0512, -0.0011],\n",
      "        [-0.1825,  0.0665, -0.1586, -0.0732, -0.0375,  0.0849, -0.1332, -0.0931,\n",
      "          0.1118, -0.1773, -0.0260,  0.0771],\n",
      "        [ 0.0442, -0.0436,  0.0985,  0.0243,  0.0522, -0.0813, -0.0268,  0.0408,\n",
      "          0.0440,  0.0057, -0.0101,  0.0095],\n",
      "        [-0.1501, -0.0489, -0.1735,  0.1442, -0.0887, -0.0638, -0.1922, -0.2014,\n",
      "         -0.0856, -0.0104,  0.1534, -0.1366],\n",
      "        [-0.0370,  0.1607,  0.1645,  0.1199, -0.0561, -0.1066, -0.0876,  0.0637,\n",
      "         -0.1589,  0.0523,  0.1397,  0.1699],\n",
      "        [ 0.0478, -0.1606,  0.0557,  0.1827,  0.0344, -0.1103, -0.1714, -0.0933,\n",
      "          0.1434, -0.1539,  0.0531, -0.0907],\n",
      "        [ 0.0710, -0.0639, -0.0099,  0.0553,  0.0806,  0.0214, -0.1351, -0.0207,\n",
      "          0.0697, -0.0720,  0.1846,  0.0776],\n",
      "        [ 0.0614, -0.1024, -0.1441,  0.0399,  0.0189, -0.0832, -0.0272, -0.1310,\n",
      "         -0.0870, -0.0257,  0.0381, -0.1332],\n",
      "        [ 0.0701, -0.1014,  0.1168, -0.1906,  0.1114,  0.0967,  0.0892, -0.0750,\n",
      "          0.0987,  0.1280, -0.0956,  0.0741],\n",
      "        [ 0.1415,  0.0394,  0.0043, -0.0537, -0.0393,  0.0885,  0.1382,  0.0804,\n",
      "         -0.1614, -0.0679,  0.0845, -0.0322],\n",
      "        [-0.1700, -0.0963, -0.0079,  0.1935,  0.1302,  0.0079, -0.0519, -0.0838,\n",
      "         -0.0557, -0.1664,  0.1638, -0.1556],\n",
      "        [-0.1358, -0.0737, -0.1644,  0.0198, -0.1398, -0.0738,  0.0749, -0.1301,\n",
      "          0.0447, -0.1301,  0.1414, -0.0784],\n",
      "        [ 0.1685,  0.1018,  0.0624, -0.0153,  0.0879,  0.1246,  0.1830,  0.1772,\n",
      "         -0.1171,  0.1460,  0.0130,  0.0429],\n",
      "        [-0.1092, -0.0005,  0.0533,  0.0641, -0.0574, -0.0870,  0.0562,  0.0589,\n",
      "         -0.0263, -0.0245,  0.0025, -0.0783],\n",
      "        [-0.0325,  0.0338, -0.0064, -0.1029, -0.0089, -0.1332, -0.0300, -0.1023,\n",
      "         -0.0294, -0.1522, -0.0764, -0.0113],\n",
      "        [ 0.1412,  0.1071,  0.1034,  0.1253, -0.0986,  0.1264,  0.0217,  0.0058,\n",
      "          0.1392,  0.0144, -0.1192,  0.0828],\n",
      "        [ 0.0675, -0.0130,  0.0959, -0.0008, -0.0386, -0.1318,  0.1189,  0.0944,\n",
      "          0.0865,  0.1096, -0.1123,  0.0340],\n",
      "        [-0.0628,  0.0317, -0.0312,  0.0781, -0.0782, -0.0727, -0.1015, -0.0910,\n",
      "         -0.0727, -0.0212,  0.1580, -0.0546],\n",
      "        [-0.0661, -0.0713, -0.0874, -0.1307, -0.0409,  0.0180,  0.0503,  0.1132,\n",
      "         -0.0554,  0.0824, -0.0767, -0.0318],\n",
      "        [ 0.0020,  0.0490,  0.0079,  0.0383,  0.0048, -0.0712,  0.0730,  0.1623,\n",
      "         -0.1395,  0.1694, -0.0590, -0.0420],\n",
      "        [ 0.0738, -0.1478,  0.0806, -0.1931, -0.0173,  0.0625,  0.1435, -0.0240,\n",
      "          0.1872, -0.0080,  0.0748, -0.1009],\n",
      "        [ 0.1825,  0.1475, -0.0597,  0.0680,  0.0825,  0.0241,  0.0117,  0.1820,\n",
      "         -0.0262,  0.0087, -0.0710,  0.1474],\n",
      "        [-0.0446, -0.1326, -0.1690,  0.2007,  0.0874,  0.1160, -0.0784,  0.0548,\n",
      "          0.0746, -0.0021, -0.0446, -0.1392],\n",
      "        [-0.0334,  0.1735, -0.0026, -0.0047, -0.0447,  0.0593,  0.1662,  0.1212,\n",
      "         -0.0175, -0.0089, -0.1133,  0.1186],\n",
      "        [-0.1683, -0.0720, -0.0948, -0.1708, -0.0338, -0.0253, -0.0485, -0.1151,\n",
      "          0.1845,  0.0812, -0.0511, -0.0051],\n",
      "        [-0.1460, -0.1699, -0.0644,  0.0922, -0.0232,  0.1350,  0.0505, -0.0277,\n",
      "          0.1635, -0.1296, -0.0180, -0.0687],\n",
      "        [ 0.0605,  0.0226,  0.0233,  0.1698,  0.1027, -0.0359,  0.0168, -0.1110,\n",
      "          0.1671, -0.1259,  0.0313, -0.0049],\n",
      "        [ 0.1050,  0.0520,  0.1088, -0.0100,  0.1323, -0.0556, -0.0939,  0.1259,\n",
      "         -0.0695, -0.0010, -0.1646,  0.0447],\n",
      "        [-0.1233, -0.1283,  0.0579,  0.0046, -0.1316,  0.0970, -0.0426, -0.1431,\n",
      "          0.1973, -0.0623,  0.1840,  0.0167],\n",
      "        [ 0.0331, -0.1243, -0.1531, -0.1282,  0.0795,  0.1231, -0.1848, -0.1774,\n",
      "          0.0836, -0.0179,  0.1719, -0.0526],\n",
      "        [-0.1888, -0.1606, -0.1073,  0.0520,  0.0348, -0.0963,  0.0607, -0.0664,\n",
      "         -0.0006,  0.0494, -0.0419,  0.0784],\n",
      "        [-0.0194,  0.0231,  0.0184, -0.1091,  0.1298, -0.0194, -0.0539, -0.1237,\n",
      "          0.0217,  0.0529, -0.0151,  0.1459],\n",
      "        [-0.0541,  0.0299, -0.0865, -0.0369, -0.0726, -0.0915,  0.0069,  0.1697,\n",
      "          0.0576, -0.0782, -0.1357,  0.0379],\n",
      "        [-0.0022, -0.1706, -0.1676,  0.0157,  0.0791,  0.0495,  0.0663,  0.0769,\n",
      "          0.1112, -0.0290,  0.1405, -0.0684],\n",
      "        [ 0.0134,  0.1767, -0.0515, -0.1899,  0.0086, -0.1034,  0.0205, -0.0552,\n",
      "          0.0586,  0.0168, -0.1875, -0.0116],\n",
      "        [-0.0960,  0.1516, -0.1207,  0.1722, -0.0177, -0.0125,  0.0539, -0.0698,\n",
      "         -0.0439,  0.1161,  0.0101,  0.0243],\n",
      "        [ 0.0323, -0.0654, -0.0706,  0.0875, -0.1315, -0.0946,  0.0084,  0.0087,\n",
      "         -0.0550,  0.0426,  0.0336, -0.0892],\n",
      "        [ 0.0896,  0.0308, -0.0405, -0.1477, -0.0474,  0.0150, -0.0289,  0.0747,\n",
      "         -0.1379, -0.0161, -0.0202, -0.0299],\n",
      "        [ 0.1241,  0.1905,  0.1407, -0.1025,  0.0812, -0.0568,  0.0213, -0.0847,\n",
      "         -0.0563,  0.0829,  0.0830,  0.1642],\n",
      "        [ 0.0784,  0.0352,  0.1862, -0.0898, -0.0063, -0.1106,  0.1166,  0.1315,\n",
      "         -0.0838,  0.0574, -0.1220,  0.1542],\n",
      "        [ 0.0642, -0.0429,  0.0307, -0.0037,  0.0280, -0.0659,  0.0360, -0.0176,\n",
      "         -0.1468,  0.0531, -0.0143, -0.0820],\n",
      "        [-0.1800, -0.1214, -0.0865, -0.1640,  0.0855,  0.0100, -0.0731,  0.0605,\n",
      "         -0.0554, -0.1712,  0.1063, -0.1246],\n",
      "        [-0.0642, -0.0035, -0.0066,  0.1526, -0.1189,  0.0304,  0.0659, -0.0534,\n",
      "         -0.0501,  0.0640, -0.1709,  0.1450],\n",
      "        [-0.0011, -0.1924,  0.0721, -0.1297, -0.0300,  0.0520, -0.0952, -0.0342,\n",
      "          0.0970, -0.0723,  0.0699,  0.0448]], device='cuda:0')\n",
      "rnn2.weight_hh_l0 tensor([[-0.0293,  0.1057,  0.0528,  ...,  0.2130,  0.0593, -0.1407],\n",
      "        [ 0.1235,  0.0909,  0.0225,  ...,  0.0221, -0.0217, -0.1257],\n",
      "        [ 0.0447, -0.1045, -0.1931,  ..., -0.0455, -0.0914,  0.0273],\n",
      "        ...,\n",
      "        [ 0.1024,  0.0186,  0.1252,  ...,  0.1471, -0.1833, -0.0462],\n",
      "        [-0.1568,  0.0471, -0.0854,  ..., -0.1634,  0.1924,  0.1785],\n",
      "        [-0.0484, -0.1324, -0.1151,  ...,  0.1677,  0.0439, -0.1055]],\n",
      "       device='cuda:0')\n",
      "rnn2.bias_ih_l0 tensor([-0.0422, -0.0916, -0.0421,  0.0767,  0.1500, -0.1491, -0.0048, -0.0905,\n",
      "         0.1746, -0.0331, -0.0399, -0.0335, -0.0173, -0.1852,  0.1713,  0.0788,\n",
      "        -0.0203, -0.1519, -0.0605, -0.0725, -0.0956, -0.0820, -0.0767, -0.0511,\n",
      "        -0.0082, -0.0614,  0.0889, -0.0395, -0.1840, -0.0465, -0.1236, -0.1637,\n",
      "        -0.0960,  0.1637, -0.1809,  0.0034,  0.0642, -0.0154,  0.0951, -0.0146,\n",
      "         0.0395,  0.0566,  0.0140,  0.0108,  0.1675, -0.0500,  0.0292, -0.1791,\n",
      "         0.1822,  0.0545], device='cuda:0')\n",
      "rnn2.bias_hh_l0 tensor([-0.1423,  0.0591, -0.0651, -0.1647,  0.0996,  0.0399,  0.1163, -0.1003,\n",
      "         0.0126, -0.0709, -0.0857, -0.0410, -0.0124,  0.0123,  0.1597, -0.0621,\n",
      "        -0.1370, -0.0086,  0.0351,  0.0506,  0.0266,  0.0263, -0.0554, -0.0737,\n",
      "        -0.0201,  0.1468,  0.0445,  0.1903, -0.1658, -0.0744, -0.1768, -0.0128,\n",
      "        -0.0624,  0.0869, -0.0130,  0.0328, -0.1821, -0.0713,  0.0360, -0.1897,\n",
      "         0.0676,  0.1498, -0.1050, -0.0051, -0.0868,  0.0752, -0.0228, -0.0715,\n",
      "         0.0490, -0.0599], device='cuda:0')\n",
      "rnn2.weight_ih_l0_reverse tensor([[-0.0828,  0.0193,  0.0837, -0.0620, -0.0517, -0.0477,  0.0415,  0.1292,\n",
      "          0.0003,  0.0418,  0.0380,  0.0701],\n",
      "        [-0.0402,  0.0822,  0.0996,  0.0292,  0.0712,  0.0162,  0.0863, -0.0361,\n",
      "         -0.0686,  0.0370,  0.0184, -0.0211],\n",
      "        [ 0.0695, -0.0077, -0.1151,  0.1091, -0.0750,  0.1248,  0.0510, -0.0301,\n",
      "          0.0553, -0.0830, -0.0021, -0.0831],\n",
      "        [ 0.0490,  0.0679,  0.1727,  0.0576, -0.0163,  0.1402,  0.0172,  0.1480,\n",
      "          0.0181,  0.0195,  0.0410,  0.1007],\n",
      "        [ 0.0009,  0.0829,  0.0431, -0.0894,  0.0254, -0.0259,  0.1207,  0.1086,\n",
      "         -0.1470,  0.1226, -0.1285,  0.0710],\n",
      "        [-0.0046, -0.1074, -0.0841, -0.0161,  0.0509, -0.0165, -0.1630, -0.0073,\n",
      "         -0.0004,  0.0674, -0.0434, -0.1648],\n",
      "        [ 0.0638,  0.0510,  0.0681, -0.0132, -0.0458, -0.0549,  0.0307, -0.1001,\n",
      "          0.0590, -0.1533,  0.1390, -0.1403],\n",
      "        [ 0.0526, -0.0334,  0.0384, -0.0524,  0.1330,  0.1231, -0.0190,  0.0495,\n",
      "          0.1101,  0.0680, -0.0773, -0.0989],\n",
      "        [-0.1561,  0.0691, -0.1214, -0.0402, -0.0031, -0.0652, -0.1557,  0.0199,\n",
      "         -0.0019, -0.0990,  0.0288,  0.0482],\n",
      "        [ 0.0780, -0.1229, -0.0485,  0.2003,  0.1015, -0.0799, -0.1245, -0.0537,\n",
      "         -0.1148, -0.0343,  0.0855, -0.1350],\n",
      "        [ 0.0850, -0.0417,  0.1461, -0.1111, -0.1357,  0.0071,  0.0004, -0.0983,\n",
      "         -0.1029,  0.0546, -0.1533, -0.0285],\n",
      "        [ 0.1026,  0.0620, -0.0512, -0.1880, -0.1014,  0.0493,  0.1848,  0.1052,\n",
      "          0.0740,  0.1566, -0.1515, -0.0233],\n",
      "        [-0.1521, -0.0944, -0.1826,  0.0709,  0.0394, -0.1371,  0.0573, -0.0014,\n",
      "          0.1284, -0.1991,  0.1083, -0.1417],\n",
      "        [ 0.0661,  0.0199, -0.1205,  0.0346, -0.0259,  0.1079, -0.1445, -0.0338,\n",
      "          0.0803, -0.1117, -0.0520, -0.1030],\n",
      "        [-0.0828, -0.1107,  0.0217,  0.1080,  0.0651, -0.1040,  0.1260, -0.0822,\n",
      "          0.1334, -0.0350, -0.1162,  0.0808],\n",
      "        [-0.0592, -0.0882, -0.0980,  0.0465,  0.1340,  0.1244, -0.0145,  0.0796,\n",
      "         -0.0390, -0.1820,  0.0645,  0.0363],\n",
      "        [-0.0211, -0.1532, -0.0735, -0.0951,  0.0348, -0.1254, -0.0602, -0.0401,\n",
      "         -0.0179,  0.0483,  0.0657,  0.0053],\n",
      "        [ 0.0416,  0.0003,  0.0551, -0.0142,  0.0692,  0.0313,  0.0233,  0.0453,\n",
      "          0.0869, -0.0733, -0.0648,  0.0455],\n",
      "        [ 0.0345,  0.0707,  0.0933,  0.0535,  0.1023,  0.0629,  0.0404,  0.1665,\n",
      "         -0.0698,  0.1067,  0.0066,  0.0336],\n",
      "        [-0.1064,  0.1487, -0.1275,  0.1420, -0.0414,  0.0788, -0.1535, -0.1505,\n",
      "         -0.0009,  0.0177, -0.0047,  0.0772],\n",
      "        [ 0.1828, -0.0049,  0.0268,  0.0046,  0.0762,  0.1007,  0.1766,  0.0773,\n",
      "         -0.1342,  0.1642,  0.0805, -0.0098],\n",
      "        [-0.0794, -0.0534, -0.1047, -0.0737, -0.0363, -0.0394,  0.0982,  0.1197,\n",
      "          0.0361,  0.0671,  0.0257, -0.0166],\n",
      "        [-0.1248, -0.0533,  0.0954, -0.0052,  0.0827,  0.0110, -0.1548,  0.0700,\n",
      "         -0.0119,  0.0590,  0.1866, -0.1395],\n",
      "        [-0.0492,  0.1120,  0.1764, -0.0887,  0.1036, -0.1056,  0.1831,  0.0145,\n",
      "         -0.1179, -0.0092, -0.0621, -0.0800],\n",
      "        [ 0.1898,  0.1652,  0.1165,  0.0155, -0.0844,  0.1117,  0.1406, -0.0534,\n",
      "         -0.0215,  0.0657, -0.1852, -0.0311],\n",
      "        [ 0.1414,  0.0398,  0.0577, -0.0140, -0.1354, -0.0362, -0.0620,  0.0984,\n",
      "          0.0483,  0.0115,  0.0545, -0.0364],\n",
      "        [-0.0140,  0.1258,  0.0815, -0.0677,  0.0814, -0.0785, -0.0591, -0.0458,\n",
      "          0.0399,  0.0120, -0.1508,  0.0112],\n",
      "        [ 0.0336, -0.0742, -0.1112, -0.0800,  0.1027, -0.0587, -0.1327, -0.0097,\n",
      "          0.0392,  0.0303,  0.0148, -0.1060],\n",
      "        [-0.0855,  0.0096, -0.0193,  0.0329,  0.0772,  0.0406,  0.0528, -0.0906,\n",
      "         -0.0724,  0.0877,  0.1620, -0.1306],\n",
      "        [-0.1468, -0.1020, -0.1691, -0.0068, -0.1131, -0.0498, -0.0107, -0.1398,\n",
      "          0.0649,  0.0736,  0.1252, -0.1587],\n",
      "        [ 0.0843,  0.0563,  0.0915,  0.1785,  0.0039,  0.0806,  0.0235,  0.0618,\n",
      "          0.0119, -0.0463, -0.0484,  0.1283],\n",
      "        [-0.2025, -0.0066, -0.0399,  0.0059, -0.0141,  0.1403, -0.0084, -0.2043,\n",
      "          0.1174,  0.0687,  0.0084,  0.0420],\n",
      "        [ 0.1834,  0.0825,  0.1416,  0.1098, -0.0078,  0.0171, -0.0720,  0.1487,\n",
      "         -0.1458,  0.0474, -0.1105, -0.0872],\n",
      "        [-0.0406,  0.0566,  0.1793, -0.0065, -0.0272, -0.0971, -0.0679,  0.1128,\n",
      "         -0.0894,  0.1622,  0.0707, -0.0085],\n",
      "        [ 0.0367,  0.1455, -0.0776, -0.0032,  0.0690, -0.0470,  0.0909, -0.0467,\n",
      "         -0.0768, -0.0518,  0.0501,  0.1577],\n",
      "        [ 0.0920,  0.0737,  0.0564,  0.0174, -0.0837, -0.0198, -0.0292, -0.0263,\n",
      "          0.0141, -0.0917, -0.0626, -0.0687],\n",
      "        [-0.0826,  0.1670, -0.0882,  0.0897,  0.0791,  0.0819,  0.0950,  0.0504,\n",
      "          0.1236, -0.1097,  0.1175, -0.1102],\n",
      "        [-0.0075, -0.0795, -0.0237, -0.0491,  0.0824, -0.0613, -0.1099, -0.0011,\n",
      "          0.0753, -0.0136,  0.1208,  0.0218],\n",
      "        [-0.0776,  0.0065, -0.1063,  0.1548,  0.1272,  0.0127, -0.1792, -0.1788,\n",
      "          0.0343, -0.0877,  0.0462,  0.0232],\n",
      "        [-0.0603,  0.1317, -0.0108, -0.0754, -0.0675, -0.0326, -0.0332, -0.1104,\n",
      "         -0.0479, -0.1317,  0.0354, -0.0819],\n",
      "        [ 0.0333, -0.0546,  0.0363, -0.0098,  0.1096, -0.1061, -0.0461, -0.0600,\n",
      "          0.0230,  0.0943, -0.0601, -0.0220],\n",
      "        [-0.0982, -0.1051,  0.1319, -0.1751,  0.0782,  0.0975,  0.0792, -0.0873,\n",
      "          0.0472,  0.0935, -0.0486, -0.0639],\n",
      "        [-0.0371, -0.0656, -0.1271,  0.2003,  0.0829, -0.1284,  0.0690,  0.1240,\n",
      "          0.0591, -0.1008, -0.0932,  0.0581],\n",
      "        [-0.0909,  0.0858,  0.1451,  0.0618,  0.1175, -0.0371, -0.0051,  0.0765,\n",
      "         -0.0029, -0.0876, -0.1179,  0.1065],\n",
      "        [ 0.1796,  0.0402,  0.0047,  0.0470, -0.1175,  0.0619, -0.0306,  0.1380,\n",
      "         -0.0317,  0.0586, -0.0133,  0.0388],\n",
      "        [ 0.0145, -0.0896, -0.0333, -0.0322,  0.0489,  0.0970,  0.0179,  0.0331,\n",
      "          0.0151,  0.1770,  0.0553,  0.0769],\n",
      "        [ 0.0281, -0.1327, -0.0844, -0.0459, -0.0691, -0.0927, -0.1594, -0.1943,\n",
      "         -0.0578, -0.1641, -0.0071, -0.0826],\n",
      "        [ 0.1617,  0.0090,  0.0947, -0.0580, -0.1293, -0.0046, -0.0777,  0.0731,\n",
      "          0.0181,  0.1865, -0.1247, -0.0804],\n",
      "        [ 0.0703, -0.0018,  0.1628, -0.0877,  0.1333,  0.0645,  0.0425, -0.0630,\n",
      "         -0.1804, -0.0824, -0.1907, -0.0057],\n",
      "        [-0.0862, -0.0196, -0.1087, -0.0081, -0.0775, -0.1389,  0.0157, -0.0383,\n",
      "          0.0020, -0.0130,  0.1499,  0.0748]], device='cuda:0')\n",
      "rnn2.weight_hh_l0_reverse tensor([[-0.0474,  0.0325,  0.1589,  ..., -0.0202, -0.1182, -0.0276],\n",
      "        [-0.0895, -0.1412,  0.0159,  ..., -0.1196, -0.1423,  0.1721],\n",
      "        [ 0.0997, -0.0675,  0.0234,  ...,  0.1066, -0.0232, -0.0732],\n",
      "        ...,\n",
      "        [-0.0417,  0.0019,  0.0148,  ...,  0.0554, -0.0931,  0.0773],\n",
      "        [-0.0849, -0.0068,  0.1392,  ..., -0.1146,  0.0081,  0.0849],\n",
      "        [ 0.0365, -0.0318,  0.0449,  ...,  0.0433,  0.1705,  0.0176]],\n",
      "       device='cuda:0')\n",
      "rnn2.bias_ih_l0_reverse tensor([-0.0028, -0.0595, -0.1377, -0.0850,  0.0627, -0.0456,  0.0316, -0.0397,\n",
      "        -0.0913, -0.1090,  0.0770, -0.0398, -0.0814, -0.1352, -0.0704, -0.0132,\n",
      "         0.1385, -0.0814,  0.1029,  0.0555,  0.0632,  0.1573, -0.1622,  0.1849,\n",
      "         0.1813,  0.1228, -0.0489, -0.1514,  0.0339, -0.0214, -0.0442, -0.0983,\n",
      "         0.0928,  0.1132,  0.1966, -0.1777, -0.0272, -0.0561, -0.1104, -0.1357,\n",
      "         0.1763, -0.0261, -0.0985,  0.1549,  0.0977,  0.1475,  0.0324,  0.1246,\n",
      "        -0.0429,  0.0592], device='cuda:0')\n",
      "rnn2.bias_hh_l0_reverse tensor([-0.0041,  0.1326,  0.0744,  0.1853,  0.0567,  0.0218, -0.1053, -0.0471,\n",
      "        -0.0660, -0.1704, -0.0013,  0.0291,  0.0038,  0.0147, -0.0928,  0.0204,\n",
      "         0.0512, -0.0817,  0.1854, -0.0209,  0.0146,  0.0153, -0.0834,  0.1310,\n",
      "        -0.0382,  0.0691,  0.0196, -0.0300, -0.0677, -0.0414, -0.0454,  0.0143,\n",
      "         0.0199, -0.0276,  0.1598,  0.0741, -0.1392, -0.0539,  0.0458,  0.0534,\n",
      "        -0.0549, -0.0299, -0.0273,  0.0067, -0.0719,  0.0724, -0.0394, -0.0881,\n",
      "        -0.0137, -0.0711], device='cuda:0')\n",
      "rnn3.weight_ih_l0 tensor([[ 7.6345e-02,  1.7514e-01,  1.5030e-01, -1.0584e-02, -2.7418e-02,\n",
      "         -4.2140e-02,  4.8694e-02,  1.3754e-01],\n",
      "        [ 1.8194e-01,  1.3493e-01,  7.6627e-03,  2.6417e-02,  1.6491e-01,\n",
      "         -3.6165e-02, -1.6539e-02,  1.3363e-01],\n",
      "        [ 3.2432e-03, -1.7795e-02, -5.2246e-02, -7.3938e-02,  2.5796e-02,\n",
      "          6.5415e-02,  2.9771e-02,  5.5682e-02],\n",
      "        [-2.6078e-02,  5.0570e-02,  4.1207e-02,  1.0080e-01,  7.4441e-02,\n",
      "          1.4797e-01,  1.1501e-01, -2.3963e-02],\n",
      "        [-1.0410e-01, -5.6651e-02, -1.7659e-01, -1.6075e-01, -1.4889e-01,\n",
      "         -1.4211e-01, -1.3675e-02, -1.8735e-01],\n",
      "        [ 1.1533e-01,  3.1639e-02,  1.3374e-01,  1.4171e-01,  5.7721e-04,\n",
      "          7.5221e-02,  9.5478e-02, -2.9990e-02],\n",
      "        [ 1.2101e-01, -3.4373e-02, -7.9502e-02, -7.7834e-02,  8.6010e-02,\n",
      "         -8.0814e-02,  9.0862e-03,  1.0561e-01],\n",
      "        [ 3.8452e-02,  2.9756e-02,  3.0586e-02,  9.6727e-02,  1.2037e-01,\n",
      "          1.5191e-02, -2.8152e-02, -6.3179e-02],\n",
      "        [-4.4996e-03,  8.3731e-02,  2.6390e-02, -5.8911e-02,  1.5179e-01,\n",
      "          1.5904e-01,  6.5505e-02,  5.6479e-02],\n",
      "        [ 1.7969e-01, -5.2837e-02,  1.7113e-01,  1.0410e-01, -8.3225e-02,\n",
      "          2.2330e-02,  1.2815e-01, -3.8423e-02],\n",
      "        [ 1.7994e-01,  3.4562e-02,  1.9259e-01, -7.4590e-02, -7.4158e-02,\n",
      "          1.4780e-01, -6.7858e-02,  1.6514e-01],\n",
      "        [ 1.7197e-01,  3.3042e-02,  2.7679e-02,  3.2371e-03, -5.1381e-02,\n",
      "          1.4645e-01,  1.5709e-01, -4.8150e-02],\n",
      "        [ 7.2892e-02,  3.3362e-02,  4.7554e-02,  7.4017e-02,  2.7653e-04,\n",
      "          7.8502e-03,  1.4016e-02, -8.5405e-02],\n",
      "        [ 1.6138e-01,  1.3503e-01,  1.2868e-01,  1.0811e-01, -4.0282e-02,\n",
      "         -6.4897e-02,  6.1774e-03,  2.3551e-02],\n",
      "        [-1.7499e-01,  1.0418e-02,  4.4935e-02,  6.3394e-02, -4.9720e-02,\n",
      "         -6.3134e-02, -1.4573e-01, -1.3096e-01],\n",
      "        [-3.7218e-02, -3.2596e-02, -5.7813e-02, -8.0199e-02,  8.6512e-02,\n",
      "         -3.2897e-02,  1.4452e-01,  1.5917e-01],\n",
      "        [ 1.3201e-02,  1.0307e-01,  1.8430e-02, -3.9253e-02,  1.8176e-01,\n",
      "          3.9105e-02,  7.4676e-02,  8.4970e-02],\n",
      "        [-6.4589e-02,  1.2295e-01, -6.4167e-03,  9.0482e-02, -3.4358e-03,\n",
      "         -2.4634e-02,  7.4688e-02, -7.4719e-02],\n",
      "        [-2.8163e-02, -6.0610e-02, -1.4845e-01, -1.0194e-01,  3.6203e-03,\n",
      "          6.2467e-02, -1.7536e-01, -7.5087e-02],\n",
      "        [ 6.2737e-02, -1.3300e-01, -1.9155e-02,  7.7410e-02, -1.0168e-01,\n",
      "          2.9662e-02,  1.4467e-02, -1.3119e-01],\n",
      "        [ 3.7370e-04,  2.2479e-02,  9.3867e-02,  6.0907e-02,  2.6074e-02,\n",
      "          1.9327e-01,  4.0443e-03,  1.0269e-01],\n",
      "        [ 7.2030e-02,  7.7284e-02, -3.8765e-02,  1.7301e-01, -4.7917e-02,\n",
      "          1.8603e-02,  8.6286e-02,  7.2771e-02],\n",
      "        [-1.5345e-01,  3.6217e-03, -4.9445e-02, -9.2051e-02, -8.6294e-02,\n",
      "          8.1077e-02, -1.8354e-01, -1.6885e-01],\n",
      "        [-8.9642e-02,  5.3678e-04, -5.9816e-02, -2.6261e-02, -4.5256e-02,\n",
      "         -4.4168e-02, -1.6378e-01,  5.7181e-03],\n",
      "        [ 2.1530e-02, -1.5492e-01, -1.3774e-01, -1.0155e-01, -6.1332e-02,\n",
      "          6.7837e-03, -8.6330e-02, -5.1439e-02],\n",
      "        [-7.6797e-02,  1.3083e-01,  7.8518e-02, -5.6406e-03, -7.9165e-04,\n",
      "          1.3216e-01,  1.8712e-02, -4.6732e-02],\n",
      "        [-2.6515e-02,  1.4420e-01,  4.7202e-02,  5.1390e-02, -6.6108e-02,\n",
      "         -1.0331e-02, -5.0744e-02,  6.2061e-03],\n",
      "        [-1.6322e-01, -7.6278e-02, -1.4191e-01, -7.5431e-02,  4.5759e-02,\n",
      "         -1.9005e-01, -7.2198e-05,  4.9477e-02],\n",
      "        [-1.0493e-01,  7.7776e-02, -1.4042e-01, -1.7739e-02,  1.5128e-02,\n",
      "         -1.3223e-01, -9.5527e-02, -1.1733e-01],\n",
      "        [ 1.5554e-01,  1.1961e-01, -4.2619e-02,  3.6747e-02,  1.3142e-01,\n",
      "          9.3274e-02,  1.1927e-01,  4.3267e-02],\n",
      "        [-9.9109e-02,  8.7244e-02,  9.2148e-02, -7.0823e-02, -8.4132e-03,\n",
      "         -1.6475e-01,  5.9235e-03,  1.8433e-02],\n",
      "        [ 4.6283e-02,  5.6318e-02, -3.0930e-02, -7.7657e-02, -1.5180e-01,\n",
      "         -3.2200e-02, -4.0289e-02, -6.5250e-02],\n",
      "        [ 2.6896e-02,  7.7846e-02, -4.2390e-02,  1.4130e-01,  4.8114e-02,\n",
      "         -8.1718e-02, -1.8297e-02, -3.1830e-02],\n",
      "        [-2.2939e-02, -1.3942e-01, -4.3968e-02, -8.4643e-02, -1.9872e-01,\n",
      "         -1.9472e-01,  3.3076e-02, -1.0415e-01],\n",
      "        [ 7.3626e-03,  1.6063e-01,  1.2287e-01,  9.7083e-02,  1.0288e-01,\n",
      "          4.9931e-02, -4.4007e-02,  1.3591e-01],\n",
      "        [ 6.5555e-02, -3.8077e-02,  7.0518e-02,  2.8685e-02, -1.4077e-01,\n",
      "          8.4990e-02, -1.8911e-01,  7.5635e-03],\n",
      "        [ 1.5780e-01,  5.1773e-02,  1.4124e-01,  1.8130e-01,  7.5671e-02,\n",
      "          8.4174e-02,  1.5700e-01,  1.5344e-01],\n",
      "        [-1.2281e-01,  1.6448e-02, -1.5555e-01,  2.4665e-02, -1.4553e-01,\n",
      "         -2.4050e-02,  2.0685e-02, -1.8508e-01],\n",
      "        [ 1.4483e-01, -6.9983e-02,  1.3523e-01,  6.0444e-02,  6.9840e-02,\n",
      "         -1.1687e-02,  9.4902e-02, -3.1819e-02],\n",
      "        [ 6.3262e-02, -8.9515e-02, -1.2515e-02, -7.2799e-02,  1.7814e-02,\n",
      "          6.1735e-03, -1.6758e-02, -1.1989e-01],\n",
      "        [ 9.5232e-02,  8.7652e-02,  6.7146e-02,  1.2286e-01,  8.5710e-02,\n",
      "          1.6298e-01, -6.2780e-02,  1.3615e-01],\n",
      "        [ 1.0965e-01, -4.7798e-02,  1.1835e-01, -7.4576e-02,  4.2937e-02,\n",
      "          1.7127e-01,  1.3916e-01, -6.0585e-02],\n",
      "        [ 1.6865e-02,  2.0529e-01, -8.4628e-02, -1.8043e-02,  1.0949e-01,\n",
      "          1.6138e-01, -1.1003e-01,  2.2278e-02],\n",
      "        [-8.4663e-02,  2.9490e-02, -1.1893e-01, -2.1110e-01,  5.8177e-02,\n",
      "         -3.9724e-02, -1.9101e-01, -1.0460e-01],\n",
      "        [-1.5643e-01, -1.4572e-01, -1.9277e-01, -1.2191e-01,  4.5868e-02,\n",
      "          1.7506e-02, -1.3641e-01, -1.2189e-01],\n",
      "        [ 4.2577e-02, -8.7283e-02, -3.2285e-02, -3.3229e-02, -4.0572e-02,\n",
      "          8.7592e-02, -7.7540e-02,  1.4251e-01],\n",
      "        [ 1.9102e-02,  1.0681e-02, -1.0029e-01, -3.2506e-02, -4.5837e-02,\n",
      "          9.6680e-02, -6.3738e-02, -6.8143e-02],\n",
      "        [-4.3546e-02,  1.4480e-01,  1.8656e-02,  2.1396e-02,  1.8113e-01,\n",
      "          1.9612e-01,  8.7727e-02, -1.0073e-02],\n",
      "        [ 1.3843e-03, -7.7008e-02,  4.8828e-02,  2.9499e-02, -1.3404e-02,\n",
      "         -1.3848e-01,  8.2229e-02,  4.5897e-02],\n",
      "        [ 1.1609e-01, -1.8274e-02,  1.8992e-01,  1.4671e-01,  1.5312e-01,\n",
      "          3.9164e-02,  7.8348e-02,  8.6904e-02]], device='cuda:0')\n",
      "rnn3.weight_hh_l0 tensor([[ 0.0550, -0.0357,  0.1771,  ...,  0.0003,  0.1652, -0.0575],\n",
      "        [-0.0361,  0.0740, -0.0567,  ...,  0.1047,  0.1075, -0.0652],\n",
      "        [-0.0309, -0.0755,  0.0639,  ..., -0.0454, -0.1475,  0.0383],\n",
      "        ...,\n",
      "        [ 0.0920, -0.1297,  0.0165,  ..., -0.0142,  0.0830,  0.0112],\n",
      "        [ 0.0327,  0.1485, -0.1715,  ...,  0.0428,  0.0802,  0.1191],\n",
      "        [-0.1233,  0.0172,  0.0701,  ..., -0.0208, -0.0546,  0.0786]],\n",
      "       device='cuda:0')\n",
      "rnn3.bias_ih_l0 tensor([ 0.0005,  0.0472,  0.0475, -0.0290,  0.0220,  0.0949, -0.0558,  0.1735,\n",
      "        -0.0528,  0.0988,  0.0172,  0.1142,  0.0310,  0.0735, -0.0979,  0.1643,\n",
      "        -0.0238, -0.0087, -0.0476, -0.0153,  0.1161,  0.1749, -0.1916,  0.0284,\n",
      "        -0.1728, -0.0258,  0.1332, -0.0895, -0.0255,  0.1395,  0.0206,  0.0297,\n",
      "         0.0803, -0.1040, -0.0920, -0.0159, -0.0805, -0.0097, -0.0418, -0.0592,\n",
      "         0.0223,  0.0430, -0.0266, -0.1623,  0.0750,  0.0859, -0.0345, -0.0033,\n",
      "        -0.0467, -0.0757], device='cuda:0')\n",
      "rnn3.bias_hh_l0 tensor([ 0.1303, -0.0343,  0.0641, -0.0437, -0.0290,  0.1410, -0.0352,  0.1570,\n",
      "         0.0785,  0.0445,  0.1024,  0.0103, -0.1175,  0.0633,  0.0642,  0.0766,\n",
      "        -0.0718,  0.0150, -0.0627, -0.0600,  0.1116,  0.1219, -0.0569, -0.1656,\n",
      "        -0.1321,  0.0370, -0.0146,  0.0227,  0.0757,  0.1147,  0.0591, -0.1631,\n",
      "        -0.0102, -0.1997,  0.0681, -0.1006,  0.1090, -0.0958, -0.0590, -0.0355,\n",
      "         0.1439,  0.0448,  0.2209, -0.0713,  0.0611,  0.1586, -0.0589,  0.0715,\n",
      "         0.0751,  0.0326], device='cuda:0')\n",
      "rnn3.weight_ih_l0_reverse tensor([[ 4.6836e-02,  1.7328e-01,  2.1990e-02,  6.3907e-02, -2.3142e-02,\n",
      "          1.4467e-01, -8.8366e-03,  1.8424e-01],\n",
      "        [-9.0504e-03, -1.7677e-01,  3.3291e-02, -1.3592e-01, -9.4659e-02,\n",
      "         -5.7680e-02, -1.0251e-01, -1.2852e-01],\n",
      "        [ 4.8589e-02, -1.0304e-01, -1.7170e-01, -4.9438e-02,  5.2978e-02,\n",
      "         -3.5157e-02, -2.4984e-02,  8.0833e-02],\n",
      "        [ 2.2604e-02, -1.7012e-01, -1.0994e-01,  9.4638e-02,  4.1310e-02,\n",
      "         -1.4305e-01, -9.7321e-02, -1.4123e-01],\n",
      "        [-3.1653e-02,  1.2136e-01,  3.3211e-02,  3.7078e-02, -1.4804e-01,\n",
      "          7.5066e-04,  4.3513e-02, -1.2819e-01],\n",
      "        [-1.4942e-01, -1.5991e-01, -1.7958e-01, -1.1371e-01, -1.6922e-02,\n",
      "          2.9755e-02, -2.1857e-02, -1.6837e-01],\n",
      "        [-1.8157e-01, -3.5449e-03, -2.1386e-02, -1.4488e-01,  3.0390e-02,\n",
      "         -1.3409e-01, -8.0522e-02, -1.2274e-01],\n",
      "        [-5.0780e-02, -1.4044e-01,  2.0449e-03, -2.3040e-02,  8.7257e-02,\n",
      "         -1.0500e-01,  5.7995e-02,  4.4352e-02],\n",
      "        [-4.5634e-02, -5.3790e-02, -1.2092e-01,  6.7017e-02, -1.2288e-01,\n",
      "         -1.8324e-01, -1.7985e-01, -1.2381e-02],\n",
      "        [-1.2271e-01, -1.0638e-01, -4.3224e-02, -9.5589e-02, -1.4324e-01,\n",
      "         -8.1451e-02, -4.4345e-02, -1.8101e-01],\n",
      "        [-5.3181e-03, -3.6855e-02, -1.6756e-02,  1.2190e-02,  1.0561e-01,\n",
      "         -7.5658e-02,  7.3382e-02,  1.0278e-01],\n",
      "        [ 2.6269e-02,  4.6458e-02,  8.7260e-02,  3.2695e-02,  1.6383e-01,\n",
      "          1.1975e-01, -3.7273e-02, -1.9920e-02],\n",
      "        [-1.1116e-01, -1.4057e-03, -7.9257e-02, -4.9074e-02, -4.6264e-02,\n",
      "         -1.8276e-01, -1.8663e-01, -6.7977e-02],\n",
      "        [-1.0764e-01, -2.0621e-01, -6.3644e-02, -1.7761e-01,  7.5399e-02,\n",
      "          3.8126e-02, -1.8050e-01, -9.0912e-02],\n",
      "        [-4.4542e-02, -4.5186e-02, -6.5629e-02, -1.8640e-01,  6.5399e-02,\n",
      "         -1.3744e-01, -1.6983e-01,  8.5848e-02],\n",
      "        [-1.1857e-01,  2.5087e-02, -1.8510e-01, -5.0534e-02, -5.4773e-02,\n",
      "         -7.2096e-02, -5.4759e-02, -1.7193e-01],\n",
      "        [ 1.0175e-01,  1.5911e-01, -4.4042e-02,  8.2455e-02,  5.4749e-02,\n",
      "          9.7789e-02,  8.8512e-02,  7.2888e-02],\n",
      "        [ 8.1793e-02, -1.3750e-01, -1.7523e-01, -1.1465e-01, -1.2557e-01,\n",
      "          1.2748e-02, -1.5155e-01, -1.1926e-01],\n",
      "        [-1.7414e-01, -1.8054e-01, -1.4237e-03,  3.6474e-02, -5.7569e-02,\n",
      "         -1.5020e-01, -6.4611e-03, -1.2055e-01],\n",
      "        [-4.2932e-02,  3.0126e-02, -1.6065e-01, -1.2644e-01, -9.2590e-02,\n",
      "         -1.1623e-02, -4.2035e-04, -1.4732e-01],\n",
      "        [-1.7829e-01, -1.0538e-01,  6.8663e-02, -1.1258e-01, -4.6462e-02,\n",
      "         -1.4095e-01,  7.9990e-03, -8.5787e-02],\n",
      "        [-2.2934e-02, -2.7253e-02,  1.4301e-01, -4.2294e-02,  1.6644e-01,\n",
      "          3.4431e-02, -4.1424e-02,  2.7550e-02],\n",
      "        [ 2.9767e-02, -1.5675e-02, -1.0206e-01, -1.2912e-01,  1.0517e-02,\n",
      "         -7.3692e-02, -5.3136e-02, -1.8435e-01],\n",
      "        [ 1.6292e-01,  1.8081e-01,  5.3104e-02,  1.7368e-01, -8.6441e-02,\n",
      "         -6.3608e-02, -3.5297e-02,  1.1120e-01],\n",
      "        [ 4.9800e-02,  5.0972e-02,  1.6083e-01,  3.9310e-02,  9.0332e-02,\n",
      "          4.6207e-03,  4.5835e-02,  1.2396e-01],\n",
      "        [-1.1671e-01, -1.4720e-01,  6.0758e-02, -9.4223e-03, -1.2751e-01,\n",
      "         -1.1081e-01, -2.1635e-01, -5.7096e-02],\n",
      "        [ 4.9418e-03, -1.8269e-01, -1.3299e-02, -1.7376e-05,  8.3958e-02,\n",
      "          7.3858e-02,  4.8590e-02,  3.2408e-02],\n",
      "        [ 1.6585e-03, -1.2469e-02, -8.7554e-02, -9.1100e-02, -1.9945e-01,\n",
      "          6.6318e-02, -1.2162e-01,  3.7153e-02],\n",
      "        [ 1.9829e-03,  3.6634e-02,  1.0429e-01, -8.2463e-02,  1.1221e-02,\n",
      "          6.6408e-02, -2.8927e-02,  6.2119e-02],\n",
      "        [-1.5327e-01, -1.7760e-01, -7.3481e-02,  8.0444e-03, -1.6119e-01,\n",
      "         -1.5093e-01, -6.9713e-02, -1.5191e-01],\n",
      "        [ 8.2459e-02, -8.2103e-02, -1.1489e-01,  3.4674e-02, -5.6235e-03,\n",
      "         -1.5059e-01,  2.5500e-02, -1.4890e-02],\n",
      "        [ 1.7794e-01, -8.8313e-03,  4.5359e-02, -1.3224e-02, -4.7804e-02,\n",
      "          5.1898e-02,  2.6852e-02,  1.5068e-01],\n",
      "        [-4.6011e-02,  1.3792e-01,  1.5512e-01,  1.3890e-01, -4.9605e-02,\n",
      "          1.1299e-01,  4.9177e-02, -3.7914e-02],\n",
      "        [-1.6939e-01, -1.8855e-01, -5.2844e-02, -1.6694e-01, -2.5549e-02,\n",
      "         -1.4769e-01, -4.8608e-02,  3.6850e-02],\n",
      "        [ 1.7023e-01,  2.0096e-01, -5.3203e-02,  9.8239e-02,  4.8702e-02,\n",
      "         -5.3010e-02, -6.4512e-02, -7.6600e-02],\n",
      "        [-3.4981e-02,  7.6630e-03,  1.8058e-01,  9.7567e-03,  1.7419e-01,\n",
      "          1.7067e-01,  1.1104e-01,  1.7657e-01],\n",
      "        [ 1.2114e-01,  3.3138e-02, -6.5543e-04,  2.1126e-02,  7.9111e-02,\n",
      "          5.9670e-02,  1.8966e-02,  1.2518e-01],\n",
      "        [ 1.4099e-01,  3.1696e-02,  1.2206e-01,  8.6771e-02,  1.7754e-01,\n",
      "          1.0428e-01, -6.9770e-02,  1.5694e-02],\n",
      "        [-1.0199e-01, -1.2315e-01, -1.1624e-01, -1.4936e-01, -1.7989e-01,\n",
      "         -4.1241e-02, -1.9214e-01,  3.7221e-02],\n",
      "        [ 1.1666e-01,  1.7967e-02,  1.2521e-01,  5.7487e-02,  1.0825e-01,\n",
      "          1.9801e-01, -3.0680e-02,  3.6860e-03],\n",
      "        [-1.9891e-02, -8.9100e-02,  4.6323e-02, -8.9743e-03,  5.4202e-02,\n",
      "          1.7665e-01,  1.8464e-01, -3.5682e-02],\n",
      "        [ 9.7948e-03, -3.9144e-02, -1.5737e-01,  4.7513e-02,  6.0985e-02,\n",
      "          1.1775e-02,  6.1980e-02,  9.6063e-03],\n",
      "        [-1.2372e-02,  1.3164e-02, -2.2807e-02,  5.4410e-02, -1.4428e-01,\n",
      "          3.1552e-04, -1.0808e-01, -1.4818e-01],\n",
      "        [-6.2040e-03,  7.1878e-03, -7.6399e-03, -5.5912e-03, -2.3256e-04,\n",
      "          9.4102e-02, -2.9739e-02,  1.0020e-01],\n",
      "        [-8.2148e-02, -6.1384e-05, -4.8647e-02,  1.6184e-01,  8.6243e-02,\n",
      "          1.9135e-01,  4.9103e-02,  5.1975e-02],\n",
      "        [ 9.3182e-03,  2.1111e-02,  1.2034e-01,  1.9318e-01,  1.5208e-01,\n",
      "          4.0722e-02, -1.7588e-02, -6.7463e-02],\n",
      "        [ 1.8376e-01, -8.3380e-02,  1.4922e-01, -5.1593e-02, -6.7307e-03,\n",
      "          1.1300e-01,  1.4134e-01,  3.0012e-02],\n",
      "        [-1.6071e-01, -8.5998e-03, -1.7625e-01, -4.8971e-02,  6.7554e-02,\n",
      "         -5.6267e-02, -1.6359e-01, -2.0194e-02],\n",
      "        [ 4.3147e-02,  3.4560e-02, -1.7388e-01,  5.9025e-02,  2.9212e-02,\n",
      "         -5.1151e-02,  6.1020e-02, -1.0012e-01],\n",
      "        [-5.3550e-02,  6.0111e-02,  8.5350e-02, -1.9621e-02,  9.9990e-02,\n",
      "          9.1062e-03, -7.1886e-02,  4.8687e-02]], device='cuda:0')\n",
      "rnn3.weight_hh_l0_reverse tensor([[ 1.3897e-01, -1.6571e-01,  1.6396e-01,  ..., -6.3240e-03,\n",
      "         -1.4249e-02,  1.8995e-01],\n",
      "        [ 1.1326e-01, -9.1638e-02, -1.5034e-01,  ...,  9.6866e-02,\n",
      "         -1.7896e-02, -6.9270e-02],\n",
      "        [-1.0455e-01, -1.3642e-01,  1.7767e-01,  ..., -7.4957e-02,\n",
      "         -1.8326e-03,  4.5085e-02],\n",
      "        ...,\n",
      "        [-7.9586e-02,  7.7901e-02,  5.0403e-02,  ..., -8.9638e-02,\n",
      "         -7.6950e-02,  2.5965e-02],\n",
      "        [ 1.5899e-04, -1.7328e-01,  8.9975e-02,  ..., -2.2571e-02,\n",
      "          1.5871e-01,  6.9876e-02],\n",
      "        [ 3.7885e-03, -5.6841e-02, -2.7659e-02,  ...,  1.8308e-02,\n",
      "         -2.5788e-03, -1.4302e-01]], device='cuda:0')\n",
      "rnn3.bias_ih_l0_reverse tensor([ 0.1501, -0.0659, -0.0047,  0.0066,  0.0728,  0.0319,  0.0050, -0.1138,\n",
      "        -0.1018, -0.0756,  0.1051, -0.0697,  0.0374, -0.1375, -0.1721,  0.0628,\n",
      "         0.1234,  0.0285,  0.0663,  0.0016, -0.2038,  0.0599, -0.0731,  0.0826,\n",
      "         0.1385,  0.0914, -0.0761, -0.1667,  0.1764, -0.0252, -0.0479, -0.1006,\n",
      "        -0.0483, -0.1850,  0.1949,  0.0265, -0.0252,  0.1135,  0.0699,  0.0082,\n",
      "         0.0450, -0.0869, -0.0359,  0.0094,  0.1618,  0.1683,  0.1174, -0.1406,\n",
      "        -0.0361, -0.0165], device='cuda:0')\n",
      "rnn3.bias_hh_l0_reverse tensor([-0.0282, -0.0856,  0.0522, -0.0777,  0.0106,  0.0805, -0.0803, -0.0660,\n",
      "        -0.0571,  0.0505, -0.0266, -0.0715, -0.0059, -0.0318, -0.0424, -0.0889,\n",
      "         0.1629,  0.0673, -0.1169,  0.0229,  0.0356,  0.0873, -0.2024,  0.1368,\n",
      "         0.0378, -0.1398, -0.0955, -0.0244,  0.1862,  0.0280, -0.0711, -0.0126,\n",
      "         0.1388,  0.0040,  0.0136,  0.1780,  0.0544, -0.0572,  0.0206,  0.0218,\n",
      "         0.0782, -0.1844, -0.1445,  0.0959,  0.1619,  0.0514,  0.0126, -0.1291,\n",
      "         0.0864,  0.0781], device='cuda:0')\n",
      "rnn4.weight_ih_l0 tensor([[ 1.4283e-01,  1.2633e-01, -7.6463e-02, -8.4519e-02,  1.4828e-01,\n",
      "          8.4060e-02,  6.1474e-02,  7.5096e-02],\n",
      "        [ 7.6704e-02,  6.3659e-02,  1.9135e-01,  7.7152e-02,  9.2174e-02,\n",
      "          1.3872e-01,  1.0862e-01, -6.1559e-02],\n",
      "        [ 1.3588e-01,  6.5060e-02, -6.9459e-02,  1.1431e-01,  1.2527e-01,\n",
      "          1.8866e-01,  7.4822e-02,  6.2294e-02],\n",
      "        [-1.8521e-01, -1.2136e-01,  6.9330e-02, -6.1287e-02, -9.1509e-02,\n",
      "         -1.4209e-01, -7.4169e-02,  2.6153e-02],\n",
      "        [ 6.1091e-02, -6.3016e-02,  7.8409e-02, -3.4033e-02, -1.5556e-01,\n",
      "         -1.2461e-01, -9.4233e-02, -1.8432e-01],\n",
      "        [ 2.7341e-04, -4.6047e-02,  2.8295e-02, -1.8225e-01, -1.3284e-01,\n",
      "         -4.0760e-02, -4.3525e-02, -6.9249e-02],\n",
      "        [-8.1126e-02, -2.8133e-02, -3.7374e-02, -1.8395e-01, -1.1099e-01,\n",
      "          4.1517e-02, -1.7658e-01,  2.9958e-02],\n",
      "        [ 9.2149e-02, -3.4738e-02, -1.9101e-02,  1.4722e-01, -4.8573e-02,\n",
      "          1.2487e-01,  8.7540e-02, -2.9754e-02],\n",
      "        [ 3.3124e-02, -1.8291e-01, -1.8689e-01,  4.9968e-02, -1.4568e-03,\n",
      "         -1.0677e-01,  1.1696e-02, -1.0879e-01],\n",
      "        [-1.8478e-02, -8.8010e-02, -1.5062e-01,  6.5908e-02, -5.7478e-02,\n",
      "          7.6380e-02, -1.5605e-02,  8.3882e-02],\n",
      "        [-1.4913e-01,  1.0865e-02, -1.9540e-02,  1.1836e-01, -1.4070e-02,\n",
      "          5.2322e-02,  1.0400e-01,  1.2328e-01],\n",
      "        [-1.2982e-01,  2.4227e-02, -1.4352e-02, -6.7902e-02, -2.2132e-02,\n",
      "          3.6842e-02,  3.5957e-02,  2.6015e-02],\n",
      "        [ 8.4475e-02,  1.0836e-02,  4.6595e-02,  1.3530e-01,  1.1586e-01,\n",
      "          4.0226e-02,  1.8699e-01, -5.7011e-02],\n",
      "        [-3.6000e-02, -4.1078e-02, -9.6102e-02, -9.7535e-02, -1.8308e-01,\n",
      "          3.8050e-02,  1.0141e-01, -1.1702e-01],\n",
      "        [-2.3747e-02, -1.1892e-01, -3.8169e-03, -5.5475e-02, -2.8813e-02,\n",
      "         -1.8630e-02, -1.3363e-01,  2.4532e-03],\n",
      "        [-5.0432e-02,  9.5028e-03,  1.9465e-01, -2.2790e-02,  1.5348e-01,\n",
      "          8.5494e-02,  4.7636e-02,  4.0038e-03],\n",
      "        [ 7.4754e-02,  1.6548e-01,  5.5476e-02,  9.9252e-02, -9.1706e-02,\n",
      "          1.9620e-02,  1.3577e-01, -6.8803e-02],\n",
      "        [ 1.7713e-01,  1.0724e-01, -5.6066e-02,  6.8437e-02,  1.1153e-01,\n",
      "          5.2371e-02,  1.0284e-01,  7.5311e-02],\n",
      "        [ 8.1985e-02, -1.8605e-01,  8.0412e-03, -1.5313e-01, -8.7902e-03,\n",
      "         -6.5079e-02,  8.1967e-02,  3.5044e-05],\n",
      "        [ 1.8414e-01, -5.6639e-02,  9.4209e-02,  1.3193e-02, -4.6125e-04,\n",
      "         -2.9137e-02,  1.3315e-01, -4.8967e-02],\n",
      "        [-2.7153e-02, -6.2916e-02,  1.1416e-01,  1.7043e-01,  6.3337e-02,\n",
      "          1.6167e-01,  1.1818e-03, -2.2576e-02],\n",
      "        [-1.9425e-01, -6.1297e-02,  3.9965e-02, -1.7846e-01, -9.0445e-02,\n",
      "          7.4244e-02, -2.4738e-02, -1.3688e-01],\n",
      "        [ 4.1405e-02,  9.6457e-02,  8.1220e-02, -8.1138e-03,  1.1709e-01,\n",
      "          1.1811e-01,  9.8409e-02,  8.6093e-02],\n",
      "        [-5.1059e-02,  9.2317e-02, -7.3896e-02, -2.3838e-02, -5.7740e-02,\n",
      "         -2.4932e-02, -1.7233e-02, -5.2992e-02],\n",
      "        [-6.0213e-02, -8.2521e-02,  6.5890e-02, -3.1097e-02, -1.6725e-01,\n",
      "          4.6097e-03,  2.0368e-03, -9.9618e-02],\n",
      "        [-1.8002e-01, -1.8052e-01,  6.4116e-02, -1.8863e-01, -1.0222e-01,\n",
      "          3.7584e-04, -1.8229e-01, -1.3069e-01],\n",
      "        [-1.1631e-01,  7.2753e-02, -1.1266e-01, -7.1879e-02, -1.0837e-01,\n",
      "         -1.5485e-01,  1.5461e-02, -8.2555e-02],\n",
      "        [-3.3137e-02,  5.2130e-02,  1.0338e-01,  7.2043e-02, -5.8872e-03,\n",
      "          1.3133e-01,  1.6103e-02,  7.5251e-02],\n",
      "        [ 1.8781e-03,  1.6978e-01,  1.6749e-01,  5.1945e-02,  2.0012e-01,\n",
      "         -3.1061e-02,  4.9826e-02,  7.1821e-02],\n",
      "        [-1.9444e-01,  5.6033e-02, -1.8756e-02, -1.6775e-01, -1.3999e-01,\n",
      "         -8.2949e-02, -1.6650e-01,  6.1203e-03],\n",
      "        [-5.0640e-02, -9.7515e-02, -1.6166e-02,  3.5474e-02, -1.1422e-01,\n",
      "         -1.6489e-01,  6.8400e-02, -3.1563e-03],\n",
      "        [ 1.3827e-01,  1.6424e-01, -9.3972e-03,  9.9491e-02,  2.7400e-02,\n",
      "          2.0434e-01, -4.5236e-02, -3.0695e-02],\n",
      "        [-1.2587e-01, -1.7949e-01, -8.6744e-02, -4.2754e-02, -1.5506e-01,\n",
      "         -4.3976e-04, -1.4951e-01, -1.4642e-01],\n",
      "        [-1.1050e-03, -1.7248e-01, -1.5875e-01, -4.5846e-02, -1.2667e-01,\n",
      "         -1.8955e-01, -1.7605e-01, -1.5820e-03],\n",
      "        [ 1.5849e-01, -6.5646e-02, -6.3503e-02, -8.4190e-02,  1.9929e-01,\n",
      "          1.8472e-01,  9.6766e-02,  1.0006e-01],\n",
      "        [-7.5732e-02, -7.0429e-02,  3.6515e-02,  1.3197e-02, -5.5602e-02,\n",
      "         -2.6639e-02,  6.8600e-02,  3.7745e-02],\n",
      "        [ 7.0595e-02,  4.2750e-02, -6.4706e-02, -1.8635e-02,  5.9325e-02,\n",
      "         -1.2437e-01, -1.5553e-01,  5.0567e-02],\n",
      "        [ 6.6730e-02, -1.1090e-01, -1.5005e-01, -8.3621e-03, -1.1922e-01,\n",
      "          5.7957e-02, -3.4094e-02, -1.7751e-01],\n",
      "        [ 3.9374e-02, -6.9855e-02, -1.9976e-01,  1.4998e-01, -1.4268e-01,\n",
      "          2.6311e-02, -1.1558e-01, -6.6637e-02],\n",
      "        [ 7.6906e-02, -1.6872e-01, -1.0697e-01,  4.4738e-02, -2.3746e-02,\n",
      "          4.4994e-02,  3.2132e-02,  4.0086e-02],\n",
      "        [ 6.0167e-02,  8.1864e-02,  3.8456e-02,  6.4233e-02, -5.3402e-02,\n",
      "          5.4994e-02, -4.6898e-02, -2.3183e-02],\n",
      "        [-5.0060e-02,  3.0927e-02, -2.1496e-02,  1.7329e-01,  6.8759e-02,\n",
      "          1.8296e-01, -4.3562e-02,  9.4757e-02],\n",
      "        [-5.4864e-05,  2.8158e-02, -3.3548e-02,  8.8660e-02, -1.3637e-01,\n",
      "          3.2149e-02,  1.3580e-02, -1.4963e-01],\n",
      "        [-6.8212e-02,  6.3617e-02, -1.1493e-01,  2.3307e-02,  2.1414e-02,\n",
      "          8.0529e-02, -9.4062e-02,  8.4946e-02],\n",
      "        [ 1.0997e-01,  9.6402e-02, -6.1105e-02,  1.7158e-01, -1.2584e-02,\n",
      "         -2.9847e-02,  1.6335e-01,  1.5178e-01],\n",
      "        [ 1.7030e-02, -9.7287e-02, -8.4654e-02, -7.0461e-02, -1.6585e-01,\n",
      "         -1.7868e-01, -3.1797e-02,  3.5083e-02],\n",
      "        [-2.2758e-02,  7.8249e-02, -1.4435e-01, -2.1502e-02,  6.4671e-02,\n",
      "         -4.6534e-02, -1.8086e-02, -1.1034e-01],\n",
      "        [ 1.7404e-01,  5.0609e-02,  1.1732e-01,  1.3750e-02,  6.6738e-02,\n",
      "          7.7854e-02, -3.5894e-02,  1.8747e-01],\n",
      "        [-1.3726e-01, -1.1744e-01,  2.4128e-02, -1.9172e-01,  4.2574e-02,\n",
      "         -9.4378e-02, -1.7943e-01,  6.6632e-02],\n",
      "        [-1.1890e-02,  1.0649e-01, -6.0348e-02,  1.2940e-01, -1.1936e-01,\n",
      "          2.8859e-02, -8.5421e-04,  9.8295e-02]], device='cuda:0')\n",
      "rnn4.weight_hh_l0 tensor([[-0.0575,  0.0436,  0.0021,  ..., -0.0473,  0.0175, -0.0341],\n",
      "        [ 0.0455, -0.0713,  0.0192,  ...,  0.1834, -0.0775, -0.1182],\n",
      "        [ 0.0714,  0.1284,  0.2152,  ...,  0.0209, -0.0148, -0.1485],\n",
      "        ...,\n",
      "        [-0.1730, -0.0417, -0.0269,  ...,  0.1518,  0.1056, -0.0812],\n",
      "        [ 0.1824, -0.1183, -0.0655,  ...,  0.0552, -0.0261,  0.0591],\n",
      "        [ 0.0740, -0.0765, -0.0030,  ...,  0.0241, -0.0895, -0.0210]],\n",
      "       device='cuda:0')\n",
      "rnn4.bias_ih_l0 tensor([-0.0463,  0.1210,  0.0567, -0.0672, -0.0846, -0.0524, -0.1792,  0.0214,\n",
      "         0.0243,  0.0251,  0.1220,  0.1030, -0.0456, -0.0149,  0.0722,  0.1883,\n",
      "         0.1767,  0.0422, -0.0401, -0.0231,  0.1756, -0.0028,  0.0145, -0.0254,\n",
      "         0.0227, -0.0201, -0.1139,  0.0761,  0.0683,  0.0334, -0.1854,  0.1928,\n",
      "        -0.1910, -0.1841, -0.0418, -0.0528, -0.1926, -0.0163, -0.0299,  0.0069,\n",
      "         0.0757, -0.0276,  0.0613, -0.0832,  0.1041, -0.0392, -0.1697,  0.1327,\n",
      "         0.0280, -0.0148], device='cuda:0')\n",
      "rnn4.bias_hh_l0 tensor([ 0.0757,  0.1169, -0.0016, -0.0093, -0.0616, -0.0950, -0.0772,  0.1431,\n",
      "        -0.0187, -0.0837,  0.1475, -0.0777,  0.0386,  0.0120, -0.0764, -0.0675,\n",
      "        -0.0883,  0.0926,  0.0242, -0.0832,  0.0442,  0.0293,  0.0698, -0.0593,\n",
      "         0.0420,  0.0678,  0.0272, -0.0394,  0.0469, -0.1130,  0.0474, -0.0202,\n",
      "         0.0451,  0.0173,  0.0138,  0.0250, -0.1653, -0.1125, -0.0531, -0.0847,\n",
      "         0.0432,  0.1684, -0.1646, -0.0357,  0.0439, -0.0838,  0.0787,  0.0904,\n",
      "         0.0458,  0.0615], device='cuda:0')\n",
      "rnn4.weight_ih_l0_reverse tensor([[-0.0173,  0.1278, -0.0662,  0.0363,  0.1520,  0.0867,  0.0348,  0.1463],\n",
      "        [-0.0297, -0.0511, -0.1607, -0.0808, -0.0839, -0.0888, -0.1761, -0.0155],\n",
      "        [ 0.1528, -0.0824,  0.0067,  0.0906,  0.1286,  0.0710, -0.0120,  0.0355],\n",
      "        [-0.1880, -0.1867, -0.1360,  0.0042, -0.0977,  0.0138,  0.0249, -0.1232],\n",
      "        [ 0.0555,  0.0427, -0.0998,  0.0100,  0.0253,  0.0787, -0.1037, -0.0821],\n",
      "        [ 0.0020, -0.0699,  0.1564,  0.1027, -0.0248,  0.1128, -0.0199, -0.0057],\n",
      "        [ 0.0134,  0.0067,  0.0332, -0.0643, -0.0666,  0.0957,  0.0957,  0.0089],\n",
      "        [ 0.0180,  0.0472,  0.0133,  0.0543,  0.0566, -0.0742, -0.0567,  0.0152],\n",
      "        [ 0.0812, -0.1175, -0.0893,  0.0643,  0.0761, -0.0337, -0.0821,  0.0659],\n",
      "        [ 0.0143, -0.1709, -0.1095, -0.0919,  0.0302, -0.0444,  0.0856, -0.0844],\n",
      "        [ 0.0747,  0.0960, -0.0511,  0.0314,  0.1662,  0.0772,  0.1825, -0.0277],\n",
      "        [-0.1237, -0.0852, -0.1008, -0.0888, -0.1070, -0.0612, -0.1945, -0.1833],\n",
      "        [ 0.0762,  0.0225, -0.0881, -0.0015, -0.1874,  0.0378,  0.0542, -0.0130],\n",
      "        [ 0.1430,  0.0753, -0.0537,  0.1456,  0.1422, -0.0361,  0.1762,  0.0543],\n",
      "        [ 0.0870,  0.0224,  0.0521,  0.0315, -0.0452,  0.0519,  0.0834, -0.0797],\n",
      "        [-0.1551, -0.0648, -0.0040, -0.0755,  0.0506,  0.0672,  0.0175, -0.1949],\n",
      "        [ 0.1466, -0.0088, -0.0896, -0.0274, -0.0538,  0.0103,  0.1039, -0.0651],\n",
      "        [ 0.0818, -0.0038,  0.0296, -0.0186, -0.1095, -0.0697,  0.0407, -0.1714],\n",
      "        [-0.0244, -0.0602, -0.1149, -0.0950, -0.1419, -0.0207, -0.0943, -0.0040],\n",
      "        [-0.1778, -0.1727, -0.0977, -0.0975, -0.0235, -0.1283, -0.1490, -0.1499],\n",
      "        [ 0.1663,  0.1442,  0.0548,  0.0023,  0.1462,  0.0207,  0.1866,  0.1112],\n",
      "        [ 0.0753, -0.0096, -0.0216, -0.0035, -0.1895, -0.1097, -0.1106, -0.1649],\n",
      "        [-0.1531,  0.0393,  0.0027, -0.0196,  0.0516, -0.0249, -0.0214, -0.0888],\n",
      "        [ 0.0407,  0.0796, -0.0431,  0.1525, -0.0010,  0.1170,  0.1798,  0.0638],\n",
      "        [-0.0689,  0.0589, -0.0756,  0.1788, -0.0697, -0.0562,  0.1334,  0.1415],\n",
      "        [ 0.0992,  0.0598, -0.1382, -0.0341, -0.0247, -0.0311, -0.1134, -0.1434],\n",
      "        [ 0.0392,  0.0192, -0.0235,  0.0127,  0.1110,  0.0448,  0.0785,  0.0504],\n",
      "        [ 0.0275, -0.0932,  0.0521, -0.0910, -0.0336, -0.0383, -0.2065,  0.0980],\n",
      "        [ 0.0789,  0.0303,  0.1527, -0.0980,  0.0093,  0.0901,  0.1373,  0.0802],\n",
      "        [ 0.0957,  0.0003, -0.0504,  0.1408, -0.0718,  0.1756,  0.1797, -0.0476],\n",
      "        [-0.1092, -0.1177, -0.0159, -0.1036, -0.0381,  0.0612, -0.1821,  0.0155],\n",
      "        [-0.1427, -0.1617,  0.0310, -0.1733, -0.0721, -0.0376,  0.0710, -0.0158],\n",
      "        [ 0.2072, -0.0707,  0.1137, -0.0555,  0.1172,  0.1564,  0.0762, -0.0758],\n",
      "        [ 0.1011, -0.0563,  0.1709, -0.0734,  0.0342, -0.0304,  0.0395, -0.0857],\n",
      "        [ 0.0209,  0.1586, -0.0056, -0.0742,  0.1896,  0.0865,  0.1062, -0.0453],\n",
      "        [-0.0026, -0.0416, -0.0663,  0.0974,  0.1025,  0.0893,  0.1868,  0.1255],\n",
      "        [ 0.0774, -0.0488, -0.0353, -0.1843, -0.1258, -0.1130,  0.0280, -0.1432],\n",
      "        [ 0.0249, -0.0729,  0.0557,  0.0675, -0.0584, -0.1451,  0.0417, -0.1338],\n",
      "        [-0.1041, -0.1005, -0.0234, -0.0217,  0.0080,  0.0483, -0.0152, -0.0041],\n",
      "        [ 0.0938,  0.0665, -0.0686, -0.0172,  0.1855,  0.0221,  0.1830,  0.1092],\n",
      "        [-0.0112,  0.0386,  0.0005, -0.0675, -0.0314, -0.1664, -0.1373, -0.1400],\n",
      "        [ 0.0549, -0.0419, -0.0150,  0.0122, -0.0086,  0.1708, -0.0120,  0.0380],\n",
      "        [-0.0147,  0.0644, -0.0784, -0.0200,  0.0587,  0.0795,  0.0572,  0.0463],\n",
      "        [ 0.1032,  0.1680,  0.0889,  0.1052,  0.0310,  0.1153, -0.0714,  0.0931],\n",
      "        [-0.1683, -0.1576, -0.1915, -0.1048,  0.0493, -0.0768, -0.1051, -0.0424],\n",
      "        [ 0.0969,  0.0913,  0.0580,  0.0275, -0.0847, -0.0741,  0.0698,  0.0334],\n",
      "        [-0.0776, -0.0425,  0.0886, -0.0752,  0.0071,  0.1423,  0.1337,  0.0588],\n",
      "        [ 0.1802, -0.0276, -0.0172,  0.0929,  0.0349,  0.1449,  0.1247,  0.0967],\n",
      "        [-0.1636, -0.1528,  0.0654, -0.1104, -0.0015, -0.0482, -0.1630, -0.1428],\n",
      "        [-0.0806, -0.0831, -0.0898,  0.0877, -0.1239,  0.0661, -0.1095,  0.0117]],\n",
      "       device='cuda:0')\n",
      "rnn4.weight_hh_l0_reverse tensor([[ 0.1849, -0.1875,  0.0063,  ...,  0.0052, -0.1661, -0.1889],\n",
      "        [-0.1044,  0.0144, -0.1574,  ..., -0.1212,  0.0292,  0.0764],\n",
      "        [-0.0004, -0.0277, -0.0875,  ...,  0.0632, -0.1006,  0.1696],\n",
      "        ...,\n",
      "        [ 0.1167,  0.0557, -0.0322,  ..., -0.0759,  0.0450,  0.1632],\n",
      "        [-0.1901,  0.1576,  0.0081,  ..., -0.1408,  0.1625,  0.0370],\n",
      "        [ 0.0557,  0.1881, -0.1756,  ...,  0.0340,  0.1339,  0.0728]],\n",
      "       device='cuda:0')\n",
      "rnn4.bias_ih_l0_reverse tensor([ 0.1160, -0.0395, -0.0023,  0.0700,  0.0571, -0.0466, -0.0709, -0.0490,\n",
      "        -0.0998, -0.1439, -0.0181, -0.0243,  0.0777,  0.1666, -0.0310,  0.0185,\n",
      "        -0.0379, -0.0809,  0.0132, -0.0763,  0.1574, -0.1811, -0.0557,  0.0942,\n",
      "         0.1597,  0.0191, -0.0793,  0.1258, -0.0464,  0.0999, -0.1875, -0.1230,\n",
      "        -0.0573,  0.1292, -0.0500, -0.0437, -0.0740, -0.0933, -0.1524,  0.0852,\n",
      "         0.0674,  0.1613,  0.1242,  0.1668, -0.0293,  0.1125, -0.0847,  0.0721,\n",
      "        -0.0759, -0.0045], device='cuda:0')\n",
      "rnn4.bias_hh_l0_reverse tensor([-0.0130, -0.0134,  0.0785, -0.0521, -0.1290,  0.1312,  0.1622, -0.0493,\n",
      "         0.0372, -0.0596,  0.0254,  0.0245,  0.0442,  0.0678,  0.0456, -0.1469,\n",
      "         0.0230, -0.0513, -0.0209, -0.1132,  0.0844, -0.1421,  0.0067,  0.0712,\n",
      "         0.0803, -0.1636,  0.1709, -0.0442, -0.1202, -0.0503, -0.1755,  0.0393,\n",
      "         0.1960,  0.0758,  0.1626,  0.0895, -0.0718, -0.0704,  0.0212,  0.0908,\n",
      "        -0.1133, -0.0253,  0.0260,  0.1302, -0.1511, -0.0257,  0.1120, -0.0248,\n",
      "        -0.1892, -0.0900], device='cuda:0')\n",
      "rnn5.weight_ih_l0 tensor([[ 1.1651e-02, -1.3017e-01, -1.6420e-02,  4.7602e-02,  9.6654e-02,\n",
      "         -7.1096e-03,  7.0723e-02, -5.0483e-02],\n",
      "        [ 1.8357e-02,  2.3486e-03, -6.3031e-02,  5.8731e-02, -1.0207e-02,\n",
      "         -1.9212e-01, -1.2078e-01,  7.4380e-02],\n",
      "        [-1.5476e-01,  4.0798e-02, -1.3961e-01, -3.1055e-02,  7.9726e-02,\n",
      "          1.3591e-01, -1.2611e-04, -6.0160e-02],\n",
      "        [-1.4505e-01, -8.2425e-02, -5.8989e-02,  1.3786e-01, -1.5424e-01,\n",
      "         -7.2673e-02, -8.3918e-02,  1.3361e-01],\n",
      "        [-1.4855e-01,  5.7973e-02,  8.2210e-02, -1.7916e-02,  3.6433e-02,\n",
      "         -1.2015e-01,  2.8112e-02,  1.2326e-01],\n",
      "        [-8.0518e-02,  6.1257e-02,  1.4274e-01, -1.3752e-01,  1.2372e-01,\n",
      "         -5.1602e-02,  1.2690e-01, -8.5246e-02],\n",
      "        [-9.5642e-02,  1.0592e-01,  7.8119e-02,  7.7658e-02, -1.8012e-03,\n",
      "          7.4109e-02, -3.3577e-02, -2.9829e-03],\n",
      "        [ 1.4908e-01, -9.6899e-02,  2.7454e-02, -6.0729e-02,  7.5624e-02,\n",
      "         -9.6379e-02, -1.3093e-01,  6.5185e-02],\n",
      "        [ 1.8716e-01,  5.7110e-02, -4.1834e-02,  8.6684e-02,  1.6523e-01,\n",
      "         -1.6994e-01, -8.9054e-03, -5.6156e-02],\n",
      "        [-1.3218e-01,  1.6776e-01, -2.4165e-02,  1.2243e-01, -4.1393e-02,\n",
      "         -3.5009e-02,  1.4018e-03, -7.3379e-02],\n",
      "        [-9.7579e-02,  2.8966e-02, -5.6714e-03,  9.1765e-03,  1.0414e-01,\n",
      "          8.8317e-02,  5.3954e-02,  9.7647e-03],\n",
      "        [ 4.2346e-02,  4.4593e-03,  4.5395e-02,  6.1662e-02,  1.9297e-02,\n",
      "          3.7170e-02,  1.5369e-01, -3.2623e-02],\n",
      "        [-1.0410e-01, -1.8947e-02, -1.6565e-01,  1.7995e-01,  1.9400e-02,\n",
      "          1.7296e-01,  5.6632e-02,  1.0767e-01],\n",
      "        [-6.6001e-02,  1.0641e-01, -8.7460e-02,  1.8680e-02, -7.5931e-02,\n",
      "         -7.1870e-02,  1.3076e-01, -1.6744e-01],\n",
      "        [-8.8025e-03,  1.2221e-01, -1.6338e-01,  1.8359e-01, -8.2799e-02,\n",
      "         -2.6324e-02, -1.7143e-01,  1.4526e-01],\n",
      "        [-5.9065e-02, -4.3872e-02,  1.2726e-01, -6.2967e-02,  8.0449e-02,\n",
      "         -1.7239e-01, -2.7487e-02, -6.4359e-02],\n",
      "        [ 1.2829e-01, -1.3780e-01, -2.2180e-02,  4.1409e-02,  3.8755e-02,\n",
      "          9.2051e-02,  7.7756e-02, -1.1692e-02],\n",
      "        [-8.1471e-02,  3.1632e-03, -2.6474e-02,  4.4804e-02, -1.8967e-01,\n",
      "         -2.6147e-02, -4.2044e-02,  3.2393e-02],\n",
      "        [ 1.1776e-01, -9.7420e-03,  5.9946e-02, -1.9288e-02,  1.5340e-01,\n",
      "         -1.3198e-01, -9.8594e-02, -9.3519e-02],\n",
      "        [-7.0494e-02, -3.5840e-02,  6.3313e-02, -1.0905e-01,  4.9462e-02,\n",
      "         -5.8132e-02, -9.4954e-02,  2.1225e-03],\n",
      "        [ 1.6692e-01,  7.2979e-02,  1.3348e-03, -3.5980e-02, -3.6338e-02,\n",
      "         -1.4622e-01,  9.4565e-02,  1.2654e-02],\n",
      "        [ 1.1633e-01, -2.1796e-03, -1.1833e-02,  4.2733e-02,  3.4061e-02,\n",
      "         -1.8662e-03,  1.6781e-01,  2.0835e-02],\n",
      "        [ 9.4405e-03, -1.6451e-01,  7.6886e-02, -2.1091e-02,  1.7345e-01,\n",
      "          4.7384e-02, -5.3350e-02, -1.1016e-02],\n",
      "        [-1.4807e-01,  1.2616e-01, -1.3948e-01,  1.5067e-01, -1.7665e-01,\n",
      "          8.0977e-02,  6.1132e-03,  1.4030e-01],\n",
      "        [-1.3507e-02,  1.7471e-01, -1.5548e-01,  1.0514e-01, -5.0389e-02,\n",
      "          2.1276e-02, -4.8071e-02,  1.4759e-01],\n",
      "        [ 7.6695e-02,  3.9004e-02,  1.0779e-01, -9.5180e-02, -3.5295e-03,\n",
      "         -1.6934e-01,  3.4983e-02, -5.3789e-02],\n",
      "        [ 5.0347e-02, -1.2278e-01, -6.3659e-02,  2.5059e-02,  7.6119e-02,\n",
      "         -7.2994e-02,  1.5430e-02, -6.2437e-02],\n",
      "        [-5.1848e-02, -2.9301e-02,  1.0276e-02, -3.9498e-02, -7.8093e-02,\n",
      "          1.7310e-01, -1.7706e-01, -4.0504e-02],\n",
      "        [-6.1098e-02, -4.3780e-02,  1.6420e-01,  8.3124e-02,  1.3207e-02,\n",
      "         -5.6015e-02,  1.1817e-01,  4.7578e-02],\n",
      "        [ 4.5849e-02, -4.6132e-02,  4.8062e-02,  7.8410e-02, -1.5332e-01,\n",
      "          3.2356e-02,  4.7984e-02,  6.8891e-02],\n",
      "        [ 7.2222e-02, -1.4308e-01,  8.2575e-02, -7.7869e-02, -3.0167e-02,\n",
      "         -1.5775e-02, -1.1173e-01, -8.1368e-02],\n",
      "        [ 4.0925e-02,  1.5294e-01, -8.3871e-02, -6.0281e-02, -8.0516e-02,\n",
      "          3.9612e-02, -7.6190e-02,  4.9902e-02],\n",
      "        [-2.8254e-02,  7.6789e-02, -1.3273e-01,  5.6504e-02, -1.8693e-01,\n",
      "          4.1619e-02, -7.7992e-02, -7.6306e-02],\n",
      "        [ 5.8252e-02,  1.4984e-01,  5.7015e-02,  1.0152e-01,  1.9485e-01,\n",
      "         -1.1359e-01, -2.8108e-03,  1.5777e-02],\n",
      "        [ 8.9321e-02, -4.9733e-03,  1.4531e-01, -1.0278e-01,  1.5825e-02,\n",
      "         -1.4514e-01, -4.5851e-02, -1.0661e-01],\n",
      "        [ 1.5774e-01, -2.3253e-02,  6.6826e-02,  1.6926e-02, -1.5766e-02,\n",
      "         -1.0934e-01, -3.0810e-02, -8.7079e-02],\n",
      "        [ 3.3470e-03,  7.3810e-02,  8.2658e-03,  7.6153e-02, -1.8274e-01,\n",
      "         -8.6891e-02, -1.3343e-01,  5.1274e-02],\n",
      "        [ 4.4966e-03,  2.5869e-02,  1.9413e-02,  8.9426e-02, -8.5860e-02,\n",
      "         -1.1043e-02, -5.3347e-02,  5.6334e-02],\n",
      "        [ 1.0626e-01, -8.1674e-02,  9.5630e-02, -1.0602e-01, -4.2069e-02,\n",
      "         -9.3336e-02,  1.2500e-01, -4.0974e-02],\n",
      "        [-3.7001e-02, -5.5860e-02,  4.0698e-02, -7.7190e-03,  9.8481e-02,\n",
      "         -4.2979e-02, -1.2190e-01,  7.3987e-02],\n",
      "        [ 3.9065e-03, -5.5381e-02, -5.3140e-02,  7.5135e-02,  1.6179e-01,\n",
      "         -1.6130e-01, -6.2757e-03,  5.8212e-02],\n",
      "        [ 1.1935e-01, -1.0662e-01,  1.7090e-01,  5.8093e-02,  5.1724e-02,\n",
      "          3.5761e-02,  1.8365e-01, -8.4198e-02],\n",
      "        [-4.8864e-02, -4.8566e-02,  8.6414e-02,  2.6007e-02,  1.2519e-01,\n",
      "         -8.2840e-02, -1.6146e-02,  1.5793e-02],\n",
      "        [ 2.4527e-02,  1.2543e-01, -1.6808e-01, -4.4791e-02, -1.9039e-01,\n",
      "          1.4882e-01, -4.4337e-02, -2.1920e-02],\n",
      "        [-1.4975e-02, -6.9916e-02,  1.1342e-01, -1.6442e-03, -6.9798e-02,\n",
      "          6.4717e-02,  7.7647e-02, -3.9164e-02],\n",
      "        [-1.9367e-01,  2.4172e-03, -1.0905e-01,  8.4425e-02, -1.5856e-01,\n",
      "          2.1397e-02, -4.3766e-02,  3.7512e-02],\n",
      "        [-5.8893e-02, -6.0092e-03,  1.3502e-01, -1.1142e-01, -6.7723e-02,\n",
      "         -1.3246e-01, -6.4604e-02, -1.4730e-01],\n",
      "        [-3.6338e-02, -5.6369e-02, -3.6180e-02,  6.0517e-02,  3.7682e-02,\n",
      "          3.8543e-02, -6.5434e-02,  7.0140e-02],\n",
      "        [-1.3438e-01, -2.4746e-02,  7.3398e-02, -8.5408e-02,  1.6879e-02,\n",
      "          1.5806e-01,  1.6963e-01, -2.1116e-02],\n",
      "        [ 1.8522e-02, -1.0695e-02,  1.6388e-01, -1.0556e-01,  1.2564e-01,\n",
      "         -7.0796e-02,  1.9938e-01, -2.1120e-02]], device='cuda:0')\n",
      "rnn5.weight_hh_l0 tensor([[ 0.1776,  0.0527, -0.0487,  ..., -0.1604,  0.0530,  0.0096],\n",
      "        [-0.0612, -0.1767,  0.1257,  ..., -0.0662, -0.0473, -0.1856],\n",
      "        [ 0.0248, -0.0253,  0.0274,  ..., -0.0037, -0.1038,  0.1880],\n",
      "        ...,\n",
      "        [ 0.0106, -0.1146,  0.0818,  ..., -0.0768,  0.0842, -0.0310],\n",
      "        [-0.0057,  0.0712, -0.0464,  ...,  0.1819, -0.0921,  0.0392],\n",
      "        [ 0.1689, -0.1854,  0.0937,  ...,  0.0430,  0.0073, -0.1443]],\n",
      "       device='cuda:0')\n",
      "rnn5.bias_ih_l0 tensor([-0.1661, -0.0970,  0.0436,  0.0255, -0.0957,  0.0093,  0.1257, -0.0946,\n",
      "        -0.1700,  0.0064, -0.0450,  0.0590,  0.0013, -0.0831, -0.0115, -0.0774,\n",
      "         0.0388, -0.0309,  0.0593, -0.1762, -0.1119, -0.0475, -0.0915, -0.0621,\n",
      "         0.1415,  0.0536, -0.0987,  0.1403, -0.1309,  0.1414,  0.0673,  0.1487,\n",
      "        -0.0766,  0.0402, -0.0648,  0.0091,  0.0567,  0.0399,  0.0276, -0.1614,\n",
      "        -0.0063, -0.0933, -0.1087, -0.0365, -0.0475, -0.0385, -0.1318, -0.0940,\n",
      "         0.1293, -0.0729], device='cuda:0')\n",
      "rnn5.bias_hh_l0 tensor([-0.0548, -0.0009,  0.0834, -0.0567, -0.0193,  0.0123,  0.1803, -0.0338,\n",
      "         0.0034,  0.1603,  0.0149, -0.0740,  0.1781,  0.1029, -0.0542, -0.1776,\n",
      "        -0.1721, -0.0459,  0.0165, -0.0288, -0.0974, -0.0654,  0.0696,  0.1178,\n",
      "         0.1796, -0.0572,  0.0683,  0.1011,  0.0421,  0.1224, -0.0045,  0.0903,\n",
      "         0.0700,  0.0703, -0.1336, -0.1536, -0.0543,  0.0888, -0.1233,  0.0190,\n",
      "        -0.1423, -0.0943,  0.0697,  0.1220,  0.1910, -0.0347, -0.0495, -0.1336,\n",
      "        -0.0289,  0.0097], device='cuda:0')\n",
      "rnn5.weight_ih_l0_reverse tensor([[ 9.1861e-02, -1.3427e-02, -1.8444e-02, -1.8455e-02, -8.0768e-03,\n",
      "         -1.0329e-01,  1.0225e-01,  1.0894e-02],\n",
      "        [-4.6900e-02,  3.3490e-02,  2.4261e-02, -8.5206e-02,  4.0124e-02,\n",
      "         -1.1454e-01,  6.6637e-02,  7.4252e-02],\n",
      "        [ 7.2226e-02, -3.6670e-02, -1.6516e-01,  4.2818e-02, -1.6718e-01,\n",
      "          1.9959e-02, -4.1609e-02,  9.0030e-02],\n",
      "        [ 6.5944e-02, -1.8541e-02,  1.1804e-02,  6.7796e-02,  1.8735e-02,\n",
      "          1.4599e-01,  3.4099e-02, -7.1942e-02],\n",
      "        [-1.4755e-01,  1.3209e-01, -7.2419e-02,  5.1081e-02, -8.2814e-03,\n",
      "         -7.1347e-02, -1.4555e-01,  1.2612e-01],\n",
      "        [ 1.8082e-01, -1.7215e-01,  1.8907e-01, -1.5617e-01,  4.5476e-02,\n",
      "         -8.3681e-02,  7.9623e-02,  4.6748e-02],\n",
      "        [ 1.0001e-01, -1.2160e-01,  1.4590e-01, -6.2739e-03,  6.3970e-02,\n",
      "         -1.4090e-01,  7.0804e-02, -9.9871e-02],\n",
      "        [ 8.7012e-02, -1.0700e-02, -3.4758e-02, -5.1670e-02,  8.2061e-02,\n",
      "          6.2784e-02,  2.1224e-03,  1.6872e-01],\n",
      "        [-1.2020e-01,  1.1332e-01,  4.4344e-02,  5.5031e-02,  1.7157e-02,\n",
      "          1.1664e-01, -1.7618e-01, -9.0277e-02],\n",
      "        [ 1.0865e-01,  2.9066e-02, -2.6968e-03,  4.8899e-02, -5.2820e-02,\n",
      "          4.3482e-02,  9.1665e-03, -9.7070e-02],\n",
      "        [-1.9052e-01,  7.2977e-02, -1.3155e-02, -3.4177e-03, -3.7053e-02,\n",
      "          3.9697e-02, -7.4400e-02, -1.0121e-01],\n",
      "        [-7.7751e-04, -7.3464e-02, -1.2165e-01, -3.7585e-02, -5.0552e-02,\n",
      "          1.1308e-01,  3.0174e-04,  6.4051e-02],\n",
      "        [-8.9724e-02, -8.5515e-02, -7.0325e-02,  1.0166e-01,  6.5518e-03,\n",
      "         -7.4127e-02, -1.7994e-01,  1.8746e-01],\n",
      "        [-2.6216e-03,  6.6567e-02,  1.1301e-01,  4.1501e-02, -5.8182e-02,\n",
      "         -1.0874e-01,  3.6434e-02,  4.1016e-02],\n",
      "        [ 1.0036e-01, -8.7491e-02,  1.8594e-01, -1.9610e-02, -6.8834e-02,\n",
      "         -9.1365e-02, -1.0449e-01,  4.6625e-02],\n",
      "        [-1.1181e-01, -1.0165e-02, -1.2167e-01,  4.4652e-03,  3.2044e-02,\n",
      "          1.6172e-02, -1.0201e-01,  3.2164e-02],\n",
      "        [-8.9682e-02,  1.3262e-01,  5.6188e-02, -2.6136e-02,  8.3278e-02,\n",
      "          7.4012e-02,  7.6504e-02,  9.7648e-02],\n",
      "        [ 7.8447e-02,  1.2109e-01, -1.4091e-01, -8.4025e-02, -7.8970e-02,\n",
      "          9.2502e-02, -6.3917e-02,  1.8587e-01],\n",
      "        [ 1.2467e-01, -1.6963e-01,  4.0689e-02, -1.3870e-01,  1.4738e-01,\n",
      "         -1.2127e-01,  4.0413e-02,  5.2791e-02],\n",
      "        [-2.0066e-02,  2.2603e-02,  1.9991e-01, -6.3203e-02,  2.0328e-01,\n",
      "         -1.0684e-01,  1.3552e-01,  3.0026e-02],\n",
      "        [ 6.9013e-03, -8.6893e-02, -4.6173e-02, -7.4232e-02,  8.1266e-02,\n",
      "         -5.3879e-02, -9.1475e-02,  8.0202e-02],\n",
      "        [ 7.6200e-02,  1.1404e-01, -7.6190e-02,  1.0055e-01, -5.7545e-02,\n",
      "          4.2392e-02, -1.7801e-01,  1.8591e-01],\n",
      "        [-1.0786e-01,  1.6523e-01, -9.9418e-02, -5.4540e-02, -9.8022e-02,\n",
      "         -9.1696e-03,  5.4277e-02,  1.4487e-01],\n",
      "        [ 7.1173e-02, -2.7483e-02,  5.1862e-02, -7.6038e-02,  4.7686e-02,\n",
      "          5.0424e-02,  1.5604e-01,  3.4397e-02],\n",
      "        [ 1.3934e-01, -1.4713e-01,  1.5465e-01, -4.4539e-02,  1.1471e-01,\n",
      "          5.8241e-02,  7.8036e-02,  6.4213e-02],\n",
      "        [ 9.3532e-02, -1.6181e-01, -1.1049e-01, -1.4538e-03, -4.1316e-02,\n",
      "          1.3403e-02,  1.0506e-01, -1.0432e-01],\n",
      "        [-9.8041e-03, -5.1535e-02,  3.4416e-02, -1.4382e-02, -3.3114e-02,\n",
      "         -7.3550e-03,  4.1683e-02,  1.0042e-01],\n",
      "        [-6.8750e-02, -1.7491e-01, -7.3280e-02, -1.5299e-01, -2.7056e-03,\n",
      "          4.0523e-02, -2.1082e-02,  1.3352e-02],\n",
      "        [ 2.6997e-02,  2.8500e-02, -7.7972e-02,  2.5843e-03, -9.3667e-02,\n",
      "         -2.1813e-02, -1.0586e-02,  7.7707e-03],\n",
      "        [-4.0411e-02,  1.3011e-01,  1.4362e-03,  1.2984e-01,  1.3345e-04,\n",
      "          1.0183e-01, -4.0077e-02,  9.8887e-02],\n",
      "        [ 3.3580e-02, -7.8606e-02, -3.5273e-02,  1.6054e-01, -1.6196e-01,\n",
      "         -6.9223e-02, -3.2554e-02, -6.7736e-02],\n",
      "        [-9.0933e-02, -2.0662e-02,  3.0438e-02,  1.3002e-01, -1.6698e-01,\n",
      "          9.1844e-02, -3.3052e-02,  4.5662e-02],\n",
      "        [ 1.5653e-01, -1.5732e-01,  1.2230e-01,  6.9759e-02, -2.2148e-02,\n",
      "         -1.9027e-01,  7.7653e-02, -1.3191e-01],\n",
      "        [ 1.4264e-01, -1.9118e-01,  6.4614e-02, -2.6927e-02,  1.9546e-02,\n",
      "         -5.3171e-02,  1.0130e-01,  7.9391e-02],\n",
      "        [-8.5999e-02,  1.6029e-01, -1.5196e-01,  4.3881e-03, -1.5994e-01,\n",
      "          8.7266e-02,  4.5013e-02,  2.3335e-02],\n",
      "        [-1.3923e-01,  8.5176e-02,  7.6831e-02,  1.1538e-01, -1.1560e-01,\n",
      "         -1.0766e-02, -1.5824e-01,  5.5860e-02],\n",
      "        [ 3.9384e-02, -1.7472e-01,  1.4825e-02,  3.3339e-03,  4.5664e-02,\n",
      "         -6.5344e-02,  1.6689e-02,  2.0061e-02],\n",
      "        [ 2.6252e-02,  4.2629e-03, -1.0831e-01, -8.5133e-02, -6.3450e-02,\n",
      "          9.2734e-02,  5.1568e-02,  5.5112e-03],\n",
      "        [ 1.5811e-01,  8.6617e-02, -8.8301e-02, -2.3697e-02,  1.2816e-01,\n",
      "         -6.9348e-02, -1.3282e-01,  7.0671e-02],\n",
      "        [-1.2297e-01, -4.0105e-02,  7.9113e-02,  4.9028e-02, -1.2927e-01,\n",
      "         -7.8072e-02, -5.6344e-02, -7.5152e-02],\n",
      "        [-4.5429e-02,  6.2373e-02, -6.5966e-02, -1.4582e-02, -1.1191e-01,\n",
      "         -6.2972e-02,  1.2591e-01, -1.8158e-01],\n",
      "        [-8.5126e-03,  2.4449e-02,  1.6108e-01, -7.9151e-02,  2.0333e-02,\n",
      "         -1.1215e-01,  1.3774e-01,  3.8694e-02],\n",
      "        [-2.9676e-02, -1.9033e-02, -7.1286e-02, -1.0520e-01,  1.0455e-01,\n",
      "          8.4443e-02,  7.2877e-03, -5.6852e-02],\n",
      "        [ 2.4876e-04,  2.4183e-02, -3.3662e-02,  5.9104e-02, -6.0679e-02,\n",
      "          1.4629e-01,  9.2794e-03,  1.8589e-01],\n",
      "        [-5.9991e-02, -6.9776e-02,  5.8637e-02,  1.3948e-01, -3.0810e-02,\n",
      "          2.9610e-02,  6.2637e-02,  8.8462e-02],\n",
      "        [ 6.2231e-02, -1.0086e-01, -5.2649e-03,  7.3946e-02,  4.4606e-02,\n",
      "          1.0269e-01, -9.2466e-02, -5.3351e-02],\n",
      "        [ 4.8181e-02, -6.1072e-02, -1.0784e-01,  1.1495e-01,  1.4357e-01,\n",
      "         -9.6657e-03, -7.4916e-03,  1.9380e-02],\n",
      "        [ 1.5159e-01, -6.5923e-02,  1.5844e-01, -1.6135e-01,  1.9119e-01,\n",
      "         -1.8299e-01,  1.3213e-01, -8.4272e-02],\n",
      "        [-6.8162e-02, -6.9183e-02,  1.9733e-01,  8.0763e-02,  1.2654e-01,\n",
      "         -8.3596e-02,  6.3148e-02, -7.3071e-02],\n",
      "        [-8.0848e-02, -1.7609e-01,  7.5585e-02,  4.7649e-02,  1.0957e-01,\n",
      "         -1.4694e-01,  1.2111e-01,  4.6204e-02]], device='cuda:0')\n",
      "rnn5.weight_hh_l0_reverse tensor([[ 0.0551, -0.1768,  0.1194,  ..., -0.1311, -0.0045,  0.0099],\n",
      "        [-0.1753, -0.0561,  0.0592,  ..., -0.1745,  0.0987,  0.0159],\n",
      "        [-0.0791, -0.0400, -0.0192,  ..., -0.1441,  0.0795, -0.1082],\n",
      "        ...,\n",
      "        [ 0.1643,  0.0116, -0.0608,  ...,  0.0694,  0.0262,  0.1063],\n",
      "        [ 0.1772, -0.0607, -0.1947,  ...,  0.0505, -0.1893,  0.0303],\n",
      "        [ 0.1110, -0.0842, -0.0247,  ...,  0.1557, -0.1401,  0.0298]],\n",
      "       device='cuda:0')\n",
      "rnn5.bias_ih_l0_reverse tensor([-0.0558,  0.0011, -0.0264, -0.0443,  0.1976, -0.1078, -0.1100, -0.0445,\n",
      "        -0.0873, -0.1399,  0.0396,  0.0730,  0.0555, -0.1856,  0.0325,  0.0767,\n",
      "        -0.0318,  0.1362, -0.0389,  0.0285,  0.0777,  0.0101,  0.0806, -0.1284,\n",
      "         0.0438, -0.0052,  0.0220, -0.1044,  0.0541,  0.0759, -0.0131,  0.0932,\n",
      "         0.0528, -0.1505,  0.1444,  0.1474, -0.0085, -0.0052,  0.0889,  0.0739,\n",
      "        -0.0527, -0.1562, -0.0392, -0.0114, -0.0491, -0.0486,  0.0413, -0.1613,\n",
      "        -0.0082, -0.0714], device='cuda:0')\n",
      "rnn5.bias_hh_l0_reverse tensor([-0.1249,  0.0829,  0.1482,  0.1521,  0.0556, -0.0416, -0.1371,  0.1849,\n",
      "         0.0798, -0.0843,  0.0379,  0.0225,  0.1603, -0.1109,  0.0191, -0.0305,\n",
      "        -0.0548,  0.0589,  0.0711,  0.0641,  0.0077,  0.1108, -0.0423, -0.0465,\n",
      "        -0.0771, -0.1036,  0.1738,  0.0498,  0.0212,  0.1077, -0.0208,  0.0226,\n",
      "         0.0763,  0.0345, -0.0304, -0.0055, -0.1214, -0.0934,  0.0214,  0.0255,\n",
      "        -0.0437,  0.0034, -0.0746,  0.1071,  0.0604,  0.0371, -0.0003,  0.0768,\n",
      "        -0.0979, -0.0740], device='cuda:0')\n",
      "rnn6.weight_ih_l0 tensor([[ 0.0175,  0.1308,  0.0039,  0.1779, -0.1051, -0.0606,  0.0810,  0.1697],\n",
      "        [ 0.1141, -0.1206, -0.0525, -0.0411,  0.0453, -0.0819, -0.0175, -0.0174],\n",
      "        [ 0.1651, -0.1889,  0.1647, -0.0304,  0.1120, -0.1116,  0.1567,  0.0299],\n",
      "        [-0.0635,  0.0900,  0.0865,  0.0671, -0.0857,  0.0764, -0.0155, -0.1433],\n",
      "        [ 0.0266,  0.1052,  0.1032,  0.1007,  0.1383,  0.0964,  0.0980,  0.0814],\n",
      "        [ 0.0317,  0.1597, -0.1654, -0.0180,  0.0319,  0.0592,  0.0843, -0.0384],\n",
      "        [-0.0654, -0.0547, -0.0861, -0.0014, -0.0396,  0.1552, -0.0240,  0.0269],\n",
      "        [ 0.0328,  0.0343,  0.0584,  0.0477,  0.1533, -0.0669,  0.0951, -0.0019],\n",
      "        [-0.0475,  0.0461,  0.1173,  0.0044,  0.0077,  0.0438, -0.0250,  0.0704],\n",
      "        [ 0.0118, -0.0022,  0.0390,  0.0210, -0.1847,  0.0385, -0.0524,  0.1468],\n",
      "        [ 0.0756, -0.0939, -0.1191, -0.0273,  0.0586,  0.1615, -0.0491,  0.0355],\n",
      "        [ 0.0693,  0.1737,  0.0347,  0.0477, -0.0552,  0.1349,  0.1298,  0.0179],\n",
      "        [-0.0919, -0.0909,  0.0950,  0.1165, -0.0160,  0.0059, -0.0529,  0.1004],\n",
      "        [-0.0285, -0.0872, -0.0125, -0.1578,  0.1617,  0.0696, -0.0169,  0.0035],\n",
      "        [-0.0922, -0.0076, -0.0590, -0.0046, -0.1902, -0.0436,  0.0129,  0.0837],\n",
      "        [ 0.0607,  0.1424, -0.0125, -0.0791, -0.1054,  0.1373, -0.1741,  0.0928],\n",
      "        [-0.0348,  0.1271, -0.1655, -0.0971, -0.0201, -0.0455,  0.1686, -0.0979],\n",
      "        [ 0.1520, -0.0042,  0.1544, -0.1233,  0.1913, -0.0991,  0.1202, -0.1908],\n",
      "        [ 0.0402, -0.0921,  0.1558, -0.1401, -0.1429,  0.0817, -0.0381, -0.1397],\n",
      "        [-0.0641, -0.0485, -0.0763,  0.0330, -0.0335,  0.1873,  0.0542, -0.0793],\n",
      "        [-0.0275,  0.0808, -0.0088, -0.0351,  0.0487,  0.1416, -0.0276,  0.1769],\n",
      "        [-0.0352, -0.0006, -0.0597,  0.1742,  0.0630,  0.1423,  0.0482, -0.0349],\n",
      "        [ 0.0468, -0.0574,  0.0712, -0.0627, -0.0303, -0.0079, -0.0266, -0.0742],\n",
      "        [-0.0709, -0.1621, -0.0652, -0.1575,  0.0970, -0.0287, -0.0698,  0.0062],\n",
      "        [-0.0498, -0.0910, -0.0773,  0.0606,  0.1089,  0.0055, -0.0390, -0.1825],\n",
      "        [ 0.0310,  0.0504, -0.1780,  0.0587, -0.0024,  0.1316, -0.0388,  0.0213],\n",
      "        [ 0.0039, -0.1863, -0.0669,  0.0194, -0.0658, -0.0270,  0.0728,  0.0498],\n",
      "        [-0.0478,  0.0005, -0.0936,  0.0770, -0.1117, -0.0168, -0.1705,  0.0202],\n",
      "        [ 0.0419,  0.0004,  0.0200, -0.0812, -0.1192, -0.1034, -0.0412, -0.1747],\n",
      "        [ 0.0811,  0.0372, -0.1265, -0.0220, -0.0006, -0.0100, -0.0433,  0.0636],\n",
      "        [ 0.0146,  0.0319,  0.1787, -0.1236,  0.0205, -0.1281,  0.0317, -0.1458],\n",
      "        [ 0.0016,  0.1094, -0.0396,  0.0143, -0.1526,  0.0097, -0.0153,  0.1769],\n",
      "        [ 0.0263,  0.0810,  0.1812,  0.0012, -0.0679, -0.0504,  0.0666, -0.1709],\n",
      "        [ 0.1707,  0.0676, -0.0025, -0.1390, -0.0839, -0.0920,  0.1436, -0.0697],\n",
      "        [ 0.0079,  0.0265,  0.1576,  0.0691,  0.0711, -0.0420, -0.0800, -0.1755],\n",
      "        [-0.0683, -0.0362, -0.0804, -0.0887, -0.0028,  0.1005,  0.1195,  0.1305],\n",
      "        [-0.1557,  0.1321, -0.1648, -0.0628, -0.1263,  0.1399, -0.0597,  0.0729],\n",
      "        [-0.0017,  0.0012, -0.1062,  0.0628,  0.0813, -0.0996,  0.1703,  0.0984],\n",
      "        [ 0.1099, -0.1545, -0.0491,  0.0140,  0.0028,  0.0406, -0.0908, -0.1515],\n",
      "        [ 0.0761, -0.0172,  0.0943,  0.0669, -0.0931, -0.0536, -0.0291, -0.1350],\n",
      "        [ 0.1241,  0.0730,  0.1548,  0.0641,  0.1807,  0.0529, -0.0171, -0.0470],\n",
      "        [-0.0162, -0.1573,  0.1816, -0.0264, -0.0820, -0.0911,  0.0206, -0.0807],\n",
      "        [ 0.0484, -0.0930,  0.0135,  0.0404,  0.1458, -0.1513, -0.0806, -0.1105],\n",
      "        [ 0.0727,  0.0199, -0.1037, -0.0516,  0.0108,  0.1402, -0.1056,  0.0238],\n",
      "        [ 0.1723, -0.0282,  0.0793, -0.1115, -0.0362, -0.1061,  0.0353,  0.0675],\n",
      "        [ 0.1284,  0.0073,  0.1183,  0.0440,  0.0581,  0.0018, -0.0907,  0.0574],\n",
      "        [ 0.0406, -0.0712, -0.0700, -0.0992,  0.0864, -0.0026,  0.1257, -0.0672],\n",
      "        [ 0.0727,  0.1596, -0.0097, -0.0855,  0.0837,  0.0540,  0.0350, -0.0458],\n",
      "        [ 0.0727, -0.1309, -0.0431, -0.0997,  0.0425, -0.1930,  0.1795, -0.2069],\n",
      "        [ 0.0747,  0.0857,  0.0544, -0.0587, -0.0417,  0.0636,  0.0097,  0.1846]],\n",
      "       device='cuda:0')\n",
      "rnn6.weight_hh_l0 tensor([[ 0.0480,  0.0796, -0.1383,  ..., -0.0354, -0.0342, -0.1708],\n",
      "        [-0.1072,  0.1098,  0.1640,  ...,  0.0311,  0.1242, -0.0349],\n",
      "        [ 0.0548,  0.1416,  0.0907,  ...,  0.0344,  0.0209,  0.1461],\n",
      "        ...,\n",
      "        [-0.0524, -0.1337,  0.0071,  ...,  0.0430,  0.0019, -0.0406],\n",
      "        [-0.0257, -0.0502,  0.0192,  ...,  0.0780, -0.0464,  0.0658],\n",
      "        [-0.0689, -0.1718, -0.0404,  ..., -0.1619, -0.1150, -0.1061]],\n",
      "       device='cuda:0')\n",
      "rnn6.bias_ih_l0 tensor([ 0.0652, -0.1707, -0.0655,  0.0159, -0.0088, -0.0698,  0.1720,  0.0322,\n",
      "        -0.1872, -0.0711, -0.0020,  0.0548,  0.0366,  0.0467,  0.1172,  0.0125,\n",
      "         0.0701,  0.0648, -0.1105, -0.0158, -0.0818,  0.0094, -0.0586,  0.0039,\n",
      "        -0.0507, -0.0088,  0.0161,  0.1154, -0.1190,  0.1694, -0.1978,  0.1951,\n",
      "         0.0277, -0.1612, -0.1217,  0.0908,  0.1036,  0.1728,  0.0460, -0.0979,\n",
      "        -0.1019, -0.0472, -0.1475,  0.0970, -0.0213, -0.1377, -0.1100,  0.1551,\n",
      "        -0.1086, -0.0851], device='cuda:0')\n",
      "rnn6.bias_hh_l0 tensor([ 1.0914e-01, -8.5324e-02, -1.5653e-01,  1.8239e-02, -4.4320e-02,\n",
      "         9.5418e-02, -1.3178e-02,  7.8811e-02, -9.2157e-02,  5.2206e-02,\n",
      "        -7.8621e-02,  1.8102e-01, -9.6249e-02, -4.3637e-02,  5.9356e-02,\n",
      "        -1.2383e-02,  8.7241e-02, -6.0382e-02,  4.8883e-02,  8.5086e-05,\n",
      "         4.8025e-02,  4.4769e-03,  3.4544e-02, -1.7182e-01,  3.6763e-02,\n",
      "         7.3874e-03,  6.3250e-02,  9.6475e-02, -3.2039e-02, -4.3532e-02,\n",
      "         5.1192e-02,  3.2371e-02, -1.4835e-01, -1.7262e-01,  2.7568e-02,\n",
      "         1.2478e-01, -3.5533e-02,  1.7447e-01,  3.7997e-02, -9.1470e-02,\n",
      "        -6.6808e-02, -4.0889e-02, -3.9638e-02, -1.1183e-01, -8.2603e-02,\n",
      "        -4.7735e-03, -1.9083e-01, -1.0687e-01,  2.2676e-02,  8.2228e-02],\n",
      "       device='cuda:0')\n",
      "rnn6.weight_ih_l0_reverse tensor([[ 0.0429, -0.0553,  0.1789, -0.0858, -0.0527,  0.0774,  0.1677, -0.0438],\n",
      "        [-0.0963, -0.0164,  0.0688, -0.0579,  0.0104, -0.1100, -0.0706, -0.1644],\n",
      "        [ 0.0492,  0.1585, -0.0419,  0.0657,  0.0786,  0.0916, -0.0707,  0.0229],\n",
      "        [-0.0340,  0.0735,  0.0396, -0.0228,  0.0335,  0.0985,  0.0446, -0.0479],\n",
      "        [ 0.1526,  0.0084, -0.0893, -0.1266,  0.0699, -0.1518,  0.1131, -0.1681],\n",
      "        [-0.0451, -0.1313,  0.1446, -0.0496,  0.0538, -0.0708, -0.0016, -0.1064],\n",
      "        [-0.0113, -0.0074,  0.0513,  0.0931, -0.0481, -0.0060,  0.0667, -0.0104],\n",
      "        [-0.0641, -0.0168,  0.0161, -0.1085, -0.0116, -0.1212,  0.0837, -0.1484],\n",
      "        [-0.0860,  0.0174, -0.0848, -0.0141,  0.0150, -0.0205, -0.1359, -0.1660],\n",
      "        [-0.1515, -0.0826,  0.0329,  0.0783,  0.0596,  0.0403, -0.0307,  0.1550],\n",
      "        [-0.1297,  0.0560, -0.0330,  0.1383,  0.0053, -0.0297,  0.0449, -0.0141],\n",
      "        [-0.0717,  0.0611,  0.0079,  0.0945, -0.0146, -0.0271,  0.0090,  0.1179],\n",
      "        [ 0.0012,  0.1974, -0.0920,  0.0049, -0.1174,  0.1344, -0.0740,  0.1331],\n",
      "        [ 0.0907, -0.0108, -0.1123,  0.0347,  0.0468, -0.0008, -0.0619,  0.1360],\n",
      "        [ 0.0080, -0.1019,  0.1128, -0.0049,  0.1131,  0.0515,  0.1825,  0.0577],\n",
      "        [ 0.0410,  0.0129,  0.0906, -0.0916, -0.0121, -0.0175,  0.1432, -0.1414],\n",
      "        [ 0.0704, -0.0402, -0.0621, -0.0208, -0.1813,  0.1462, -0.0384,  0.1104],\n",
      "        [-0.1273,  0.1150, -0.1828, -0.0136, -0.1142,  0.1725, -0.0304,  0.0565],\n",
      "        [-0.1890, -0.0579,  0.0757, -0.0615,  0.0282,  0.0711, -0.1677, -0.0170],\n",
      "        [ 0.0738,  0.1935, -0.0484, -0.0694,  0.0825,  0.1697, -0.1052,  0.0020],\n",
      "        [-0.0328,  0.1841,  0.0819,  0.0181,  0.0858,  0.0521, -0.0926, -0.0165],\n",
      "        [-0.0690,  0.1789,  0.0258, -0.0117, -0.1353,  0.1636,  0.0376,  0.1702],\n",
      "        [ 0.0243,  0.0412,  0.1478,  0.0345,  0.1713, -0.1523, -0.0608,  0.0167],\n",
      "        [ 0.0472,  0.1869, -0.0758, -0.0451,  0.0437, -0.0311, -0.1023, -0.0733],\n",
      "        [ 0.0190, -0.0855,  0.0476,  0.0099, -0.0713,  0.1597, -0.0645, -0.0278],\n",
      "        [ 0.1439, -0.1679,  0.0227,  0.0532,  0.1607, -0.0413,  0.1282,  0.0331],\n",
      "        [ 0.0088,  0.1132, -0.0479,  0.1000, -0.0850,  0.1816,  0.0480,  0.0927],\n",
      "        [ 0.1910, -0.1289,  0.1421, -0.0999,  0.1651, -0.0543,  0.0656, -0.1898],\n",
      "        [-0.1847,  0.0323, -0.2059, -0.0480, -0.0875, -0.0876, -0.1686, -0.0128],\n",
      "        [-0.1408,  0.1718, -0.1514,  0.0910, -0.0875,  0.0266, -0.1727,  0.1671],\n",
      "        [-0.0019,  0.0818, -0.0764,  0.2055, -0.0395,  0.1472,  0.0406, -0.0505],\n",
      "        [-0.0733,  0.1045, -0.1440,  0.1512, -0.0497,  0.1881, -0.0291, -0.0329],\n",
      "        [-0.0610, -0.0748,  0.0222, -0.0693,  0.0259, -0.0996, -0.0406, -0.1264],\n",
      "        [-0.0167, -0.0840,  0.1551,  0.0427,  0.1298,  0.0716,  0.1922, -0.0575],\n",
      "        [-0.1668,  0.0424, -0.1531, -0.1210, -0.0603,  0.0043,  0.0824, -0.1111],\n",
      "        [ 0.0731, -0.0630, -0.1796,  0.1196, -0.0026,  0.0197, -0.0340,  0.0650],\n",
      "        [-0.0932,  0.0312, -0.1053, -0.0747,  0.0250,  0.1914, -0.1495, -0.0539],\n",
      "        [ 0.0551, -0.0914,  0.0475,  0.0033,  0.1601,  0.0338, -0.0795, -0.0533],\n",
      "        [-0.0059,  0.0869,  0.0962, -0.1224, -0.0575, -0.0349,  0.1902,  0.0433],\n",
      "        [ 0.0865,  0.1564, -0.1138,  0.0425,  0.0442,  0.1136,  0.0562,  0.0901],\n",
      "        [ 0.1218, -0.1836,  0.1335, -0.1644,  0.0193, -0.0364, -0.0710, -0.0405],\n",
      "        [ 0.0126,  0.1015,  0.0654,  0.1042, -0.0680,  0.1421, -0.0441,  0.0724],\n",
      "        [-0.0130, -0.1433,  0.0887,  0.0931, -0.0165, -0.1233, -0.0572, -0.0856],\n",
      "        [ 0.0859, -0.0084, -0.0889,  0.1581, -0.0612,  0.0548, -0.1107, -0.0283],\n",
      "        [-0.1000,  0.0148, -0.0573,  0.1478, -0.0719,  0.1327, -0.1698, -0.0757],\n",
      "        [-0.0488,  0.1388, -0.1835, -0.0160, -0.0674,  0.0890,  0.0805,  0.0873],\n",
      "        [ 0.0603, -0.0229, -0.0177, -0.0802, -0.1871, -0.0281,  0.0082,  0.0273],\n",
      "        [-0.1525,  0.1452,  0.0821, -0.0961, -0.0915,  0.0242, -0.0788,  0.0309],\n",
      "        [ 0.0705,  0.0348,  0.0043, -0.0159, -0.0810, -0.0482, -0.0435,  0.0496],\n",
      "        [-0.1586, -0.0561,  0.0310,  0.1317, -0.1726,  0.0507, -0.0410,  0.1316]],\n",
      "       device='cuda:0')\n",
      "rnn6.weight_hh_l0_reverse tensor([[ 0.0953,  0.0196,  0.0579,  ..., -0.0178, -0.1209,  0.1205],\n",
      "        [ 0.0383, -0.0927,  0.0299,  ..., -0.0857,  0.0089,  0.0450],\n",
      "        [ 0.1018, -0.0341, -0.0839,  ..., -0.1138,  0.0372, -0.0771],\n",
      "        ...,\n",
      "        [-0.0011, -0.1729,  0.0947,  ...,  0.0215, -0.0784, -0.0798],\n",
      "        [ 0.1148,  0.0069, -0.0511,  ..., -0.1556,  0.0076,  0.1769],\n",
      "        [-0.0085, -0.0276,  0.0428,  ..., -0.0414, -0.0485, -0.1028]],\n",
      "       device='cuda:0')\n",
      "rnn6.bias_ih_l0_reverse tensor([-0.1606,  0.0122,  0.1465,  0.0609, -0.0989,  0.0630, -0.0339, -0.1277,\n",
      "        -0.1472, -0.0101,  0.1163,  0.1423,  0.0695, -0.0855, -0.1523,  0.0439,\n",
      "         0.1703,  0.1149, -0.0965,  0.0862,  0.0898,  0.1247,  0.0567,  0.1813,\n",
      "         0.1355, -0.1674,  0.0154, -0.0663,  0.0307,  0.1701, -0.0310,  0.0670,\n",
      "        -0.1575, -0.0940,  0.0590,  0.0276, -0.0546, -0.1428,  0.0016, -0.0306,\n",
      "        -0.1657,  0.0354,  0.0564,  0.0621, -0.0390, -0.0207,  0.1425,  0.1563,\n",
      "        -0.0690,  0.0330], device='cuda:0')\n",
      "rnn6.bias_hh_l0_reverse tensor([-0.1438, -0.1841, -0.0140, -0.0219, -0.1203, -0.0627, -0.0155,  0.0487,\n",
      "        -0.0616, -0.0166, -0.0402, -0.0370,  0.0269, -0.0867, -0.0832,  0.0728,\n",
      "         0.0129,  0.0151,  0.1601,  0.1102,  0.1298,  0.0366, -0.0977, -0.0466,\n",
      "        -0.0228,  0.0929,  0.0387, -0.0160,  0.1774,  0.1013,  0.0867, -0.0508,\n",
      "        -0.1238, -0.0138,  0.0453, -0.0066,  0.1379, -0.0855,  0.0235,  0.0650,\n",
      "         0.0387, -0.0738, -0.1410,  0.1346,  0.0290,  0.1192,  0.0725,  0.1392,\n",
      "        -0.0279, -0.0956], device='cuda:0')\n",
      "rnn_l2.weight_ih_l0 tensor([[-0.0373, -0.0120, -0.0064,  ...,  0.1172, -0.0176,  0.1151],\n",
      "        [-0.0645, -0.0438,  0.0333,  ..., -0.0223,  0.0879, -0.1442],\n",
      "        [-0.1580,  0.0346,  0.0610,  ..., -0.0319, -0.0423, -0.0805],\n",
      "        ...,\n",
      "        [-0.0214,  0.0117, -0.0888,  ...,  0.0308,  0.0890,  0.1423],\n",
      "        [-0.0501, -0.0305,  0.1073,  ...,  0.1175,  0.0032,  0.0397],\n",
      "        [-0.0351, -0.0053, -0.0488,  ..., -0.0573, -0.0713, -0.0765]],\n",
      "       device='cuda:0')\n",
      "rnn_l2.weight_hh_l0 tensor([[ 1.1617e-01, -2.2275e-02, -4.5399e-02,  ..., -1.0363e-01,\n",
      "          1.2588e-01, -1.5979e-01],\n",
      "        [ 3.0195e-02, -1.2131e-01, -9.2735e-02,  ...,  9.7107e-02,\n",
      "         -1.2548e-01, -1.0511e-01],\n",
      "        [-6.7248e-02,  1.0633e-01,  5.5453e-02,  ...,  2.4965e-02,\n",
      "         -1.0827e-02, -5.5421e-02],\n",
      "        ...,\n",
      "        [ 1.1473e-01, -5.3183e-03, -2.4933e-02,  ..., -1.5808e-01,\n",
      "          4.3729e-02, -1.5663e-04],\n",
      "        [ 3.9811e-02,  1.0766e-02,  1.3993e-02,  ...,  1.1872e-02,\n",
      "         -1.4412e-01, -9.9056e-03],\n",
      "        [-3.7811e-02,  7.8224e-02,  1.1536e-01,  ..., -1.1403e-01,\n",
      "          4.2773e-02, -5.8195e-02]], device='cuda:0')\n",
      "rnn_l2.bias_ih_l0 tensor([-0.0103, -0.0227,  0.1638,  0.0054, -0.0269, -0.1259,  0.0585, -0.0979,\n",
      "        -0.0305, -0.1181, -0.1289,  0.0306,  0.1176,  0.0244,  0.0331,  0.0785,\n",
      "         0.0558, -0.0288,  0.0039,  0.1237,  0.1200, -0.0916,  0.1071, -0.0283,\n",
      "        -0.0269,  0.0657,  0.0142, -0.1359, -0.0102,  0.0837, -0.0221, -0.0794,\n",
      "        -0.1254,  0.1186, -0.0009,  0.0420,  0.0321,  0.1262,  0.0746,  0.0054,\n",
      "         0.0734, -0.1513, -0.0480,  0.0037, -0.0301, -0.0502, -0.0297, -0.0101,\n",
      "         0.0003,  0.0845,  0.0628,  0.0251, -0.1238, -0.0171, -0.0578, -0.0282,\n",
      "        -0.0370,  0.0826,  0.0719, -0.0655, -0.0242,  0.0209,  0.0207,  0.0793,\n",
      "        -0.0355,  0.1145,  0.1093, -0.0508, -0.1002, -0.1355, -0.0069,  0.0067,\n",
      "         0.0359,  0.0646,  0.0320,  0.0111,  0.1219,  0.0277,  0.1096, -0.1015,\n",
      "         0.0145,  0.1225, -0.0451, -0.0022, -0.0197, -0.0069, -0.0582,  0.0378,\n",
      "         0.0061, -0.0960, -0.0567, -0.1110, -0.0171, -0.1286, -0.0195, -0.0228,\n",
      "         0.0120, -0.0528, -0.1227, -0.1458], device='cuda:0')\n",
      "rnn_l2.bias_hh_l0 tensor([ 0.0231, -0.0126,  0.0406, -0.0797, -0.0286, -0.0276,  0.0702, -0.0232,\n",
      "        -0.0147, -0.0901, -0.1229, -0.0810, -0.0167, -0.0982, -0.0098, -0.0203,\n",
      "         0.1242, -0.1648, -0.0530,  0.0303,  0.0017,  0.0352,  0.1541, -0.0495,\n",
      "        -0.1273,  0.1274,  0.1079, -0.0776, -0.0029,  0.0687, -0.0723,  0.0330,\n",
      "        -0.0775,  0.0600, -0.0378,  0.0629, -0.0143,  0.0810, -0.0264,  0.0616,\n",
      "         0.1132, -0.0441,  0.0906,  0.0422, -0.0485, -0.0728, -0.0619, -0.0165,\n",
      "        -0.0742, -0.0230,  0.0353,  0.0220, -0.0389, -0.0740, -0.1303,  0.0808,\n",
      "        -0.0672,  0.0474,  0.1317, -0.0742, -0.0184, -0.0572, -0.0436,  0.1027,\n",
      "         0.0068,  0.0356,  0.0647,  0.0349, -0.0358, -0.1230,  0.1180, -0.0104,\n",
      "        -0.0031, -0.0481,  0.0290,  0.0156,  0.1113,  0.1390,  0.0180, -0.0077,\n",
      "         0.1029,  0.0203, -0.0351, -0.0405, -0.0098, -0.0418, -0.0452, -0.1199,\n",
      "        -0.0429,  0.0337,  0.1022,  0.0156,  0.0671, -0.1219,  0.1026,  0.0325,\n",
      "        -0.0343,  0.0036, -0.0197, -0.0609], device='cuda:0')\n",
      "rnn_l2.weight_ih_l0_reverse tensor([[ 0.0820,  0.1065,  0.0307,  ..., -0.0164,  0.0216, -0.0654],\n",
      "        [ 0.0492, -0.0113, -0.0942,  ...,  0.1214,  0.1053,  0.1439],\n",
      "        [-0.0523, -0.0531,  0.1158,  ..., -0.1008,  0.0795,  0.0418],\n",
      "        ...,\n",
      "        [ 0.0066,  0.1115, -0.0294,  ..., -0.0457, -0.1384, -0.0660],\n",
      "        [-0.0647,  0.0333,  0.0212,  ..., -0.0146, -0.0009,  0.0340],\n",
      "        [ 0.0275,  0.1420, -0.0129,  ...,  0.0851,  0.0056, -0.0145]],\n",
      "       device='cuda:0')\n",
      "rnn_l2.weight_hh_l0_reverse tensor([[-0.0398,  0.0172,  0.1049,  ...,  0.0613, -0.1313, -0.0860],\n",
      "        [-0.0120,  0.0337, -0.0694,  ..., -0.0706, -0.0524,  0.0305],\n",
      "        [-0.1536,  0.1269,  0.0275,  ...,  0.0457,  0.0147,  0.0473],\n",
      "        ...,\n",
      "        [ 0.0926,  0.0357,  0.1065,  ..., -0.0399, -0.0952, -0.0497],\n",
      "        [-0.0929, -0.0255,  0.0963,  ...,  0.1160,  0.0343, -0.0064],\n",
      "        [-0.1220,  0.0146,  0.1197,  ...,  0.1293, -0.0461,  0.0028]],\n",
      "       device='cuda:0')\n",
      "rnn_l2.bias_ih_l0_reverse tensor([-0.0141,  0.0444,  0.0494,  0.1091,  0.1109,  0.0573,  0.0608, -0.1106,\n",
      "        -0.1120,  0.0671,  0.0443, -0.1270, -0.0556, -0.0947, -0.0391, -0.0068,\n",
      "         0.0055, -0.0416,  0.0108, -0.0459,  0.0077, -0.0527, -0.0221, -0.0207,\n",
      "         0.0461,  0.1215, -0.0089,  0.0981,  0.0076,  0.1006,  0.0139,  0.0506,\n",
      "        -0.0171,  0.0343, -0.1205,  0.0586,  0.0555,  0.0692, -0.0481,  0.0086,\n",
      "        -0.1104,  0.0287,  0.1154,  0.0454,  0.0641, -0.0184,  0.1011,  0.1500,\n",
      "         0.1118, -0.0106, -0.0449, -0.0990,  0.0719,  0.0420,  0.0143, -0.1071,\n",
      "         0.1265, -0.0616, -0.1466,  0.1082,  0.0165,  0.0132,  0.1256, -0.0274,\n",
      "         0.0434,  0.0068,  0.1443,  0.0075, -0.1282,  0.0050, -0.0060, -0.0389,\n",
      "        -0.0234, -0.0328,  0.0529, -0.0049, -0.0576,  0.0635,  0.0058,  0.0140,\n",
      "        -0.0191, -0.0239, -0.0129,  0.0478,  0.1382,  0.0468, -0.0794, -0.0949,\n",
      "         0.1328, -0.0224, -0.0082, -0.0481,  0.0370,  0.0524, -0.0244,  0.0293,\n",
      "         0.0202,  0.0018, -0.0810,  0.0217], device='cuda:0')\n",
      "rnn_l2.bias_hh_l0_reverse tensor([-0.0143,  0.0628,  0.0578,  0.0320,  0.0739,  0.1100,  0.0594, -0.0580,\n",
      "        -0.1265, -0.0810, -0.0128, -0.0037, -0.0156,  0.0159, -0.0231,  0.0918,\n",
      "         0.0442,  0.0767, -0.1099, -0.1038, -0.0926, -0.0943, -0.0012, -0.0231,\n",
      "         0.0069,  0.0565, -0.0170,  0.1301, -0.0741,  0.0680,  0.0394,  0.1270,\n",
      "         0.0522, -0.0489,  0.0212,  0.0781,  0.0034, -0.0063,  0.0518, -0.1358,\n",
      "        -0.0812,  0.0310,  0.0244, -0.1066,  0.0463, -0.0241,  0.1081,  0.0072,\n",
      "        -0.0066, -0.1139,  0.0759, -0.0965,  0.1362,  0.0361, -0.0314, -0.0851,\n",
      "         0.1119, -0.1200,  0.0238, -0.0181,  0.1681,  0.0405,  0.0194,  0.1047,\n",
      "        -0.0209,  0.0376,  0.1225,  0.0015, -0.0235, -0.0133,  0.0328,  0.0457,\n",
      "        -0.0167, -0.0611,  0.1309, -0.0836,  0.0123,  0.0513, -0.1142,  0.1573,\n",
      "        -0.1342,  0.0636,  0.0452,  0.1580, -0.0404,  0.1444, -0.1322, -0.0733,\n",
      "         0.0418, -0.0238, -0.0525, -0.0540, -0.1479,  0.0430,  0.0697,  0.0268,\n",
      "         0.0210,  0.0248, -0.1127,  0.0600], device='cuda:0')\n",
      "rnn_l41.weight_ih_l0 tensor([[-0.1221,  0.0757, -0.0673,  ...,  0.1335, -0.0860,  0.0091],\n",
      "        [ 0.0502, -0.0148,  0.0555,  ..., -0.0656,  0.1323, -0.0029],\n",
      "        [-0.1107,  0.1125, -0.0375,  ..., -0.0060, -0.0355, -0.0752],\n",
      "        ...,\n",
      "        [ 0.0602, -0.0396,  0.0898,  ..., -0.0085,  0.0317,  0.0961],\n",
      "        [ 0.0305, -0.0115,  0.1052,  ..., -0.0618,  0.0209,  0.0363],\n",
      "        [-0.0087, -0.0185,  0.0959,  ..., -0.0363,  0.0504,  0.0536]],\n",
      "       device='cuda:0')\n",
      "rnn_l41.weight_hh_l0 tensor([[ 0.1357, -0.0342, -0.0416,  ..., -0.0155, -0.1172, -0.0606],\n",
      "        [-0.0139,  0.1157, -0.0245,  ..., -0.0562,  0.0935,  0.0445],\n",
      "        [ 0.0979, -0.0336, -0.0424,  ...,  0.0293, -0.0608, -0.0543],\n",
      "        ...,\n",
      "        [-0.0247,  0.0039,  0.0278,  ..., -0.0559,  0.0104,  0.0528],\n",
      "        [-0.0628,  0.0916,  0.0407,  ..., -0.0758, -0.0054,  0.0958],\n",
      "        [-0.0048, -0.0098,  0.0161,  ..., -0.0979,  0.0902,  0.0835]],\n",
      "       device='cuda:0')\n",
      "rnn_l41.bias_ih_l0 tensor([ 2.9993e-02, -9.4496e-02,  3.7064e-02, -6.6968e-02,  7.8411e-03,\n",
      "         2.0726e-02,  1.0764e-01,  9.5308e-03, -2.7280e-02,  2.8303e-02,\n",
      "         1.0742e-01, -2.6547e-02, -7.3357e-02, -4.6546e-03, -1.2217e-01,\n",
      "        -5.4770e-02, -1.5513e-02,  1.3008e-01,  1.3451e-02, -1.2158e-01,\n",
      "         5.9746e-02,  1.8077e-04, -9.8905e-02,  2.4382e-02,  1.5927e-02,\n",
      "        -8.9000e-02, -1.7033e-02, -4.8292e-02, -1.2634e-02,  1.1423e-01,\n",
      "        -1.0618e-01, -8.0815e-03,  1.2841e-01,  1.2347e-02, -1.5921e-02,\n",
      "         3.3963e-02,  3.5921e-02, -7.7892e-02,  1.2329e-01, -8.4018e-03,\n",
      "        -5.1702e-02,  4.0265e-02,  3.1349e-02, -3.5067e-03, -4.9041e-02,\n",
      "         7.6238e-02, -2.1693e-02, -1.0642e-01,  1.2290e-01,  1.2711e-02,\n",
      "         5.7480e-02, -5.4193e-02, -4.2957e-02, -1.0184e-01, -3.2617e-02,\n",
      "        -3.6283e-02, -9.3205e-03,  1.1817e-01,  9.8912e-02, -8.2648e-02,\n",
      "        -1.4184e-02, -7.6379e-02,  1.3382e-01, -2.3658e-02, -3.0948e-02,\n",
      "        -6.7635e-02, -6.4232e-03,  7.7289e-02,  1.4263e-01,  2.7483e-03,\n",
      "         8.9669e-02, -1.1024e-03, -3.6800e-02, -9.2248e-03,  1.7497e-02,\n",
      "         3.2508e-02, -1.4934e-02, -1.2347e-01,  9.6308e-03, -9.6476e-02,\n",
      "         1.9405e-02,  8.6973e-02,  1.7244e-02,  1.1796e-01,  1.0797e-02,\n",
      "         8.1122e-02, -1.2161e-02,  9.0174e-03,  1.0724e-02, -7.4036e-03,\n",
      "        -1.1393e-01, -1.1744e-01,  1.1304e-01, -1.3786e-01,  2.0036e-02,\n",
      "        -8.1931e-03, -5.0135e-02, -2.9987e-02, -1.7934e-02, -4.3313e-02,\n",
      "        -9.3071e-03, -2.3702e-02,  1.1592e-01, -1.1732e-01, -6.0017e-02,\n",
      "         1.9633e-02,  4.4468e-02, -7.0314e-02, -1.1350e-02,  5.0761e-02,\n",
      "        -7.8505e-02, -7.9759e-03,  6.3765e-02,  3.5180e-02, -3.2214e-02,\n",
      "         1.8878e-02, -6.3875e-02, -2.8024e-02, -5.5330e-02, -8.2495e-02,\n",
      "         1.6298e-02,  2.1216e-02, -5.0354e-02, -8.0402e-02, -7.6941e-02,\n",
      "        -1.1918e-01,  8.1270e-02, -4.8546e-02, -3.5670e-02, -1.1109e-01,\n",
      "        -7.2483e-02,  7.0053e-02, -7.9874e-02, -8.6553e-02,  2.6469e-02,\n",
      "         1.1934e-01,  2.6389e-02, -1.0769e-02, -4.9256e-02, -1.3069e-02,\n",
      "         7.7635e-02, -9.0308e-02, -8.6127e-03, -6.4204e-02,  8.4770e-02,\n",
      "         1.4958e-02, -2.1617e-02,  5.6524e-03,  5.2300e-02, -3.1447e-02,\n",
      "         6.1701e-02,  1.0719e-02, -8.3751e-02,  1.0968e-01, -1.2438e-04,\n",
      "         4.0072e-02,  1.0285e-01,  1.1658e-01,  1.0053e-03,  8.6038e-02,\n",
      "        -1.1066e-01,  6.7861e-02, -2.0463e-03, -7.1347e-02,  4.5214e-02,\n",
      "         1.0664e-01, -6.6146e-02,  2.8550e-02, -4.7503e-02, -9.4417e-02,\n",
      "        -1.4932e-02,  1.1447e-01, -1.3189e-02,  6.1683e-02,  8.8813e-03,\n",
      "        -2.1018e-02,  4.2348e-02, -1.6289e-03, -1.1524e-01, -9.4918e-02,\n",
      "        -3.7044e-02,  3.8525e-02, -9.5753e-02, -9.3505e-02, -6.8407e-02,\n",
      "        -6.1039e-02, -7.1967e-02,  4.1724e-02,  7.3212e-02,  1.1526e-01,\n",
      "         7.6980e-03, -9.5706e-02,  3.6300e-02, -9.5044e-02, -9.4095e-02,\n",
      "         1.0501e-01,  5.4955e-02, -2.1255e-03, -8.0995e-02, -8.6269e-02],\n",
      "       device='cuda:0')\n",
      "rnn_l41.bias_hh_l0 tensor([ 0.1080, -0.0464,  0.1016, -0.0082, -0.0354, -0.0250,  0.0995, -0.0158,\n",
      "        -0.0408,  0.0019,  0.0358, -0.0874, -0.1040, -0.0264, -0.0738, -0.0290,\n",
      "         0.0300,  0.0945,  0.0244, -0.0014,  0.0646,  0.0563, -0.0650,  0.0233,\n",
      "        -0.0071, -0.0169,  0.0240,  0.0378, -0.1046,  0.0319, -0.0746,  0.0139,\n",
      "         0.1353, -0.0506, -0.0479,  0.0069, -0.0201, -0.0087,  0.0900, -0.0226,\n",
      "        -0.0958,  0.1242,  0.1137, -0.1013,  0.0185,  0.0336, -0.0895, -0.0067,\n",
      "         0.0727,  0.1266,  0.0955, -0.0360,  0.0012,  0.0075, -0.0355, -0.1114,\n",
      "        -0.0590,  0.0323,  0.1165, -0.0267,  0.0244, -0.0924,  0.0012, -0.0257,\n",
      "        -0.1008, -0.0173, -0.0230, -0.0082,  0.1307, -0.0229,  0.0588,  0.0994,\n",
      "        -0.1117,  0.0158,  0.0304,  0.0589, -0.0887, -0.0475, -0.0030, -0.0974,\n",
      "        -0.0304, -0.0313, -0.0445,  0.1150,  0.1292,  0.0632, -0.0537,  0.1235,\n",
      "        -0.0034, -0.1014, -0.0356, -0.0142,  0.0926, -0.1243,  0.0503, -0.1286,\n",
      "        -0.1297,  0.0003, -0.0027,  0.0010,  0.0219,  0.0137,  0.0548, -0.1002,\n",
      "        -0.1026, -0.0576,  0.0100, -0.1133, -0.0846,  0.0359, -0.1251,  0.0495,\n",
      "         0.0987,  0.0320, -0.0446,  0.0828,  0.0200, -0.0484, -0.1201, -0.0295,\n",
      "         0.0874,  0.0284, -0.0548, -0.1267, -0.0863, -0.1261,  0.0359, -0.0858,\n",
      "         0.0066, -0.0485, -0.0999,  0.0493, -0.0660, -0.0543,  0.1248,  0.0525,\n",
      "        -0.0019, -0.0949, -0.0370,  0.0823,  0.0873, -0.0605, -0.0547, -0.1070,\n",
      "         0.0489,  0.0260, -0.0212,  0.0344,  0.0043, -0.0277,  0.0749, -0.0011,\n",
      "        -0.0480,  0.0484, -0.0346,  0.0865,  0.0109,  0.1016, -0.0832, -0.0258,\n",
      "         0.0081,  0.0708, -0.1122, -0.0948,  0.0027,  0.1399, -0.0770,  0.0100,\n",
      "        -0.0207, -0.0164, -0.0083,  0.1352, -0.0548,  0.0312,  0.0260, -0.0482,\n",
      "         0.0270,  0.1048, -0.0004, -0.0559, -0.0525, -0.0129, -0.0419, -0.0111,\n",
      "        -0.1003, -0.0959, -0.0206,  0.0362,  0.0456,  0.0619,  0.0133, -0.1243,\n",
      "        -0.0245, -0.1298, -0.0032,  0.0845,  0.0228, -0.0335, -0.0746,  0.0100],\n",
      "       device='cuda:0')\n",
      "rnn_l41.weight_ih_l0_reverse tensor([[-0.0258,  0.1108, -0.1128,  ...,  0.0688, -0.0715, -0.0160],\n",
      "        [ 0.0246,  0.0597,  0.0352,  ...,  0.0394,  0.0396, -0.1065],\n",
      "        [-0.1305,  0.0486, -0.1039,  ...,  0.1307, -0.0784, -0.0737],\n",
      "        ...,\n",
      "        [-0.0363,  0.0604,  0.0797,  ...,  0.0509,  0.0861, -0.0776],\n",
      "        [ 0.0141,  0.0113,  0.0791,  ..., -0.0751,  0.1270,  0.0642],\n",
      "        [-0.0247,  0.0680, -0.0794,  ...,  0.0557, -0.1021, -0.0820]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_l41.weight_hh_l0_reverse tensor([[ 0.1041, -0.0808,  0.0887,  ..., -0.1192, -0.0012,  0.0685],\n",
      "        [ 0.0122, -0.0532, -0.0337,  ..., -0.0868, -0.0553,  0.0156],\n",
      "        [ 0.0083, -0.0380,  0.0235,  ..., -0.0324, -0.0888,  0.0856],\n",
      "        ...,\n",
      "        [-0.0760,  0.0874, -0.0654,  ..., -0.0201,  0.0485, -0.0263],\n",
      "        [-0.0259,  0.0911, -0.1134,  ...,  0.0240,  0.1143, -0.0855],\n",
      "        [-0.0092,  0.0113,  0.1347,  ..., -0.0535, -0.1079,  0.1071]],\n",
      "       device='cuda:0')\n",
      "rnn_l41.bias_ih_l0_reverse tensor([ 0.0295, -0.0027,  0.1307,  0.1233,  0.0047, -0.0635,  0.0162, -0.0016,\n",
      "        -0.1311,  0.1141,  0.0062, -0.0283,  0.0790,  0.0734, -0.0712,  0.0853,\n",
      "        -0.0890,  0.0149, -0.0035, -0.0165, -0.1131,  0.0768,  0.0702, -0.0982,\n",
      "         0.0751,  0.0827,  0.0176,  0.0650, -0.0805,  0.1280,  0.0322,  0.0732,\n",
      "         0.0193, -0.0199,  0.0195, -0.0703, -0.0351, -0.0251, -0.0585,  0.0528,\n",
      "         0.0208,  0.0170,  0.0230,  0.0468,  0.0447, -0.1236, -0.0857, -0.0133,\n",
      "         0.0882,  0.1205,  0.1394, -0.1024,  0.0924,  0.0731,  0.0781, -0.1079,\n",
      "        -0.0319, -0.0117,  0.0077,  0.0933, -0.0454,  0.1000, -0.1001, -0.0736,\n",
      "        -0.0236, -0.0140, -0.0366,  0.0406, -0.0202,  0.0679,  0.0323,  0.0059,\n",
      "         0.0821, -0.0283, -0.1146, -0.0448, -0.0542,  0.0613, -0.0356,  0.0499,\n",
      "        -0.1217, -0.1380,  0.0784,  0.0309,  0.0076,  0.0274, -0.1101,  0.0455,\n",
      "        -0.1058,  0.0634,  0.1123,  0.0419,  0.0225, -0.1051,  0.0275,  0.1019,\n",
      "         0.1256,  0.0491, -0.1029,  0.0354, -0.0522, -0.0689, -0.0462, -0.0302,\n",
      "         0.0914, -0.1044, -0.0065,  0.1092, -0.0252,  0.0377,  0.0488,  0.0117,\n",
      "        -0.0366, -0.0451, -0.0255, -0.0515,  0.0572,  0.0469,  0.0281,  0.0229,\n",
      "         0.1255,  0.0292,  0.0007, -0.0170,  0.0529,  0.1007, -0.0008, -0.0833,\n",
      "         0.0920,  0.0795, -0.0109, -0.0042, -0.0583, -0.0078, -0.0755,  0.0604,\n",
      "        -0.0314,  0.1010,  0.0222,  0.0758, -0.0268, -0.0050, -0.0655, -0.0930,\n",
      "         0.0803, -0.0377,  0.0321, -0.0536,  0.0407, -0.0027,  0.0094,  0.0496,\n",
      "        -0.0063, -0.0493, -0.0620, -0.0381,  0.0266, -0.0933,  0.1282, -0.0899,\n",
      "         0.0977, -0.0342, -0.0459,  0.1128, -0.0348, -0.1024, -0.0333, -0.0199,\n",
      "         0.0779, -0.0034,  0.1163, -0.0447,  0.0172,  0.1163, -0.0941,  0.0013,\n",
      "        -0.0346,  0.0328,  0.0813, -0.0233, -0.0282,  0.0764, -0.0692, -0.1181,\n",
      "         0.0176, -0.0698, -0.0482,  0.0699, -0.1242, -0.1127, -0.1295, -0.0536,\n",
      "        -0.0731, -0.0970, -0.0014,  0.0897, -0.0073, -0.0287, -0.0493,  0.0993],\n",
      "       device='cuda:0')\n",
      "rnn_l41.bias_hh_l0_reverse tensor([ 1.1863e-01,  7.0280e-02,  8.9796e-02,  2.4210e-02,  1.2892e-04,\n",
      "        -3.9379e-02,  6.2502e-02,  1.3892e-02, -1.1416e-01,  9.6111e-02,\n",
      "        -1.0314e-01, -7.8823e-02,  1.4398e-02,  1.0473e-01, -1.6249e-02,\n",
      "         1.1122e-01, -2.4209e-02,  1.2058e-01, -7.1174e-02, -1.8595e-02,\n",
      "        -1.1615e-01,  8.4333e-03,  3.0913e-04,  9.5328e-03,  1.2051e-01,\n",
      "        -3.5012e-03,  1.0335e-01, -6.6718e-02, -8.0660e-02,  1.2875e-01,\n",
      "        -2.5773e-02,  1.2083e-01, -1.2231e-02, -1.0727e-02, -2.9542e-02,\n",
      "        -8.2584e-02, -2.2821e-02,  6.6017e-02, -3.8325e-02,  2.2674e-03,\n",
      "         2.7565e-02, -3.7432e-02,  2.9521e-02,  6.7814e-02,  1.7483e-02,\n",
      "        -5.5776e-02, -4.8213e-03, -1.2757e-02,  4.1162e-02,  3.0493e-02,\n",
      "         1.1620e-01, -1.0057e-01,  3.3119e-02,  7.0910e-02,  9.1249e-02,\n",
      "        -1.2241e-01, -7.6781e-02, -7.6315e-02,  9.6081e-02, -8.7108e-04,\n",
      "        -8.3755e-02,  1.0170e-01, -3.9610e-02,  1.5498e-02, -5.4651e-03,\n",
      "        -2.1238e-02, -9.4178e-02,  1.0573e-01, -9.4729e-02,  7.5440e-02,\n",
      "         7.3563e-02, -1.0727e-01,  4.5560e-02,  2.4368e-02,  4.0658e-03,\n",
      "        -2.1540e-02, -9.4330e-02,  5.2474e-02, -1.1032e-01,  2.7272e-02,\n",
      "        -1.0553e-01, -7.6913e-02, -1.7435e-02,  9.3406e-02, -4.9738e-02,\n",
      "        -9.8444e-02, -6.7652e-02,  7.1908e-02, -4.7738e-02,  9.1200e-02,\n",
      "        -8.5105e-03,  4.2812e-02, -4.7959e-02, -2.7212e-02,  6.2559e-02,\n",
      "         1.2274e-01,  4.6079e-02,  1.1831e-01, -3.0270e-03,  4.0628e-02,\n",
      "         1.3378e-02, -7.1588e-02,  2.8539e-04, -8.3327e-03,  8.5921e-03,\n",
      "        -3.0715e-02, -1.1634e-01,  8.6964e-02, -1.8847e-03,  1.6657e-03,\n",
      "        -2.1008e-02,  8.2914e-02,  1.8628e-02, -1.5706e-02,  5.7851e-02,\n",
      "        -1.5638e-02,  9.7068e-02,  2.4632e-02,  1.5432e-02, -3.6199e-02,\n",
      "         1.2190e-02,  1.5479e-02,  1.4372e-02, -2.3957e-02,  1.2975e-02,\n",
      "         7.0260e-02, -3.0947e-02, -1.2197e-01,  1.8986e-02,  1.2714e-01,\n",
      "         8.5311e-02,  2.3842e-02, -1.0363e-01, -9.9085e-02, -7.3598e-02,\n",
      "         1.2083e-01, -5.7886e-02,  3.4212e-02, -7.8565e-02,  5.1995e-03,\n",
      "        -5.2254e-02, -2.8946e-02, -2.0939e-02, -1.1903e-01, -1.6973e-02,\n",
      "         2.4937e-03, -8.2113e-02, -1.3301e-02, -2.9454e-02, -1.1917e-01,\n",
      "        -5.3453e-02, -6.4595e-02,  4.1291e-02,  2.5138e-03, -1.0003e-01,\n",
      "         1.1729e-02,  7.3702e-03,  9.0108e-04,  1.8495e-03, -2.4472e-02,\n",
      "         7.3193e-02,  4.5895e-02, -3.6019e-02,  5.6701e-02, -8.7417e-02,\n",
      "        -1.0439e-01, -4.1591e-02, -2.0039e-02,  1.0134e-01,  2.6987e-02,\n",
      "         3.8978e-02, -4.5605e-02, -1.0544e-03,  1.1320e-01, -3.6292e-02,\n",
      "         1.7011e-02, -5.8937e-02,  1.0808e-01,  8.0219e-02, -2.6049e-02,\n",
      "         1.6455e-02, -8.3900e-03, -9.7052e-02, -9.7768e-02, -7.1070e-03,\n",
      "        -1.1986e-01, -5.4939e-02, -2.5214e-02, -7.5685e-02,  3.0653e-04,\n",
      "        -6.0419e-02, -1.4127e-01, -7.5329e-02, -6.4039e-02, -4.2491e-02,\n",
      "         1.3575e-01, -1.4418e-02,  7.5136e-03,  2.7752e-03,  1.2145e-01],\n",
      "       device='cuda:0')\n",
      "rnn_l42.weight_ih_l0 tensor([[-0.1308, -0.0339,  0.0894,  ..., -0.0924,  0.0142, -0.0521],\n",
      "        [-0.0216, -0.1085,  0.0307,  ..., -0.1179,  0.0824, -0.1090],\n",
      "        [ 0.0778,  0.1009, -0.0628,  ...,  0.0311,  0.0031,  0.0595],\n",
      "        ...,\n",
      "        [ 0.1091, -0.1127,  0.0424,  ...,  0.0082,  0.0543, -0.0577],\n",
      "        [ 0.0063, -0.0158,  0.0768,  ..., -0.0995, -0.0980, -0.0515],\n",
      "        [ 0.0477, -0.0686,  0.0290,  ..., -0.0092,  0.0401, -0.0322]],\n",
      "       device='cuda:0')\n",
      "rnn_l42.weight_hh_l0 tensor([[ 0.0138,  0.0447, -0.0051,  ...,  0.0789,  0.0167, -0.0126],\n",
      "        [ 0.1226,  0.0281,  0.0655,  ...,  0.1116,  0.0092, -0.0411],\n",
      "        [-0.1046, -0.0028, -0.0829,  ..., -0.0750,  0.0531,  0.0607],\n",
      "        ...,\n",
      "        [ 0.0288,  0.0986,  0.1038,  ..., -0.0316, -0.0596, -0.1061],\n",
      "        [ 0.0295,  0.0092,  0.0840,  ...,  0.0827, -0.0405, -0.1194],\n",
      "        [ 0.0598,  0.0903,  0.1164,  ...,  0.0225, -0.0544, -0.0375]],\n",
      "       device='cuda:0')\n",
      "rnn_l42.bias_ih_l0 tensor([-0.0056, -0.0369, -0.0166, -0.0196, -0.0698, -0.0159,  0.0886, -0.0127,\n",
      "         0.0915,  0.0163,  0.0962, -0.0376,  0.0205, -0.0516,  0.0545,  0.1144,\n",
      "        -0.0096,  0.0988, -0.1127, -0.0169, -0.0014,  0.0920,  0.0103,  0.1207,\n",
      "        -0.0237, -0.0592,  0.0033, -0.1086,  0.0171,  0.0067, -0.0760,  0.0565,\n",
      "        -0.0982, -0.0046, -0.1217,  0.1083, -0.1343, -0.0510,  0.0933, -0.0222,\n",
      "         0.0269,  0.0338,  0.0483, -0.0739, -0.1122,  0.0331,  0.0285,  0.0728,\n",
      "        -0.1234,  0.0520, -0.0085, -0.0088,  0.0556, -0.0379, -0.0113,  0.0155,\n",
      "         0.0168,  0.0191, -0.0861,  0.0531, -0.0677, -0.0714, -0.1095,  0.0427,\n",
      "         0.1017, -0.0633,  0.0848, -0.1065, -0.0251,  0.0283,  0.0970, -0.0305,\n",
      "         0.0350,  0.0808,  0.0537,  0.0362, -0.0332, -0.0175,  0.0174,  0.0981,\n",
      "         0.0335,  0.0687, -0.0040,  0.0904, -0.0320, -0.0571,  0.0235,  0.0098,\n",
      "        -0.0900, -0.0763, -0.0590,  0.1085, -0.0873,  0.1079,  0.0114,  0.0452,\n",
      "        -0.1037, -0.0985, -0.0653, -0.0107, -0.1212,  0.0141,  0.0449,  0.0228,\n",
      "         0.0416, -0.0321,  0.1072, -0.0206,  0.0465,  0.0580, -0.0031, -0.0057,\n",
      "        -0.0696, -0.1125,  0.0496, -0.1081,  0.0343,  0.0144,  0.0002, -0.0258,\n",
      "        -0.0100,  0.0113, -0.1111,  0.0540,  0.0966,  0.0057,  0.0517,  0.0538,\n",
      "         0.0078,  0.1171, -0.1125, -0.1189,  0.0235, -0.1077, -0.0179, -0.0011,\n",
      "        -0.0915, -0.0143,  0.0009, -0.0724,  0.0304, -0.0178,  0.0631,  0.0206,\n",
      "         0.1274, -0.0373,  0.0083, -0.0292,  0.0171, -0.0237, -0.0757,  0.1004,\n",
      "        -0.0081,  0.0082, -0.0285,  0.0003, -0.0435, -0.0837,  0.0879,  0.0007,\n",
      "         0.0863, -0.1178,  0.0636, -0.0907,  0.0606, -0.0826, -0.0316,  0.0882,\n",
      "         0.0682, -0.0486, -0.0483,  0.0650, -0.0413, -0.0874,  0.0936,  0.0496,\n",
      "        -0.0884, -0.1091,  0.0163, -0.1261, -0.0185, -0.0610, -0.0859,  0.0955,\n",
      "        -0.0298,  0.0103, -0.0866,  0.0108,  0.0318, -0.1265, -0.1268,  0.0610,\n",
      "        -0.0703, -0.0631,  0.0268,  0.0421, -0.0303, -0.0799, -0.0139, -0.0425],\n",
      "       device='cuda:0')\n",
      "rnn_l42.bias_hh_l0 tensor([-0.1020, -0.0909,  0.0931, -0.0824, -0.0941, -0.0317,  0.0108, -0.0850,\n",
      "         0.0767,  0.0031,  0.1247,  0.0336,  0.0035,  0.0025,  0.0561,  0.1031,\n",
      "        -0.0707,  0.0189, -0.0222,  0.0408,  0.0679,  0.0125,  0.0421,  0.0646,\n",
      "        -0.0289, -0.0025,  0.0909, -0.0782, -0.1192,  0.1270, -0.0716,  0.0111,\n",
      "        -0.0888, -0.0827, -0.0073,  0.0807, -0.0621, -0.0217,  0.0930, -0.0586,\n",
      "         0.0806, -0.0726,  0.0645, -0.0829, -0.1001,  0.1001,  0.0621,  0.0259,\n",
      "        -0.0527,  0.0658, -0.0538,  0.0334,  0.0633, -0.0025, -0.0438,  0.0779,\n",
      "        -0.0251, -0.0658, -0.0390,  0.0116, -0.0382, -0.0039, -0.1106, -0.0196,\n",
      "         0.0374, -0.0421,  0.1153, -0.1191, -0.0784,  0.0502,  0.0053, -0.0712,\n",
      "        -0.0095,  0.0855,  0.0384,  0.0917, -0.0053,  0.0167,  0.0080, -0.0029,\n",
      "         0.0019,  0.1225,  0.0280,  0.0341, -0.0736, -0.0892, -0.0012, -0.0362,\n",
      "         0.0159, -0.1112, -0.0664,  0.0034, -0.0143,  0.0739,  0.0240,  0.1383,\n",
      "        -0.0161, -0.0878, -0.1054, -0.0415, -0.0687, -0.1050, -0.0320,  0.0033,\n",
      "         0.0660, -0.0420,  0.0105, -0.1161,  0.0664,  0.1187,  0.1099,  0.0075,\n",
      "        -0.1367, -0.0252,  0.0970,  0.0119,  0.0457,  0.0341, -0.0752, -0.0060,\n",
      "         0.0452, -0.0102, -0.0017,  0.0874, -0.0143,  0.0331, -0.0082,  0.0378,\n",
      "         0.0371,  0.0997, -0.0674, -0.0784,  0.0017, -0.0567, -0.0497,  0.0296,\n",
      "         0.0119,  0.0076, -0.0368,  0.0021, -0.0287, -0.1072,  0.0055,  0.0938,\n",
      "         0.0354, -0.0181,  0.0895, -0.0628, -0.0274, -0.1072, -0.0860,  0.0816,\n",
      "        -0.0606,  0.0100,  0.0025, -0.0240, -0.0925, -0.0318,  0.0871, -0.0919,\n",
      "         0.1169, -0.0153,  0.0802, -0.0968,  0.0416, -0.1095, -0.0264,  0.0993,\n",
      "         0.0053,  0.0074, -0.0456, -0.0111, -0.0754, -0.0675,  0.0080,  0.0299,\n",
      "        -0.0904, -0.1159, -0.0735, -0.0788,  0.1101, -0.0045, -0.0538,  0.0485,\n",
      "        -0.0119, -0.1169, -0.0537, -0.1105,  0.0265, -0.0250, -0.0462, -0.0396,\n",
      "        -0.0697, -0.0641,  0.0714,  0.1013, -0.0680, -0.1121, -0.0488, -0.0187],\n",
      "       device='cuda:0')\n",
      "rnn_l42.weight_ih_l0_reverse tensor([[ 0.0215, -0.0288,  0.0349,  ..., -0.0650, -0.0029,  0.0020],\n",
      "        [ 0.0222,  0.0675, -0.0355,  ..., -0.0232, -0.0035,  0.1129],\n",
      "        [-0.0346, -0.1252,  0.0906,  ..., -0.0079,  0.0167, -0.0343],\n",
      "        ...,\n",
      "        [ 0.0164,  0.0303, -0.1218,  ...,  0.0802, -0.0528,  0.0709],\n",
      "        [-0.1366, -0.1363,  0.1045,  ...,  0.0006, -0.0286, -0.0440],\n",
      "        [-0.0481, -0.0828,  0.0243,  ..., -0.0947, -0.0145, -0.0803]],\n",
      "       device='cuda:0')\n",
      "rnn_l42.weight_hh_l0_reverse tensor([[ 0.0359, -0.0058,  0.0485,  ..., -0.0070,  0.0143, -0.0053],\n",
      "        [ 0.0853, -0.1006,  0.0069,  ..., -0.0832,  0.0789, -0.0101],\n",
      "        [ 0.1034, -0.0684,  0.0982,  ..., -0.0410,  0.0307,  0.1063],\n",
      "        ...,\n",
      "        [-0.0471,  0.0956, -0.1349,  ...,  0.0246,  0.0080, -0.0260],\n",
      "        [-0.0050, -0.0404,  0.0024,  ...,  0.0056,  0.0951,  0.1322],\n",
      "        [ 0.0419, -0.0913,  0.0121,  ..., -0.0241,  0.0325,  0.0284]],\n",
      "       device='cuda:0')\n",
      "rnn_l42.bias_ih_l0_reverse tensor([-0.0563,  0.0446, -0.0386, -0.0969, -0.0026,  0.1207,  0.0851, -0.1037,\n",
      "        -0.1217,  0.0895, -0.1225, -0.0169,  0.0950,  0.0267,  0.0256, -0.0170,\n",
      "         0.0872,  0.0691,  0.0323, -0.1378, -0.0337, -0.0109, -0.0450, -0.0926,\n",
      "         0.0849,  0.0784,  0.0028,  0.0550, -0.0072,  0.0842, -0.1172,  0.0066,\n",
      "         0.0418, -0.0117, -0.0492, -0.0159,  0.0348, -0.0352, -0.1194, -0.0072,\n",
      "        -0.0369,  0.0608, -0.0181,  0.0798, -0.0248,  0.0451, -0.0950, -0.0706,\n",
      "        -0.0306,  0.0551,  0.0058, -0.0080,  0.0292, -0.0246,  0.0232, -0.0245,\n",
      "         0.1038,  0.1244, -0.1118, -0.0149, -0.0598, -0.0291, -0.0930,  0.1104,\n",
      "        -0.1159, -0.1025, -0.0006, -0.0604,  0.0780,  0.0388,  0.1139,  0.0051,\n",
      "         0.0671,  0.0002,  0.0009, -0.1059,  0.0275,  0.0208,  0.0135, -0.0366,\n",
      "         0.0009,  0.0610,  0.0079, -0.0338,  0.0376, -0.1076, -0.0604, -0.0361,\n",
      "        -0.0840,  0.0683,  0.1090,  0.0018, -0.0130, -0.1093, -0.0146,  0.0640,\n",
      "         0.0012,  0.0648,  0.0094, -0.0506, -0.0080, -0.0679, -0.0256,  0.0764,\n",
      "         0.1124, -0.0627,  0.0532, -0.0670, -0.0949, -0.0748, -0.0004,  0.0115,\n",
      "         0.0048, -0.1239, -0.0777, -0.0927, -0.0359,  0.0383, -0.0670, -0.0592,\n",
      "         0.0125,  0.0762,  0.0584,  0.0918, -0.0263, -0.0053,  0.0426,  0.0954,\n",
      "        -0.0288, -0.0008, -0.0194, -0.0816,  0.0153, -0.0100,  0.0234,  0.1210,\n",
      "         0.1154, -0.0556,  0.0544, -0.0161,  0.0480,  0.0984, -0.0745, -0.0925,\n",
      "         0.0746, -0.0112, -0.0725,  0.0734, -0.1233,  0.0419, -0.0019, -0.0829,\n",
      "        -0.0476, -0.0180,  0.0438,  0.1097, -0.0217,  0.0318, -0.0632, -0.0821,\n",
      "        -0.0844,  0.1230,  0.1244,  0.0290,  0.0203, -0.0291,  0.0488, -0.0938,\n",
      "        -0.0328, -0.0255, -0.1085,  0.0554, -0.0498, -0.1031, -0.1027, -0.1227,\n",
      "        -0.0277, -0.0973,  0.0359, -0.0642,  0.1097, -0.0340, -0.0394, -0.0697,\n",
      "         0.0339, -0.0364,  0.1394, -0.0616, -0.0253, -0.0517, -0.0348,  0.0803,\n",
      "         0.0816,  0.1187, -0.0762,  0.0182, -0.0052,  0.1212, -0.0411, -0.0839],\n",
      "       device='cuda:0')\n",
      "rnn_l42.bias_hh_l0_reverse tensor([-0.0883,  0.0125, -0.0583, -0.0161,  0.0254,  0.0455,  0.0934, -0.0800,\n",
      "        -0.1307,  0.0850, -0.1272, -0.0849,  0.1356, -0.0939,  0.0051,  0.0604,\n",
      "         0.0436,  0.0385,  0.0176, -0.0717,  0.0160,  0.0510, -0.1092, -0.0201,\n",
      "        -0.0176,  0.0655, -0.0002,  0.0591,  0.0595,  0.1113, -0.0267,  0.0003,\n",
      "        -0.0012,  0.1070,  0.0043,  0.1004,  0.1020, -0.0803, -0.0962,  0.0237,\n",
      "        -0.0277,  0.0278, -0.0155,  0.0485, -0.0112,  0.0302, -0.1044, -0.0146,\n",
      "        -0.0327,  0.0481,  0.0844,  0.0031, -0.0395, -0.0259,  0.0791,  0.0695,\n",
      "         0.0860,  0.1083, -0.0470,  0.0878, -0.1085,  0.0009, -0.1224, -0.0163,\n",
      "        -0.0148, -0.0470,  0.0614, -0.0663, -0.0035,  0.0731,  0.0140, -0.0445,\n",
      "         0.0154, -0.1327, -0.0051, -0.0035,  0.0460, -0.0097,  0.0250, -0.0636,\n",
      "        -0.0843,  0.0483, -0.0109,  0.0079,  0.0113, -0.0205,  0.0116,  0.0232,\n",
      "        -0.0743,  0.0808,  0.0449,  0.0048, -0.1326, -0.0850, -0.0418,  0.0986,\n",
      "         0.0581,  0.0018, -0.0132, -0.1061,  0.0290, -0.1022, -0.1049, -0.0204,\n",
      "         0.0235, -0.0944,  0.1039, -0.0739, -0.1271, -0.0782,  0.0909, -0.0029,\n",
      "         0.0744, -0.0445, -0.0474, -0.0080, -0.0586,  0.0550, -0.0045, -0.0891,\n",
      "         0.0963,  0.0631, -0.0389,  0.0423, -0.0985, -0.0300,  0.0826,  0.1149,\n",
      "        -0.0296, -0.0545, -0.1078, -0.0405,  0.1160,  0.0285,  0.0825,  0.1210,\n",
      "         0.0695, -0.0360,  0.0631,  0.0622,  0.0275,  0.0744, -0.0541, -0.0527,\n",
      "         0.0968, -0.0411, -0.1234,  0.1141, -0.1109, -0.0018, -0.0474, -0.0857,\n",
      "        -0.0616, -0.0076,  0.0514,  0.0097, -0.0747,  0.1143, -0.0589, -0.0686,\n",
      "        -0.0942,  0.1053,  0.1238, -0.0342,  0.0058,  0.0105,  0.0765, -0.0554,\n",
      "        -0.0804, -0.0336,  0.0027,  0.0106,  0.0011, -0.0341, -0.0530,  0.0176,\n",
      "        -0.0898, -0.0683,  0.0254, -0.0440,  0.0791, -0.0472, -0.0496, -0.0552,\n",
      "        -0.0080,  0.0080,  0.0141, -0.0420, -0.0798, -0.1213, -0.0862,  0.1343,\n",
      "         0.0819,  0.0134, -0.1229,  0.1191, -0.0123,  0.0749, -0.0483, -0.0397],\n",
      "       device='cuda:0')\n",
      "rnn_l6.weight_ih_l0 tensor([[-0.0563, -0.0089,  0.0473,  ..., -0.0771,  0.0862,  0.0931],\n",
      "        [-0.0512,  0.0058,  0.0004,  ..., -0.0822,  0.0461,  0.0646],\n",
      "        [-0.0606,  0.0036, -0.0258,  ..., -0.0826,  0.0887,  0.0564],\n",
      "        ...,\n",
      "        [-0.0866, -0.0146, -0.0519,  ..., -0.0113,  0.0685,  0.0270],\n",
      "        [-0.0902, -0.0230, -0.0189,  ..., -0.0212,  0.0167,  0.0416],\n",
      "        [-0.0830,  0.0055, -0.0403,  ..., -0.0651,  0.0549,  0.0512]],\n",
      "       device='cuda:0')\n",
      "rnn_l6.weight_hh_l0 tensor([[-0.0370,  0.0359, -0.0833,  ...,  0.0976,  0.0132, -0.0178],\n",
      "        [-0.0390, -0.0357, -0.0036,  ...,  0.0404,  0.0339,  0.0291],\n",
      "        [-0.0230, -0.0002,  0.0443,  ..., -0.0701,  0.0529,  0.0843],\n",
      "        ...,\n",
      "        [-0.0333,  0.0444, -0.0636,  ...,  0.0673,  0.0481, -0.0593],\n",
      "        [ 0.0008, -0.0341,  0.0136,  ...,  0.0454,  0.0185, -0.0015],\n",
      "        [-0.0847, -0.0321,  0.0243,  ...,  0.0077,  0.0476, -0.0138]],\n",
      "       device='cuda:0')\n",
      "rnn_l6.bias_ih_l0 tensor([-0.0674, -0.0870, -0.0879,  ..., -0.0838, -0.0741, -0.0775],\n",
      "       device='cuda:0')\n",
      "rnn_l6.bias_hh_l0 tensor([-0.0084, -0.1038, -0.0419,  ..., -0.0169, -0.0114, -0.0528],\n",
      "       device='cuda:0')\n",
      "rnn_l6.weight_ih_l0_reverse tensor([[ 0.0297,  0.0025,  0.0166,  ...,  0.0835, -0.0058, -0.0190],\n",
      "        [ 0.0833,  0.0646,  0.0258,  ...,  0.0301, -0.0755, -0.0764],\n",
      "        [ 0.0716,  0.0017,  0.0757,  ...,  0.0970, -0.1145, -0.0198],\n",
      "        ...,\n",
      "        [ 0.0633, -0.0678,  0.0697,  ...,  0.0754, -0.0111, -0.0739],\n",
      "        [-0.0681, -0.0034,  0.0152,  ..., -0.0520,  0.0982,  0.0125],\n",
      "        [ 0.0880, -0.0213,  0.0794,  ...,  0.0413, -0.0674, -0.0901]],\n",
      "       device='cuda:0')\n",
      "rnn_l6.weight_hh_l0_reverse tensor([[-0.0064, -0.0079,  0.0279,  ..., -0.0337,  0.0088, -0.0015],\n",
      "        [ 0.0107, -0.0478,  0.0046,  ...,  0.0280, -0.0117, -0.0164],\n",
      "        [-0.0333,  0.0439,  0.0026,  ...,  0.0051,  0.0442,  0.0358],\n",
      "        ...,\n",
      "        [ 0.0217,  0.0311,  0.0309,  ...,  0.0206, -0.0295, -0.0282],\n",
      "        [ 0.0378,  0.0352, -0.0268,  ...,  0.0169, -0.0199, -0.0327],\n",
      "        [-0.0366, -0.0411, -0.0111,  ..., -0.0198, -0.0066, -0.0200]],\n",
      "       device='cuda:0')\n",
      "rnn_l6.bias_ih_l0_reverse tensor([ 0.0393,  0.0482,  0.0953,  ..., -0.0295, -0.0794,  0.0667],\n",
      "       device='cuda:0')\n",
      "rnn_l6.bias_hh_l0_reverse tensor([ 0.0573,  0.0998,  0.0754,  ...,  0.0215, -0.0410,  0.0140],\n",
      "       device='cuda:0')\n",
      "classify_layer.weight tensor([[ 0.0227, -0.0521,  0.0423,  ..., -0.0252,  0.0299,  0.0824],\n",
      "        [-0.0293,  0.0894, -0.0241,  ..., -0.0853,  0.0910,  0.0070],\n",
      "        [-0.0300,  0.0152, -0.0572,  ...,  0.0650, -0.0280, -0.0717],\n",
      "        [-0.0629, -0.0043, -0.0454,  ...,  0.0982, -0.0417, -0.0685]],\n",
      "       device='cuda:0')\n",
      "classify_layer.bias tensor([ 0.0413, -0.0073, -0.0791, -0.0626], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_ft.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn1.weight_ih_l0\n",
      "rnn1.weight_hh_l0\n",
      "rnn1.bias_ih_l0\n",
      "rnn1.bias_hh_l0\n",
      "rnn1.weight_ih_l0_reverse\n",
      "rnn1.weight_hh_l0_reverse\n",
      "rnn1.bias_ih_l0_reverse\n",
      "rnn1.bias_hh_l0_reverse\n",
      "rnn2.weight_ih_l0\n",
      "rnn2.weight_hh_l0\n",
      "rnn2.bias_ih_l0\n",
      "rnn2.bias_hh_l0\n",
      "rnn2.weight_ih_l0_reverse\n",
      "rnn2.weight_hh_l0_reverse\n",
      "rnn2.bias_ih_l0_reverse\n",
      "rnn2.bias_hh_l0_reverse\n",
      "rnn3.weight_ih_l0\n",
      "rnn3.weight_hh_l0\n",
      "rnn3.bias_ih_l0\n",
      "rnn3.bias_hh_l0\n",
      "rnn3.weight_ih_l0_reverse\n",
      "rnn3.weight_hh_l0_reverse\n",
      "rnn3.bias_ih_l0_reverse\n",
      "rnn3.bias_hh_l0_reverse\n",
      "rnn4.weight_ih_l0\n",
      "rnn4.weight_hh_l0\n",
      "rnn4.bias_ih_l0\n",
      "rnn4.bias_hh_l0\n",
      "rnn4.weight_ih_l0_reverse\n",
      "rnn4.weight_hh_l0_reverse\n",
      "rnn4.bias_ih_l0_reverse\n",
      "rnn4.bias_hh_l0_reverse\n",
      "rnn5.weight_ih_l0\n",
      "rnn5.weight_hh_l0\n",
      "rnn5.bias_ih_l0\n",
      "rnn5.bias_hh_l0\n",
      "rnn5.weight_ih_l0_reverse\n",
      "rnn5.weight_hh_l0_reverse\n",
      "rnn5.bias_ih_l0_reverse\n",
      "rnn5.bias_hh_l0_reverse\n",
      "rnn6.weight_ih_l0\n",
      "rnn6.weight_hh_l0\n",
      "rnn6.bias_ih_l0\n",
      "rnn6.bias_hh_l0\n",
      "rnn6.weight_ih_l0_reverse\n",
      "rnn6.weight_hh_l0_reverse\n",
      "rnn6.bias_ih_l0_reverse\n",
      "rnn6.bias_hh_l0_reverse\n",
      "rnn_l2.weight_ih_l0\n",
      "rnn_l2.weight_hh_l0\n",
      "rnn_l2.bias_ih_l0\n",
      "rnn_l2.bias_hh_l0\n",
      "rnn_l2.weight_ih_l0_reverse\n",
      "rnn_l2.weight_hh_l0_reverse\n",
      "rnn_l2.bias_ih_l0_reverse\n",
      "rnn_l2.bias_hh_l0_reverse\n",
      "rnn_l41.weight_ih_l0\n",
      "rnn_l41.weight_hh_l0\n",
      "rnn_l41.bias_ih_l0\n",
      "rnn_l41.bias_hh_l0\n",
      "rnn_l41.weight_ih_l0_reverse\n",
      "rnn_l41.weight_hh_l0_reverse\n",
      "rnn_l41.bias_ih_l0_reverse\n",
      "rnn_l41.bias_hh_l0_reverse\n",
      "rnn_l42.weight_ih_l0\n",
      "rnn_l42.weight_hh_l0\n",
      "rnn_l42.bias_ih_l0\n",
      "rnn_l42.bias_hh_l0\n",
      "rnn_l42.weight_ih_l0_reverse\n",
      "rnn_l42.weight_hh_l0_reverse\n",
      "rnn_l42.bias_ih_l0_reverse\n",
      "rnn_l42.bias_hh_l0_reverse\n",
      "rnn_l6.weight_ih_l0\n",
      "rnn_l6.weight_hh_l0\n",
      "rnn_l6.bias_ih_l0\n",
      "rnn_l6.bias_hh_l0\n",
      "rnn_l6.weight_ih_l0_reverse\n",
      "rnn_l6.weight_hh_l0_reverse\n",
      "rnn_l6.bias_ih_l0_reverse\n",
      "rnn_l6.bias_hh_l0_reverse\n",
      "classify_layer.weight\n",
      "classify_layer.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_ft.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucXfPZ9/HPNxEmchCJYxKaUC1JTCZjhN5VkgaPaIlTkVKVlpTWqa1WHk/vUq3etKhjKep0C7k9FKnHqdWUqhKJRoggwWAkSEJIIg4T1/PHWrPt7OzZs5PMmp3MfN+v137NOq9rHWZf+/dba/2WIgIzMzOATpUOwMzM1h1OCmZmluOkYGZmOU4KZmaW46RgZmY5TgpmZpbjpLCOkTRAUkjaIO2/T9K3y5l2DdZ1pqRr1yZeW/+t7XnUCuv/sqQ5kpZKOqgSMRRK98fnKx1HJTgptDJJD0g6p8jwMZLeXN1/vIgYHRE3tkJcIyQ1FCz71xFx3Nouu4V1hqSfZrWO9kjSsel++0nB8AZJIyoUVpbOAS6PiO4RcVfhSEn1kpanSaPpc3kF4uwQnBRa3w3AtySpYPi3gIkR0dj2IVXMt4F30r9tqlK/elvRO8AZknpWOpDVsYb7/XPArBamOSBNGk2fk9ZgPVYGJ4XWdxfQG/hK0wBJmwJfB25K+78m6d+S3pf0uqSzm1uYpL9LOi7t7izpAkkLJb0MfK1g2nGSZktaIullSd9Lh3cD7gP65v3S6ivpbEk3581/oKRZkhan690pb1y9pNMlzZT0nqT/kVRVIu6NgcOAHwA7SKorGL+HpMfSdb0u6dh0eFdJF0p6NV3Po+mwVUo6aUx7p91nS7pd0s2S3geOlTRc0r/SdcyXdLmkDfPmHyzpL5LekfRWWp22laQPJPXJm24XSQskdSlYf9/0F2zvvGHD0uPTRdLnJT2cbsdCSf/T3P4qYjbwL+CHzezfGyT9Kq9/pf2T7pufpMdrmaQ/StpSSXXkEkl/Tc/LfN+RNC/dVz/OW1YnSRMkvSRpkaTbmrZZn1U9fVfSa8Dfmon3eElz0309WVLfdPhLwHbAn9PzcqPV2EdNpap/Sros3c/PSxqVN75vur530vUfnzeuc3rMX0r3yXRJ2+Qtfm8l1VrvSrpCSn7oreVxXfdFhD+t/AGuAa7N6/8eMCOvfwSwM0lSrgbeAg5Kxw0AAtgg7f87cFzafQLwPLANSeKZUjDt14DtAQF7AR8AtXnrbCiI82zg5rT7C8AyYB+gC/BTYC6wYTq+HpgK9E3XPRs4ocQ++BYwH+gM/Bm4NG/ctsASYGy6rj5ATTruinSb+6Xz/gewUTPx1wN7523LJ8BB6X7tCuwC7A5skO7X2cBp6fQ90vh+DFSl/bul4+4FTsxbz++Ay5rZzr8Bx+f1/xa4Ku2+Ffg/aTxVwB5lnj/HAo8CNcBioHc6vAEYkXbfAPyq4JxqKNg3jwNbpvvybeApYFi6P/8GnFVwzt0KdCM5Nxfk7dvT0mX1T+f9A3Brwbw3pfN2LbI9XwUWArXp/JcBjxQ7js3sj2bHp/uqkSR5dgGOAN7L22cPA79P939Nul2j0nE/AZ4BvkjyPzMU6JOOC+AeoBfJ+boA2G9tjuv68ql4AO3xA+yRnphd0/5/Aj8sMf3FwO/S7qZ/smJJ4W/kfRED++ZPW2S5dwGnpt0rfWmkw87ms6Twn8BteeM6AW/w2ZdQPXB03vjfkH75NbPuvwIXp91j03+qLmn//wbuLDJPJ2A5MLTIuGLx574s0m15pLl40mlOa1pvGtO/m5nuCOCfaXdn4E1geDPTHgf8Le0W8DqwZ9p/E3A10H81z59jgUfT7tuA89Pu1U0KR+X13wFcmdd/MnBXwTm3Y8Hx/WPaPZv0izTt35okAW+QN+92Jbbnj8Bv8vq7p/MPKDyOzcxfDywlSZBNn+Pz9tU8QHnTTyX5UbINsALokTfuv4Ab0u4XgDHNrDPI+7JPj8OEtTmu68vH1UcZiIhHSb4Ex0jaDtgVuKVpvKTdJE1JqyTeIykBbFbGovuSfOk0eTV/pKTRkh5Pi8qLgf3LXG7TsnPLi4hP03X1y5vmzbzuD0j+uVeRFsFHAhPTQXeT/KJqqu7aBnipyKybpdMVG1eO/H2DpC9IukfJBf73gV/z2f5oLoameAelx24f4L2ImNrMtLcDX0qrQ/Yk+TL5RzrupySJYqqSarnvrME2/Rw4UdJWazDvW3ndy4v0Fx6/wnOrb9r9OeDOtBpuMUmSWEFSCik2b6HCc2spsIiVz62WHBQRvfI+1+SNeyPSb+uC2PsC70TEkoJxTestdQ5A8+d7axzXdZaTQnZuAo4h+cXyYETk/0PeAkwGtomITYCrSE6ylswnOZGbbNvUkdbF3gFcAGwZEb1IqkGalttSc7jzSP75m5andF1vlBFXoW+RnFt/lvQm8DLJl/0x6fjXSaq5Ci0EPmxm3DJg47z4OgObF0xTuI1XklS37RARPYEz+Wx/NBcDEfEhyS/Do9Jt+e9i06XTLgYeBA4HvklSrRLpuDcj4viI6EtShfh7reZtjhHxPPCnNPZ8K+0PYE2SRqHCc2te2v06MLrgS7kqIvLPjVLnV+G51Y2kynBNzq1i+jXV9xfEPg/oLalHwbim9TZ7DpTSGsd1XeakkJ2bgL2B44HCW0p7kPyC+VDScJIvk3LcBpwiqX96kXBC3rgNSeprFwCNkkaTVC81eQvoI2mTEsv+mqRR6QXVHwMfAY+VGVu+Y4BfkNThNn0OTZffh6QEsbekwyVtIKmPpJq0dHIdcFF6gbCzpC+lCe9FoErJRfouwM/S7S2lB/A+sFTSjsCJeePuAbaSdJqkjST1kLRb3vibSKomDgRuprRb0m0+lJVLhN+Q1D/tfZfki3NFC8sq5hfAOJL67SYzgP0l9U5LEaetwXIL/aekjSUNTtfXdAH1KuBcSZ8DkLS5pDGrsdxbgHGSatJj+WvgiYiob4WYAbYg+b/oIukbwE7AvRHxOsn5+1+SqiRVA9/lsxLstcAvJe2gRLXybjBoTise13WSk0JG0hP+MZKLb5MLRn8fOEfSEpLqgdvKXOw1wAPA0yQXDf+Ut74lwCnpst4lSTST88Y/T3KB7OW0GqBv3nKJiBeAo0kuAi4EDiC5DfDjMmMDQNLuJPXMV6S/qJo+k0kuXI+NiNdIqrZ+THLr5QySi3wAp5Nc/HsyHXc+0Cki3iPZb9eS/NJbRlLHXsrp6X5YQrLvcneJpPtrn3Q73wTmkFR5NY3/J/Ap8FQZX16TgR2AtyLi6bzhuwJPSFqaTnNqRLyS7qdZko5qYblNsbxCUlrpljf4v0nOg3qSkkpr3AHzMMkxegi4ICIeTIdfksb/YHrOPg7sVnwRq4qIh0iuWd1BUtrdHjhyNWNrujup6XNn3rgnSPb/QuBc4LCIWJSOG0tyPs4D7iS5uP6XdNxFJP8vD5L8ePgjyQ0KLWn2uLYHWrkqzsyaSPobcEtE+KnvdZSSW5mPi4g9Kh1Le7G+P+BjlglJu5LcQrk61SRm673Mqo8kXSfpbUnPNjNeki5NHyiZKak2q1jMVoekG0luqT2t4M4Vs3Yvs+ojSXuS3Ft8U0QMKTJ+f5J7pfcnqZ+8JCLKrqc0M7PWl1lJISIeIblQ2JwxJAkjIuJxoJekrbOKx8zMWlbJawr9WPmBl4Z02PzCCSWNB8YDdOvWbZcdd9yxTQI0M2svpk+fvjAiCp/tWUUlk0Kxh7WK1mVFxNUkj5VTV1cX06ZNyzIuM7N2R9KrLU9V2ecUGlj5Ccr+fPYEpZmZVUAlk8Jk4Jj0LqTdSdqXWaXqyMzM2k5m1UeSbiVpuXEzJe28n0XStC0RcRVJuzz7kzxB+QHJY/VmZlZBmSWFiBjbwvggeQGLmXVQn3zyCQ0NDXz44YeVDqXdqKqqon///nTp0qXliYvwE81mVjENDQ306NGDAQMGoFXeYGurKyJYtGgRDQ0NDBw4cI2W4QbxzKxiPvzwQ/r06eOE0Eok0adPn7UqeTkpmFlFOSG0rrXdn04KZmaW46RgZh3WokWLqKmpoaamhq222op+/frl+j/+uLxXiYwbN44XXnih5DRXXHEFEydOLDnNusIXms2sw+rTpw8zZswA4Oyzz6Z79+6cfvrpK02Te6F9p+K/oa+//voW1/ODH6w/N1q6pGBmVmDu3LkMGTKEE044gdraWubPn8/48eOpq6tj8ODBnHPOOblp99hjD2bMmEFjYyO9evViwoQJDB06lC996Uu8/fbbAPzsZz/j4osvzk0/YcIEhg8fzhe/+EUeeyx54+2yZcs49NBDGTp0KGPHjqWuri6XsNqSSwpmtk74xZ9n8dy891t1mYP69uSsAwav0bzPPfcc119/PVdddRUA5513Hr1796axsZGRI0dy2GGHMWjQoJXmee+999hrr70477zz+NGPfsR1113HhAkTVll2RDB16lQmT57MOeecw/33389ll13GVlttxR133MHTTz9NbW1lXjHjkoKZWRHbb789u+66a67/1ltvpba2ltraWmbPns1zzz23yjxdu3Zl9OjRAOyyyy7U19cXXfYhhxyyyjSPPvooRx6ZvLp66NChDB68ZslsbbmkYGbrhDX9RZ+Vbt265brnzJnDJZdcwtSpU+nVqxdHH3100WcBNtxww1x3586daWxsLLrsjTbaaJVpsnrh2epyScHMrAXvv/8+PXr0oGfPnsyfP58HHnig1dexxx57cNtttwHwzDPPFC2JtAWXFMzMWlBbW8ugQYMYMmQI2223HV/+8pdbfR0nn3wyxxxzDNXV1dTW1jJkyBA22WSTVl9PSzJ7R3NW/JIds/Zj9uzZ7LTTTpUOY53Q2NhIY2MjVVVVzJkzh3333Zc5c+awwQar/9u92H6VND0i6lqa1yUFM7N1wNKlSxk1ahSNjY1EBH/4wx/WKCGsLScFM7N1QK9evZg+fXqlw/CFZjMz+4yTgpmZ5TgpmJlZjpOCmZnlOCmYWYc1YsSIVR5Eu/jii/n+97/f7Dzdu3cHYN68eRx22GHNLrelW+cvvvhiPvjgg1z//vvvz+LFi8sNPTNOCmbWYY0dO5ZJkyatNGzSpEmMHTu2xXn79u3L7bffvsbrLkwK9957L7169Vrj5bUWJwUz67AOO+ww7rnnHj766CMA6uvrmTdvHjU1NYwaNYra2lp23nln7r777lXmra+vZ8iQIQAsX76cI488kurqao444giWL1+em+7EE0/MNbl91llnAXDppZcyb948Ro4cyciRIwEYMGAACxcuBOCiiy5iyJAhDBkyJNfkdn19PTvttBPHH388gwcPZt99911pPa3FzymY2brhvgnw5jOtu8ytdobR5zU7uk+fPgwfPpz777+fMWPGMGnSJI444gi6du3KnXfeSc+ePVm4cCG77747Bx54YLPvP77yyivZeOONmTlzJjNnzlyp2etzzz2X3r17s2LFCkaNGsXMmTM55ZRTuOiii5gyZQqbbbbZSsuaPn06119/PU888QQRwW677cZee+3Fpptuypw5c7j11lu55pprOPzww7njjjs4+uijW2dfpVxSMLMOLb8KqanqKCI488wzqa6uZu+99+aNN97grbfeanYZjzzySO7Lubq6murq6ty42267jdraWoYNG8asWbNabOju0Ucf5eCDD6Zbt250796dQw45hH/84x8ADBw4kJqaGqB009xrwyUFM1s3lPhFn6WDDjqIH/3oRzz11FMsX76c2tpabrjhBhYsWMD06dPp0qULAwYMKNpUdr5ipYhXXnmFCy64gCeffJJNN92UY489tsXllGqPrqnJbUia3c6i+sglBTPr0Lp3786IESP4zne+k7vA/N5777HFFlvQpUsXpkyZwquvvlpyGXvuuScTJ04E4Nlnn2XmzJlA0uR2t27d2GSTTXjrrbe47777cvP06NGDJUuWFF3WXXfdxQcffMCyZcu48847+cpXvtJam9silxTMrMMbO3YshxxySK4a6aijjuKAAw6grq6Ompoadtxxx5Lzn3jiiYwbN47q6mpqamoYPnw4kLxBbdiwYQwePHiVJrfHjx/P6NGj2XrrrZkyZUpueG1tLccee2xuGccddxzDhg3LpKqoGDedbWYV46azs7E2TWe7+sjMzHKcFMzMLMdJwcwqan2rwl7Xre3+dFIws4qpqqpi0aJFTgytJCJYtGgRVVVVa7wM331kZhXTv39/GhoaWLBgQaVDaTeqqqro37//Gs/vpGBmFdOlSxcGDhxY6TAsj6uPzMwsJ9OkIGk/SS9ImitpQpHxm0j6s6SnJc2SNC7LeMzMrLTMkoKkzsAVwGhgEDBW0qCCyX4APBcRQ4ERwIWSNswqJjMzKy3LksJwYG5EvBwRHwOTgDEF0wTQQ0lLUt2Bd4DGDGMyM7MSskwK/YDX8/ob0mH5Lgd2AuYBzwCnRsSnhQuSNF7SNEnTfJeCmVl2skwKxd5GUXgz8v8CZgB9gRrgckk9V5kp4uqIqIuIus0337z1IzUzMyDbpNAAbJPX35+kRJBvHPCnSMwFXgFKN0doZmaZyTIpPAnsIGlgevH4SGBywTSvAaMAJG0JfBF4OcOYzMyshMweXouIRkknAQ8AnYHrImKWpBPS8VcBvwRukPQMSXXTGRGxMKuYzMystEyfaI6Ie4F7C4Zdldc9D9g3yxjMzKx8fqLZzMxynBTMzCzHScHMzHKcFMzMLMdJwczMcpwUzMwsx0nBzMxynBTMzCzHScHMzHKcFMzMLMdJwczMclpMCulrNc3MrAMop6QwV9Jvi7xf2czM2plykkI18CJwraTH01djrvJ2NDMzW/+1mBQiYklEXBMR/wH8FDgLmC/pRkmfzzxCMzNrM2VdU5B0oKQ7gUuAC4HtgD9T8K4EMzNbv5Xzkp05wBTgtxHxWN7w2yXtmU1YZmZWCeUkheqIWFpsRESc0srxmJlZBZVzofkKSb2aeiRtKum6DGMyM7MKKevuo4hY3NQTEe8Cw7ILyczMKqWcpNBJ0qZNPZJ6U161k5mZrWfK+XK/EHhM0u1p/zeAc7MLyczMKqXFpBARN0maDowEBBwSEc9lHpmZmbW5sqqBImKWpAVAFYCkbSPitUwjMzOzNlfOw2sHSpoDvAI8DNQD92Ucl5mZVUA5F5p/CewOvBgRA4FRwD8zjcrMzCqinKTwSUQsIrkLqVNETAFqMo7LzMwqoJxrCosldQceASZKehtozDYsMzOrhHJKCmOAD4AfAvcDLwEHZBmUmZlVRsmSQvrWtbsjYm/gU+DGNonKzMwqomRJISJWAB9I2qSN4jEzswoq55rCh8Azkv4CLGsa6BZSzczan3KSwv9LP2Zm1s6V08yFryOYmXUQ5TzR/Iqklws/5Sxc0n6SXpA0V9KEZqYZIWmGpFmSHl7dDTAzs9ZTTvVRXV53FUkrqb1bmim9c+kKYB+gAXhS0uT8xvTSl/f8HtgvIl6TtMXqBG9mZq2rxZJCRCzK+7wRERcDXy1j2cOBuRHxckR8DEwieeYh3zeBPzU1rhcRb69m/GZm1opaLClIqs3r7URScuhRxrL7Aa/n9TcAuxVM8wWgi6S/p8u8JCJuKhLDeGA8wLbbblvGqs3MbE2U+5KdJo0kraUeXsZ8KjIsiqx/F5JG9roC/5L0eES8uNJMEVcDVwPU1dUVLsPMzFpJOXcfjVzDZTcA2+T19wfmFZlmYUQsA5ZJegQYCryImZm1uXLuPvp1ekG4qX9TSb8qY9lPAjtIGihpQ+BIYHLBNHcDX5G0gaSNSaqXZpcfvpmZtaZyGsQbHRGLm3oi4l1g/5ZmiohG4CTgAZIv+tvSN7idIOmEdJrZJI3szQSmAtdGxLOrvxlmZtYayrmm0FnSRhHxEYCkrsBG5Sw8Iu4F7i0YdlVB/2+B35YXrpmZZamcpHAz8JCk60kuFH8Ht5ZqZtYulXOh+TeSZgJ7k9xR9MuIeCDzyMzMrM2V85zCQODvEXF/2t9V0oCIqM86ODMza1vlXGj+vyQv2GmyIh1mZmbtTDlJYYO0mQoA0u4NswvJzMwqpZyksEDSgU09ksYAC7MLyczMKqWcu49OACZKupzkQvPrwDGZRmVmZhVRzt1HLwG7S+oOKCKWSNoy+9DMzKytlVN91KQz8A1JfwWeyigeMzOroJIlhfTp5QNJ3ntQS9K89UHAI9mHZmZmba3ZkoKkiSStle4LXA4MAN6NiL9HxKfNzWdmZuuvUtVHQ4B3SRqzez4iVrDq+xDMzKwdaTYpRMRQkpfp9AT+KukfQA9JW7VVcGZm1rZKXmiOiOcj4ucR8UXgh8BNwFRJj7VJdGZm1qbKeU4BgIiYBkyTdDqwZ3YhmZlZpZSdFJpERAAPZxCLmZlV2Oo8p2BmZu2ck4KZmeWU8z6FjYBDSZ5TyE0fEedkF5aZmVVCOdcU7gbeA6YDH2UbjpmZVVI5SaF/ROyXeSRmZlZx5VxTeEzSzplHYmZmFVdOSWEP4FhJr5BUH4nkztTqTCMzM7M2V05SGJ15FGZmtk5osfooIl4FegEHpJ9e6TAzM2tnWkwKkk4FJgJbpJ+bJZ2cdWBmZtb2yqk++i6wW0QsA5B0PvAv4LIsAzMzs7ZXzt1HAlbk9a9Ih5mZWTtTTknheuAJSXem/QcBf8wuJDMzq5QWk0JEXCTp7yS3pgoYFxH/zjowMzNre80mBUk9I+J9Sb2B+vTTNK53RLyTfXhmZtaWSpUUbgG+TtLmUf67mZX2b5dhXGZmVgHNJoWI+Hr6d2DbhbPueHXRMu6Y3sDzby6pdChmZgDsN2QrDqntn+k6ymk6+6GIGNXSsPZg6UeN3DtzPrdPb2Bq/Tt0Enx+i+50km+2MrPKe/eDTzJfR6lrClXAxsBmkjbls9tQewJ9M4+sjXz6afD4y4u4fXoD9z37Jss/WcH2m3fjjP125OBh/dhqk6pKh2hm1mZKlRS+B5xGkgCm81lSeB+4opyFS9oPuAToDFwbEec1M92uwOPAERFxe3mhr52m6qE7nnqDNxYvp0fVBhxS24/DdulPzTa9kEsHZtYBlbqmcAlwiaSTI2K1n16W1JkkeewDNABPSpocEc8Vme584IHVXcfqKlY99JUdNmfC6B3ZZ9CWVHXpnHUIZmbrtHKeU7hM0hBgEFCVN/ymFmYdDsyNiJcBJE0CxgDPFUx3MnAHsOtqxL3a6m8+mbfnTGPbCM7s0pnNt9yIzXtsxIbqBE+RfMzM1mVb7Qyji1a4tJpyLjSfBYwgSQr3kjSl/SjQUlLoB7ye198A7Faw7H7AwcBXKZEUJI0HxgNsu+22LYVcVO9uG/Jp9w3ZvMdGdN9oA+SWOszMVlFOMxeHAUOBf0fEOElbAteWMV+xb90o6L8YOCMiVpSqw4+Iq4GrAerq6gqXUZaeB19IzzWZ0cysAyknKSyPiE8lNUrqCbxNeQ+uNQDb5PX3B+YVTFMHTEoTwmbA/pIaI+KuMpZvZmatrJykME1SL+AakruQlgJTy5jvSWAHSQOBN4AjgW/mT5D/YJykG4B7nBDMzCqnnAvN3087r5J0P9AzImaWMV+jpJNI7irqDFwXEbMknZCOv2ot4jYzswyUenitttS4iGjxfp2IuJfk4nT+sKLJICKObWl5ZmaWrVIlhQvTv1Ukdf9Pk1w8rgaeIGlK28zM2pFm37wWESMjYiTwKlAbEXURsQswDJjbVgGamVnbKed1nDtGxDNNPRHxLFCTXUhmZlYp5dx9NFvStcDNJM8ZHA3MzjQqMzOriHKSwjjgRODUtP8R4MrMIjIzs4op55bUD4HfpR8zM2vHSt2SeltEHC7pGVZtnoKIqM40MjMza3OlSgpN1UVfb4tAzMys8kq9T2F++vfVtgvHzMwqqVT10RKKVBuRPMAWEeFGR83M2plSJYUebRmImZlVXjm3pAIgaQtWfvPaa5lEZGZmFdPiE82SDpQ0B3gFeBioB+7LOC4zM6uAcpq5+CWwO/Bi+v6DUcA/M43KzMwqopyk8ElELAI6SeoUEVNw20dmZu1SOdcUFkvqTtK8xURJbwON2YZlZmaVUE5JYQywHPghcD/wEnBAlkGZmVlllHpO4XLgloh4LG/wjdmHZGZmlVKqpDAHuFBSvaTzJfk6gplZO1fqzWuXRMSXgL2Ad4DrJc2W9HNJX2izCM3MrM20eE0hIl6NiPMjYhjwTeBg/JIdM7N2qZyH17pIOkDSRJKH1l4EDs08MjMza3OlLjTvA4wFvgZMBSYB4yNiWRvFZmZmbazUcwpnArcAp0fEO20Uj5mZVVCpVlJHtmUgZmZWeeU8vGZmZh2Ek4KZmeU4KZiZWY6TgpmZ5TgpmJlZjpOCmZnlOCmYmVmOk4KZmeU4KZiZWU6mSUHSfpJekDRX0oQi44+SNDP9PCZpaJbxmJlZaZklBUmdgSuA0cAgYKykQQWTvQLsFRHVwC+Bq7OKx8zMWpZlSWE4MDciXo6Ij0laWR2TP0FEPBYR76a9jwP9M4zHzMxakGVS6Ae8ntffkA5rzndJ3tewCknjJU2TNG3BggWtGKKZmeXLMimoyLAoOqE0kiQpnFFsfERcHRF1EVG3+eabt2KIZmaWr9T7FNZWA7BNXn9/YF7hRJKqgWuB0RGxKMN4zMysBVmWFJ4EdpA0UNKGwJHA5PwJJG0L/An4VkS8mGEsZmZWhsxKChHRKOkk4AGgM3BdRMySdEI6/irg50Af4PeSABojoi6rmMzMrDRFFK3mX2fV1dXFtGnTKh2Gmdl6RdL0cn50+4lmMzPLcVIwM7McJwUzM8txUjAzsxwnBTMzy3FSMDOzHCcFMzPLcVIwM7McJwUzM8txUjAzsxwnBTMzy3FSMDOzHCcFMzPLcVIwM7McJwUzM8txUjAzsxwnBTMzy3FSMDOzHCcFMzPLcVIwM7McJwUzM8txUjAzsxwnBTMzy3FSMDOzHCcFMzPLcVIwM7McJwUzM8txUjAzsxwnBTMzy3FSMDOzHCcFMzPLcVIwM7McJwUzM8txUjAzsxwnBTMzy8k0KUjaT9ILkuZKmlBkvCRdmo6fKak2y3jMzKy0zJKCpM7AFcAXFOvyAAAFQ0lEQVRoYBAwVtKggslGAzukn/HAlVnFY2ZmLcuypDAcmBsRL0fEx8AkYEzBNGOAmyLxONBL0tYZxmRmZiVskOGy+wGv5/U3ALuVMU0/YH7+RJLGk5QkAJZKeiHt3gxY2FoBr2c68rZDx95+b3vHtTbb/7lyJsoyKajIsFiDaYiIq4GrV1mBNC0i6tYsvPVbR9526Njb723vmNsObbP9WVYfNQDb5PX3B+atwTRmZtZGskwKTwI7SBooaUPgSGBywTSTgWPSu5B2B96LiPmFCzIzs7aRWfVRRDRKOgl4AOgMXBcRsySdkI6/CrgX2B+YC3wAjFvN1axSpdSBdORth469/d72jivz7VfEKlX4ZmbWQfmJZjMzy3FSMDOznPUyKbTUfEZ7J6le0jOSZkiaVul4siTpOklvS3o2b1hvSX+RNCf9u2klY8xSM9t/tqQ30uM/Q9L+lYwxK5K2kTRF0mxJsySdmg5v98e/xLZnfuzXu2sKafMZLwL7kNzS+iQwNiKeq2hgbUhSPVAXEe3+IR5JewJLSZ58H5IO+w3wTkScl/4o2DQizqhknFlpZvvPBpZGxAWVjC1raesGW0fEU5J6ANOBg4BjaefHv8S2H07Gx359LCmU03yGtRMR8QjwTsHgMcCNafeNJP8s7VIz298hRMT8iHgq7V4CzCZp8aDdH/8S25659TEpNNc0RkcSwIOSpqdNgHQ0WzY9z5L+3aLC8VTCSWnLwte1x+qTQpIGAMOAJ+hgx79g2yHjY78+JoWymsZo574cEbUkrcz+IK1isI7jSmB7oIaknbALKxtOtiR1B+4ATouI9ysdT1sqsu2ZH/v1MSl0+KYxImJe+vdt4E6SKrWO5K2m1nTTv29XOJ42FRFvRcSKiPgUuIZ2fPwldSH5UpwYEX9KB3eI419s29vi2K+PSaGc5jPaLUnd0gtPSOoG7As8W3qudmcy8O20+9vA3RWMpc0VNC9/MO30+EsS8EdgdkRclDeq3R//5ra9LY79enf3EUB6G9bFfNZ8xrkVDqnNSNqOpHQASTMlt7Tn7Zd0KzCCpMngt4CzgLuA24BtgdeAb0REu7wY28z2jyCpPgigHvhee2wzTNIewD+AZ4BP08FnktStt+vjX2Lbx5LxsV8vk4KZmWVjfaw+MjOzjDgpmJlZjpOCmZnlOCmYmVmOk4KZmeU4KZilJK3Ia31yRmu2wCtpQH5Lp2brqsxex2m2HloeETWVDsKsklxSMGtB+v6K8yVNTT+fT4d/TtJDaeNkD0naNh2+paQ7JT2dfv4jXVRnSdek7eM/KKlrOv0pkp5LlzOpQptpBjgpmOXrWlB9dETeuPcjYjhwOcnT9KTdN0VENTARuDQdfinwcEQMBWqBWenwHYArImIwsBg4NB0+ARiWLueErDbOrBx+otksJWlpRHQvMrwe+GpEvJw2UvZmRPSRtJDkRSifpMPnR8RmkhYA/SPio7xlDAD+EhE7pP1nAF0i4leS7id5kc5dwF0RsTTjTTVrlksKZuWJZrqbm6aYj/K6V/DZNb2vAVcAuwDTJflan1WMk4JZeY7I+/uvtPsxklZ6AY4CHk27HwJOhOT1sZJ6NrdQSZ2AbSJiCvBToBewSmnFrK34F4nZZ7pKmpHXf39ENN2WupGkJ0h+SI1Nh50CXCfpJ8ACYFw6/FTgaknfJSkRnEjyQpRiOgM3S9qE5AVSv4uIxa22RWarydcUzFqQXlOoi4iFlY7FLGuuPjIzsxyXFMzMLMclBTMzy3FSMDOzHCcFMzPLcVIwM7McJwUzM8v5/8i/JlEGqiwlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy\n",
    "num_epochs = 25\n",
    "thist = []\n",
    "vhist = []\n",
    "thist = np.array([h.cpu().numpy() for h in train_acc])\n",
    "vhist = np.array([h.cpu().numpy() for h in val_acc])\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(0, num_epochs+1, 5.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cow234-3', 'cow257-4', 'cow1404-0', 'cow160-7', 'cow276-1', 'cow56-7', 'cow210-2', 'cow56-14', 'cow248-14', 'cow274-3', 'cow80-0', 'cow224-1', 'cow278-2', 'cow285-4', 'cow1403-4', 'cow267-3')\n",
      "True:  tensor([1, 0, 0, 2, 0, 2, 0, 2, 1, 1, 2, 1, 0, 0, 3, 0], device='cuda:0')\n",
      "Pred:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "('cow202-5', 'cow273-1', 'cow253-6', 'cow240-3', 'cow69-1', 'cow210-4', 'cow243-1', 'cow208-1', 'cow285-6', 'cow267-4', 'cow215-7', 'cow285-7', 'cow272-7', 'cow274-7', 'cow234-1', 'cow160-6')\n",
      "True:  tensor([3, 0, 1, 0, 3, 0, 2, 2, 0, 0, 2, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "Pred:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "('cow273-14', 'cow202-0', 'cow262-4', 'cow234-2', 'cow287-7', 'cow161-14', 'cow240-4', 'cow216-5', 'cow272-4', 'cow253-0', 'cow212-14', 'cow212-6', 'cow233-5', 'cow217-2', 'cow155-1', 'cow215-4')\n",
      "True:  tensor([1, 3, 1, 1, 1, 2, 0, 3, 0, 0, 1, 1, 1, 0, 1, 2], device='cuda:0')\n",
      "Pred:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "('cow80-14', 'cow171-3', 'cow287-5', 'cow1413-2', 'cow248-2', 'cow215-1', 'cow1408-2', 'cow1409-0', 'cow1-3', 'cow199-1', 'cow224-0', 'cow243-4', 'cow56-3', 'cow272-3', 'cow1408-0', 'cow204-1')\n",
      "True:  tensor([3, 0, 0, 0, 0, 2, 0, 1, 3, 1, 1, 2, 1, 0, 0, 1], device='cuda:0')\n",
      "Pred:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "('cow1-5', 'cow1413-5', 'cow262-5', 'cow233-2', 'cow240-1', 'cow160-1', 'cow234-0', 'cow201-14', 'cow287-2', 'cow277-5', 'cow204-4', 'cow277-14', 'cow1403-3', 'cow276-3', 'cow56-1', 'cow254-7')\n",
      "True:  tensor([3, 0, 1, 1, 0, 1, 2, 2, 0, 0, 1, 0, 3, 0, 1, 0], device='cuda:0')\n",
      "Pred:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "tensor([[32.,  0.,  0.,  0.],\n",
      "        [26.,  0.,  0.,  0.],\n",
      "        [13.,  0.,  0.,  0.],\n",
      "        [ 9.,  0.,  0.,  0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei-chan.hsu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Source: @ptrblck at Pytorch forum\n",
    "nb_classes = 4\n",
    "\n",
    "cm = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for cow, sample in dataloaders['val']:\n",
    "        inputs = sample['seq'].view(batch_size, 20, 50)\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = sample['label'].to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        print(cow)\n",
    "        print('True: ', labels)\n",
    "        print('Pred: ', preds)\n",
    "        print()\n",
    "        for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                cm[t.long(), p.long()] += 1\n",
    "                               \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
